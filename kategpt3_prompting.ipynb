{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kategpt3_prompting import gpt_generation\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt_wrapper\n",
    "\n",
    "# gpt_wrapper.api_base = \"http://mnlp-backend-938795011.eu-central-1.elb.amazonaws.com\"\n",
    "# gpt_wrapper.api_key = get_api_key()\n",
    "\n",
    "# key of exercice 7, to use for small trials since we have a budget limit on our own key :)\n",
    "gpt_wrapper.api_base = \"http://mnlp-backend-938795011.eu-central-1.elb.amazonaws.com\"\n",
    "# gpt_wrapper.api_key = \"d12f21ae-82f9-43d4-9734-55c1c3e9c5b4\"\n",
    "\n",
    "#? Céline\n",
    "#gpt_wrapper.api_key = \"c959e27d-a8bc-420b-aa83-079e234c5505\"\n",
    "gpt_wrapper.api_key = \"bf20344b-e01b-4964-b382-77e743c8e79f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/328519.json\", \"r\") as f:\n",
    "    questions = np.array(json.load(f))\n",
    "\n",
    "#known_answers= [8, 16, 29, 85, 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------Question 0--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Tick the \\textbf{false} statement : \n",
      "[ ] As a defender of a machine learning model you should be more worried about black-box effective attacks than white-box effective attacks.\n",
      "[ ] Privacy problems in machine learning stem solely from the need for data to train models.\n",
      "[ ] Poisoning attacks can be used to increase vulnerability to adversarial examples.\n",
      "[SOLUTION] : The false statement is : Privacy problems in machine learning stem solely from the need for data to train models. Data collection for training is one of many privacy attack vectors in machine learning. There exist attacks on models and outputs; and naturally exposing data for test is a risk in itself. The first statement is true, an adversary performing a black-box attack needs much less resources and capabilities than a white-box adversary. This is much more dangerous, as the adversary only needs the ability to interact with the model. The last statement is also true because by providing poisoning inputs, the adversary gets to shape the boundaries of the model. Thus, she can carve this boundary to facilitate classification errors. In fact, you can understand a backdoor attack as a particular instance of an adversarial example.\n",
      "[QUESTION] : Tick the false assertion. Bluetooth ... \n",
      "[ ] uses a stream cipher for encryption.\n",
      "[ ] has secure integrity protection for secure communication.\n",
      "[ ] has devices which use the same secret key with any other device.uses the SAFER+ block cipher in a one-way mode.\n",
      "[SOLUTION] : The false assertion is : has secure integrity protection for secure communication. Bluetooth is indeed a secure protocol which relies on the E0 stream cipher for privacy. In Bluetooth, the encryption process involves the Long Term Key (LTK), which is a secret key shared and stored by both connected devices. Bluetooth implements confidentiality, authentication and key derivation with custom algorithms based on a SAFER+ block cipher\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : What is a good distance metric to be used when you want to compute the similarity between documents independent of their length?A penalty will be applied for any incorrect answers.\n",
      "[ ] Cosine similarity\n",
      "[ ] Euclidean distance\n",
      "[ ] Manhattan distance\n",
      "[ ] Chi-squared distance\n",
      "[SOLUTION] : \n",
      "Cosine similarity is the correct distance metric to use when you want to compute the similarity between documents independent of their length. This metric measures the cosine of the angle between two vectors, making it insensitive to the magnitude of the vectors and therefore independent of the length of the documents.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "What is a good distance metric to be used when you want to compute the similarity between documents independent of their length?A penalty will be applied for any incorrect answers.\n",
      "[ ] Cosine similarity\n",
      "[ ] Euclidean distance\n",
      "[ ] Manhattan distance\n",
      "[ ] Chi-squared distance\n",
      "The correct answer is:\n",
      "[ ] Cosine similarity\n",
      "\n",
      "Cosine similarity is a good distance metric to use when you want to compute the similarity between documents independent of their length. It measures the cosine of the angle between two vectors, which makes it effective for comparing documents based on the orientation of their term vectors rather than their length.\n",
      "---------------------------------Question 1--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : Consider the motion of a harmonic oscillator. Identify when the  acceleration is naught.\n",
      "\n",
      "\n",
      "[SOLUTION] : \n",
      "The acceleration of a harmonic oscillator is zero at the extreme points of its motion, i.e. at the points where the velocity is maximum and the displacement is either maximum or minimum. This occurs when the oscillator reaches its equilibrium position or its maximum displacement in either direction.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Consider the motion of a harmonic oscillator. Identify when the  acceleration is naught.\n",
      "\n",
      "\n",
      "In the motion of a harmonic oscillator, the acceleration is zero at the extreme points of the motion, where the velocity is maximum. This is because the acceleration is directly proportional to the displacement from the equilibrium position and acts in the opposite direction to the displacement.\n",
      "\n",
      "At the extreme points of the motion (when the oscillator reaches the maximum displacement from the equilibrium position), the direction of the acceleration changes, and at that instant, the acceleration is zero. This occurs because the restoring force at the extreme points is zero, and hence there is no acceleration acting on the oscillator.\n",
      "---------------------------------Question 2--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Considering a sequence of n tokens, the computational complexity of the masked attention mechanism in BERT language models is: (select the smallest correct complexity)\n",
      "[ ] O(n^3)\n",
      "[ ] O(nlog(n))\n",
      "[ ] O(n)\n",
      "[ ] O(n^(1/2))\n",
      "[ ] O(n^2)\n",
      "[SOLUTION] : Masked attention is quadratic in the sequence length n because it computes the attention between all pairs of tokens, therefore O(n^2).\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Which one of these Ciphers is perfectly secure?\n",
      "[ ] Hieroglyphs\n",
      "[ ] Caesar\n",
      "[ ] Vigen\\`{e}re\n",
      "[ ] Vernam\n",
      "[SOLUTION] : \n",
      "Vernam cipher is perfectly secure if used correctly with a truly random key that is at least as long as the message being encrypted. This is because the key stream used in Vernam cipher is XORed with the plaintext, making it impossible for cryptanalysis to determine the original message without the key.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Which one of these Ciphers is perfectly secure?\n",
      "[ ] Hieroglyphs\n",
      "[ ] Caesar\n",
      "[ ] Vigen\\`{e}re\n",
      "[ ] Vernam\n",
      "The Vernam cipher is considered perfectly secure when implemented correctly. It is also known as the one-time pad, where the key used to encrypt the message is as long as the message itself and is completely random. This makes it theoretically unbreakable if the key is kept secret and only used once.\n",
      "---------------------------------Question 3--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Considering a sequence of n tokens, the computational complexity of the masked attention mechanism in BERT language models is: (select the smallest correct complexity)\n",
      "[ ] O(n^3)\n",
      "[ ] O(nlog(n))\n",
      "[ ] O(n)\n",
      "[ ] O(n^(1/2))\n",
      "[ ] O(n^2)\n",
      "[SOLUTION] : Masked attention is quadratic in the sequence length n because it computes the attention between all pairs of tokens, therefore O(n^2).\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : A vending machine dispensing books of stamps accepts only $1 bills, $2 bills and $5 bills.\n",
      "\n",
      "Find a recurrence relation for the number of ways to deposit $$n$$ dollars in the vending machine, where the order in which the coins and bills are deposited matters.\n",
      "[ ] $$a_{n} = a_{n-1} + a_{n-2} + a_{n-5}$$\n",
      "[ ] $$a_{n+1} = a_{n-1} + a_{n-2} + a_{n-5}$$\n",
      "[ ] $$a_{n+1} = a_{n-1} + 2a_{n-2} + 5a_{n-5}$$\n",
      "[ ] $$a_{n} = a_{n-1} + 2a_{n-2} + 5a_{n-5}$$\n",
      "[SOLUTION] : \n",
      "$$a_{n} = a_{n-1} + a_{n-2} + a_{n-5}$$\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "A vending machine dispensing books of stamps accepts only $1 bills, $2 bills and $5 bills.\n",
      "\n",
      "Find a recurrence relation for the number of ways to deposit $$n$$ dollars in the vending machine, where the order in which the coins and bills are deposited matters.\n",
      "[ ] $$a_{n} = a_{n-1} + a_{n-2} + a_{n-5}$$\n",
      "[ ] $$a_{n+1} = a_{n-1} + a_{n-2} + a_{n-5}$$\n",
      "[ ] $$a_{n+1} = a_{n-1} + 2a_{n-2} + 5a_{n-5}$$\n",
      "[ ] $$a_{n} = a_{n-1} + 2a_{n-2} + 5a_{n-5}$$\n",
      "To find the recurrence relation for the number of ways to deposit $n$ dollars in the vending machine, we need to consider the possible last bill deposited. The last bill could be a $1 bill, a $2 bill, or a $5 bill.\n",
      "\n",
      "If the last bill deposited is a $1 bill, then there are $a_{n-1}$ ways to deposit the remaining $n-1$ dollars.\n",
      "\n",
      "If the last bill deposited is a $2 bill, then there are $a_{n-2}$ ways to deposit the remaining $n-2$ dollars.\n",
      "\n",
      "If the last bill deposited is a $5 bill, then there are $a_{n-5}$ ways to deposit the remaining $n-5$ dollars.\n",
      "\n",
      "Therefore, the correct recurrence relation is:\n",
      "$$a_{n} = a_{n-1} + a_{n-2} + a_{n-5}$$\n",
      "\n",
      "So, the correct option is:\n",
      "[ ] $$a_{n} = a_{n-1} + a_{n-2} + a_{n-5}$$\n",
      "---------------------------------Question 4--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Considering a sequence of n tokens, the computational complexity of the masked attention mechanism in BERT language models is: (select the smallest correct complexity)\n",
      "[ ] O(n^3)\n",
      "[ ] O(nlog(n))\n",
      "[ ] O(n)\n",
      "[ ] O(n^(1/2))\n",
      "[ ] O(n^2)\n",
      "[SOLUTION] : Masked attention is quadratic in the sequence length n because it computes the attention between all pairs of tokens, therefore O(n^2).\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Tick the false assertion. Bluetooth ... \n",
      "[ ] uses a stream cipher for encryption.\n",
      "[ ] has secure integrity protection for secure communication.\n",
      "[ ] has devices which use the same secret key with any other device.uses the SAFER+ block cipher in a one-way mode.\n",
      "[SOLUTION] : The false assertion is : has secure integrity protection for secure communication. Bluetooth is indeed a secure protocol which relies on the E0 stream cipher for privacy. In Bluetooth, the encryption process involves the Long Term Key (LTK), which is a secret key shared and stored by both connected devices. Bluetooth implements confidentiality, authentication and key derivation with custom algorithms based on a SAFER+ block cipher\n",
      "[QUESTION] : Which of the following graph analysis techniques do you believe would be most appropriate to identify communities on a social graph?\n",
      "[ ] Cliques\n",
      "[ ] Random Walks\n",
      "[ ] Shortest Paths\n",
      "[ ] Association rules\n",
      "[SOLUTION] : \n",
      "The most appropriate graph analysis technique to identify communities on a social graph would be Cliques. Cliques are subsets of vertices in a graph where every vertex is connected to every other vertex in the subset. In the context of social networks, cliques can represent tightly-knit groups or communities of individuals who interact frequently with each other. By identifying cliques in a social graph, we can uncover these community structures within the network.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Which of the following graph analysis techniques do you believe would be most appropriate to identify communities on a social graph?\n",
      "[ ] Cliques\n",
      "[ ] Random Walks\n",
      "[ ] Shortest Paths\n",
      "[ ] Association rules\n",
      "The most appropriate graph analysis technique to identify communities on a social graph is \"Cliques.\" \n",
      "\n",
      "Cliques are groups of nodes within a graph that are densely connected to each other. In a social graph, cliques can represent communities or groups of individuals who are closely connected or have similar interests. By identifying cliques in a social graph, we can uncover these communities and understand the relationships between members within them. \n",
      "\n",
      "Random walks, shortest paths, and association rules are also valuable techniques for analyzing graphs, but they may not specifically focus on identifying communities within a social graph.\n",
      "---------------------------------Question 5--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : A rigid and homogeneous horizontal rod of mass M, of length L, of negligible thickness e, i.e. e << L, is rotating in a horizontal plane around the vertical axis $C e_3$ at angular velocity $\\Omega=\\dot{\\psioldsymbol{e}3$. The moment of inertia of the rod with respect to the vertical principal axis that contains its centre of mass G is $I{G,3}=\frac1{12}ML^{2}$. Let C be the point of contact between the extremity of the rod and the rotation axis, and P the point at the other extremity. The unit vector $e_1$ is oriented along the rod and the vector $e_2$ is orthogonal to $e_1$. The unit vectors $e_1$, $e_2$ and $e_3$, attached to the rod at point C, are the principal axis frame of the rod. We consider that there is no friction and we do not take explicitly into account the influence of the gravitational field. Give the expression of the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis of rotation $C e_3$ in terms of the scalar quantities M and L.\n",
      "[SOLUTION] : Applying the Huygens-Steiner theorem, we determine the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis $C e_3$ taking into account the fact that d = L/2 is the distance separating points G and C and that $I_{G,3}=\frac1{12}ML^{2}$,\n",
      "ight)^2=\frac{1}{12}ML^2+\frac{1}{4}ML^2=\frac{1}{3}ML^2$\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : Vectorize the input with the Vector Space Model\n",
      "[SOLUTION] : \n",
      "To vectorize the input with the Vector Space Model, we first need to represent the input text as a set of vectors. This can be done by converting the text into a document-term matrix, where each row represents a document (in this case, a sentence or a phrase) and each column represents a term (word).\n",
      "\n",
      "For example, considering the input text \"Vectorize the input with the Vector Space Model\", we can represent it as a document-term matrix with the following terms: \"vectorize\", \"input\", \"with\", \"the\", \"space\", \"model\".\n",
      "\n",
      "The document-term matrix for the input text would look like this:\n",
      "\n",
      "|            | vectorize | input | with | the | space | model |\n",
      "|------------|-----------|-------|------|-----|-------|-------|\n",
      "| Sentence 1 | 1         | 1     | 1    | 1   | 1     | 1     |\n",
      "\n",
      "Each row in the matrix represents a document (sentence) and each column represents a term (word), with the values in the cells indicating the frequency of each term in the corresponding document.\n",
      "\n",
      "This document-term matrix can then be used as input for various text analysis and machine learning tasks, such as information retrieval, document clustering, and text classification, using techniques like cosine similarity or TF-IDF weighting.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Vectorize the input with the Vector Space Model\n",
      "To vectorize the input using the Vector Space Model, we need to follow these steps:\n",
      "\n",
      "1. Tokenization: Break the input text into individual words or tokens.\n",
      "2. Create a vocabulary: Build a list of unique words from the input text.\n",
      "3. Vectorization: Represent the input text as a numerical vector based on the frequency of each word in the vocabulary.\n",
      "\n",
      "Let's illustrate this with an example:\n",
      "\n",
      "Input text: \"The quick brown fox jumps over the lazy dog\"\n",
      "\n",
      "Step 1: Tokenization\n",
      "Tokens: [\"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\"]\n",
      "\n",
      "Step 2: Create a vocabulary\n",
      "Vocabulary: [\"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"lazy\", \"dog\"]\n",
      "\n",
      "Step 3: Vectorization\n",
      "Vector representation:\n",
      "- \"the\": 2 (appears twice in the input text)\n",
      "- \"quick\": 1\n",
      "- \"brown\": 1\n",
      "- \"fox\": 1\n",
      "- \"jumps\": 1\n",
      "- \"over\": 1\n",
      "- \"lazy\": 1\n",
      "- \"dog\": 1\n",
      "\n",
      "The vector representation of the input text using the Vector Space Model would be [2, 1, 1, 1, 1, 1, 1, 1] based on the frequency of each word in the vocabulary.\n",
      "---------------------------------Question 6--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : A rigid and homogeneous horizontal rod of mass M, of length L, of negligible thickness e, i.e. e << L, is rotating in a horizontal plane around the vertical axis $C e_3$ at angular velocity $\\Omega=\\dot{\\psioldsymbol{e}3$. The moment of inertia of the rod with respect to the vertical principal axis that contains its centre of mass G is $I{G,3}=\frac1{12}ML^{2}$. Let C be the point of contact between the extremity of the rod and the rotation axis, and P the point at the other extremity. The unit vector $e_1$ is oriented along the rod and the vector $e_2$ is orthogonal to $e_1$. The unit vectors $e_1$, $e_2$ and $e_3$, attached to the rod at point C, are the principal axis frame of the rod. We consider that there is no friction and we do not take explicitly into account the influence of the gravitational field. Give the expression of the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis of rotation $C e_3$ in terms of the scalar quantities M and L.\n",
      "[SOLUTION] : Applying the Huygens-Steiner theorem, we determine the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis $C e_3$ taking into account the fact that d = L/2 is the distance separating points G and C and that $I_{G,3}=\frac1{12}ML^{2}$,\n",
      "ight)^2=\frac{1}{12}ML^2+\frac{1}{4}ML^2=\frac{1}{3}ML^2$\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : In which type of processors do you expect to find a reorder buffer?\n",
      "[SOLUTION] : \n",
      "A reorder buffer is typically found in out-of-order processors.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "In which type of processors do you expect to find a reorder buffer?\n",
      "Reorder buffers are typically found in out-of-order processors. These processors can execute instructions in an order that is different from the order they appear in the program. The reorder buffer helps keep track of the original program order and ensures that instructions are completed and retired in the correct sequence.\n",
      "---------------------------------Question 7--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : A rigid and homogeneous horizontal rod of mass M, of length L, of negligible thickness e, i.e. e << L, is rotating in a horizontal plane around the vertical axis $C e_3$ at angular velocity $\\Omega=\\dot{\\psioldsymbol{e}3$. The moment of inertia of the rod with respect to the vertical principal axis that contains its centre of mass G is $I{G,3}=\frac1{12}ML^{2}$. Let C be the point of contact between the extremity of the rod and the rotation axis, and P the point at the other extremity. The unit vector $e_1$ is oriented along the rod and the vector $e_2$ is orthogonal to $e_1$. The unit vectors $e_1$, $e_2$ and $e_3$, attached to the rod at point C, are the principal axis frame of the rod. We consider that there is no friction and we do not take explicitly into account the influence of the gravitational field. Give the expression of the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis of rotation $C e_3$ in terms of the scalar quantities M and L.\n",
      "[SOLUTION] : Applying the Huygens-Steiner theorem, we determine the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis $C e_3$ taking into account the fact that d = L/2 is the distance separating points G and C and that $I_{G,3}=\frac1{12}ML^{2}$,\n",
      "ight)^2=\frac{1}{12}ML^2+\frac{1}{4}ML^2=\frac{1}{3}ML^2$\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : Consider the following matrix-factorization problem. For the observed ratings $r_{u m}$ for a given pair $(u, m)$ of a user $u$ and a movie $m$, one typically tries to estimate the score by $$ f_{u m}=\\left\\langle\\mathbf{v}_{u}, \\mathbf{w}_{m}\\right\\rangle+b_{u}+b_{m} $$ Here $\\mathbf{v}_{u}$ and $\\mathbf{w}_{m}$ are vectors in $\\mathbb{R}^{D}$ and $b_{u}$ and $b_{m}$ are scalars, indicating the bias. How could you address the problem of potentially recommending a new movie without any ratings to users? [As in the previous point, this is also not a math question.]\n",
      "[SOLUTION] : \n",
      "One common approach to recommending a new movie to users without any ratings is to use collaborative filtering techniques. Collaborative filtering leverages the ratings of other users to make recommendations. \n",
      "\n",
      "One way to do this is by using matrix factorization techniques, such as Singular Value Decomposition (SVD) or Alternating Least Squares (ALS), to learn latent factors representing users and movies from the existing ratings data. These learned latent factors can then be used to predict the potential rating a user might give to a new movie.\n",
      "\n",
      "Another approach is to use content-based filtering, where information about the movie itself (such as genre, actors, director, etc.) is used to make recommendations. This can be combined with collaborative filtering to provide more personalized recommendations.\n",
      "\n",
      "Additionally, techniques like hybrid recommendation systems that combine collaborative filtering, content-based filtering, and other methods can also be used to recommend new movies to users without any ratings.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Consider the following matrix-factorization problem. For the observed ratings $r_{u m}$ for a given pair $(u, m)$ of a user $u$ and a movie $m$, one typically tries to estimate the score by $$ f_{u m}=\\left\\langle\\mathbf{v}_{u}, \\mathbf{w}_{m}\\right\\rangle+b_{u}+b_{m} $$ Here $\\mathbf{v}_{u}$ and $\\mathbf{w}_{m}$ are vectors in $\\mathbb{R}^{D}$ and $b_{u}$ and $b_{m}$ are scalars, indicating the bias. How could you address the problem of potentially recommending a new movie without any ratings to users? [As in the previous point, this is also not a math question.]\n",
      "One way to address the problem of recommending a new movie without any ratings from users is to use a combination of content-based filtering and collaborative filtering techniques.\n",
      "\n",
      "1. **Content-Based Filtering**: In content-based filtering, movies are recommended to users based on the attributes of the items they have liked in the past. You can recommend a new movie to a user by analyzing the features of the movie (e.g., genre, actors, director, plot keywords) and comparing them with the user's historical preferences. If the movie shares similar characteristics with movies the user has liked before, it may be a good recommendation.\n",
      "\n",
      "2. **Collaborative Filtering**: Collaborative filtering techniques recommend items to users based on the preferences of other users. In the absence of ratings for a new movie, you can leverage collaborative filtering to recommend the new movie to users who have similar preferences to the target user. By analyzing the historical ratings of other users who have rated the new movie, you can identify users with similar taste and recommend the movie to the target user based on their preferences.\n",
      "\n",
      "3. **Hybrid Approaches**: Another approach is to use hybrid recommendation systems that combine content-based and collaborative filtering techniques. By leveraging both content-based features and collaborative filtering algorithms, you can provide more accurate and diverse recommendations to users, even for new items with little to no ratings.\n",
      "\n",
      "By combining these techniques, you can effectively address the challenge of recommending new movies to users without any ratings, providing personalized and relevant recommendations based on user preferences and item characteristics.\n",
      "---------------------------------Question 8--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : A rigid and homogeneous horizontal rod of mass M, of length L, of negligible thickness e, i.e. e << L, is rotating in a horizontal plane around the vertical axis $C e_3$ at angular velocity $\\Omega=\\dot{\\psioldsymbol{e}3$. The moment of inertia of the rod with respect to the vertical principal axis that contains its centre of mass G is $I{G,3}=\frac1{12}ML^{2}$. Let C be the point of contact between the extremity of the rod and the rotation axis, and P the point at the other extremity. The unit vector $e_1$ is oriented along the rod and the vector $e_2$ is orthogonal to $e_1$. The unit vectors $e_1$, $e_2$ and $e_3$, attached to the rod at point C, are the principal axis frame of the rod. We consider that there is no friction and we do not take explicitly into account the influence of the gravitational field. Give the expression of the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis of rotation $C e_3$ in terms of the scalar quantities M and L.\n",
      "[SOLUTION] : Applying the Huygens-Steiner theorem, we determine the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis $C e_3$ taking into account the fact that d = L/2 is the distance separating points G and C and that $I_{G,3}=\frac1{12}ML^{2}$,\n",
      "ight)^2=\frac{1}{12}ML^2+\frac{1}{4}ML^2=\frac{1}{3}ML^2$\n",
      "[QUESTION] : Assume your colleague wants to wait until the next minor release to include a major bugfix instead of making a bugfix release. Explain why this is not a good idea.\n",
      "[SOLUTION] : \n",
      "Waiting until the next minor release to include a major bugfix is not a good idea because it leaves the bug unfixed and potentially affecting users until the next release, which could be weeks or even months away. This can lead to user frustration, negative reviews, and potential loss of users or customers. Additionally, the longer the bug remains unfixed, the more time-consuming and costly it may become to address it in the future. It is generally best practice to address major bugs as soon as possible through a bugfix release to minimize the impact on users and maintain the overall quality and stability of the software.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Assume your colleague wants to wait until the next minor release to include a major bugfix instead of making a bugfix release. Explain why this is not a good idea.\n",
      "Waiting until the next minor release to include a major bugfix instead of making a bugfix release is not a good idea for several reasons:\n",
      "\n",
      "1. Impact on users: By delaying the bugfix until the next minor release, users will have to wait longer for a resolution to the issue. This can result in frustration and dissatisfaction among users who are affected by the bug.\n",
      "\n",
      "2. Severity of the bug: If the bug is considered a major issue that significantly impacts the functionality or security of the software, it should be addressed as soon as possible. Delaying the bugfix can leave the software vulnerable to exploitation or cause further issues down the line.\n",
      "\n",
      "3. Maintenance burden: Allowing major bugs to linger in the software can create additional maintenance burden for the development team. It may lead to more complex bugfixes and testing requirements in the future, increasing the overall workload and potential for introducing new issues.\n",
      "\n",
      "4. Reputation and trust: Failing to address major bugs promptly can damage the reputation of the software and the trust users have in the development team. Users rely on software to work reliably and securely, and delays in addressing critical issues can erode confidence in the product.\n",
      "\n",
      "In conclusion, it is generally recommended to address major bugs promptly through bugfix releases to minimize the impact on users, maintain the integrity of the software, and uphold the trust of the user base.\n",
      "---------------------------------Question 9--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Which of the following is true for Generative Adversarial Networks (GANs) but not Diffusion Models:\n",
      "        \n",
      "[ ] They can generate new data from input noise.\n",
      "[ ] They use two different models during training.\n",
      "[ ] They use a simple L2 loss function.\n",
      "[ ] They gradually remove noise from inputs using a Markov chain.\n",
      "[SOLUTION] : \n",
      "[ ] They can generate new data from input noise. \n",
      "\n",
      "Generative Adversarial Networks (GANs) can generate new data from input noise, while Diffusion Models do not generate data from noise but instead model the data distribution directly.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Which of the following is true for Generative Adversarial Networks (GANs) but not Diffusion Models:\n",
      "        \n",
      "[ ] They can generate new data from input noise.\n",
      "[ ] They use two different models during training.\n",
      "[ ] They use a simple L2 loss function.\n",
      "[ ] They gradually remove noise from inputs using a Markov chain.\n",
      "The statement that is true for Generative Adversarial Networks (GANs) but not Diffusion Models is:\n",
      "\n",
      "[X] They use two different models during training.\n",
      "\n",
      "Explanation:\n",
      "- GANs consist of two neural networks, a generator and a discriminator, that are trained against each other.\n",
      "- Diffusion Models do not involve two separate models like GANs.\n",
      "--------------------------------Question 10--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Considering a sequence of n tokens, the computational complexity of the masked attention mechanism in BERT language models is: (select the smallest correct complexity)\n",
      "[ ] O(n^3)\n",
      "[ ] O(nlog(n))\n",
      "[ ] O(n)\n",
      "[ ] O(n^(1/2))\n",
      "[ ] O(n^2)\n",
      "[SOLUTION] : Masked attention is quadratic in the sequence length n because it computes the attention between all pairs of tokens, therefore O(n^2).\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Tick the false assertion. Bluetooth ... \n",
      "[ ] uses a stream cipher for encryption.\n",
      "[ ] has secure integrity protection for secure communication.\n",
      "[ ] has devices which use the same secret key with any other device.uses the SAFER+ block cipher in a one-way mode.\n",
      "[SOLUTION] : The false assertion is : has secure integrity protection for secure communication. Bluetooth is indeed a secure protocol which relies on the E0 stream cipher for privacy. In Bluetooth, the encryption process involves the Long Term Key (LTK), which is a secret key shared and stored by both connected devices. Bluetooth implements confidentiality, authentication and key derivation with custom algorithms based on a SAFER+ block cipher\n",
      "[QUESTION] : Which of the following is well preserved by 2G?\n",
      "[ ] Confidentiality\n",
      "[ ] Message Integrity\n",
      "[ ] Challenge freshness\n",
      "[ ] Authentication of Mobile Station\n",
      "[SOLUTION] : \n",
      "[ ] Challenge freshness\n",
      "\n",
      "Challenge freshness is not well preserved by 2G networks. 2G networks are known to have vulnerabilities in terms of confidentiality, message integrity, and authentication of the mobile station.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Which of the following is well preserved by 2G?\n",
      "[ ] Confidentiality\n",
      "[ ] Message Integrity\n",
      "[ ] Challenge freshness\n",
      "[ ] Authentication of Mobile Station\n",
      "The correct answer is:\n",
      "\n",
      "[ ] Confidentiality\n",
      "\n",
      "2G networks primarily focus on providing confidentiality through encryption techniques to protect the communication between the mobile station and the base station. Other security features like message integrity, challenge freshness, and authentication are also important but may not be as well preserved in 2G networks compared to newer generations like 3G or 4G.\n",
      "--------------------------------Question 11--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : Tick the \\textbf{false} statement : \n",
      "[ ] As a defender of a machine learning model you should be more worried about black-box effective attacks than white-box effective attacks.\n",
      "[ ] Privacy problems in machine learning stem solely from the need for data to train models.\n",
      "[ ] Poisoning attacks can be used to increase vulnerability to adversarial examples.\n",
      "[SOLUTION] : The false statement is : Privacy problems in machine learning stem solely from the need for data to train models. Data collection for training is one of many privacy attack vectors in machine learning. There exist attacks on models and outputs; and naturally exposing data for test is a risk in itself. The first statement is true, an adversary performing a black-box attack needs much less resources and capabilities than a white-box adversary. This is much more dangerous, as the adversary only needs the ability to interact with the model. The last statement is also true because by providing poisoning inputs, the adversary gets to shape the boundaries of the model. Thus, she can carve this boundary to facilitate classification errors. In fact, you can understand a backdoor attack as a particular instance of an adversarial example.\n",
      "[QUESTION] : Which of the following statements about mitigations are correct?\n",
      "[ ] Control-Flow Integrity can efficiently protect the forward edge\n",
      "            but, when using target sets, is limited on the backward edge\n",
      "[ ] Code-Pointer Integrity (specifically the implementation\n",
      "            described in the slides) uses a separate stack to protect code\n",
      "            pointers.\n",
      "[ ] Shadow stacks can be implemented in software with zero\n",
      "            overhead.\n",
      "[ ] Safe stacks protect against corruption of all data on the\n",
      "            stack.\n",
      "[SOLUTION] : \n",
      "The correct statements about mitigations are:\n",
      "[ ] Control-Flow Integrity can efficiently protect the forward edge but, when using target sets, is limited on the backward edge\n",
      "[ ] Code-Pointer Integrity (specifically the implementation described in the slides) uses a separate stack to protect code pointers.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Which of the following statements about mitigations are correct?\n",
      "[ ] Control-Flow Integrity can efficiently protect the forward edge\n",
      "            but, when using target sets, is limited on the backward edge\n",
      "[ ] Code-Pointer Integrity (specifically the implementation\n",
      "            described in the slides) uses a separate stack to protect code\n",
      "            pointers.\n",
      "[ ] Shadow stacks can be implemented in software with zero\n",
      "            overhead.\n",
      "[ ] Safe stacks protect against corruption of all data on the\n",
      "            stack.\n",
      "Let's break down each statement to determine if it is correct:\n",
      "\n",
      "1. [ ] Control-Flow Integrity can efficiently protect the forward edge but, when using target sets, is limited on the backward edge.\n",
      "   - This statement is generally true. Control-Flow Integrity (CFI) focuses on protecting the control flow of a program to prevent attackers from hijacking the program's execution. While it can efficiently protect the forward edge (return addresses), it may have limitations on the backward edge in certain implementations.\n",
      "\n",
      "2. [ ] Code-Pointer Integrity (specifically the implementation described in the slides) uses a separate stack to protect code pointers.\n",
      "   - This statement is false. Code-Pointer Integrity (CPI) typically involves protecting pointers to code functions within the program. While CPI implementations may involve various techniques, such as shadow stacks or metadata checks, using a separate stack specifically for code pointers is not a common approach.\n",
      "\n",
      "3. [ ] Shadow stacks can be implemented in software with zero overhead.\n",
      "   - This statement is false. Shadow stacks are a security mechanism used to store return addresses separately from the main stack to protect against return-oriented programming attacks. While shadow stacks can enhance security, they do incur some overhead in terms of memory and performance, albeit the overhead can be minimized through efficient implementation.\n",
      "\n",
      "4. [ ] Safe stacks protect against corruption of all data on the stack.\n",
      "   - This statement is false. Safe stacks are a security feature designed to protect return addresses on the stack from being overwritten by attackers. They focus on protecting specific data (return addresses) rather than all data on the stack. Other techniques, such as stack canaries, are used to protect against general stack buffer overflows.\n",
      "\n",
      "In conclusion, the correct statements are:\n",
      "- [x] Control-Flow Integrity can efficiently protect the forward edge but, when using target sets, is limited on the backward edge.\n",
      "--------------------------------Question 12--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Considering a sequence of n tokens, the computational complexity of the masked attention mechanism in BERT language models is: (select the smallest correct complexity)\n",
      "[ ] O(n^3)\n",
      "[ ] O(nlog(n))\n",
      "[ ] O(n)\n",
      "[ ] O(n^(1/2))\n",
      "[ ] O(n^2)\n",
      "[SOLUTION] : Masked attention is quadratic in the sequence length n because it computes the attention between all pairs of tokens, therefore O(n^2).\n",
      "[QUESTION] : Suppose we run JOS and set a breakpoint at syscall (in lib/syscall.c). What are the Current Privilege Level (CPL) before invoking the syscall function and after executing the int 0x30 instruction?\n",
      "[ ] 0 3\n",
      "[ ] 0 0\n",
      "[ ] 3 0\n",
      "[ ] 3 3\n",
      "[SOLUTION] : \n",
      "Before invoking the syscall function, the Current Privilege Level (CPL) is 0. After executing the int 0x30 instruction, the CPL changes to 3. Therefore, the correct answer is 0 3.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Suppose we run JOS and set a breakpoint at syscall (in lib/syscall.c). What are the Current Privilege Level (CPL) before invoking the syscall function and after executing the int 0x30 instruction?\n",
      "[ ] 0 3\n",
      "[ ] 0 0\n",
      "[ ] 3 0\n",
      "[ ] 3 3\n",
      "Before invoking the syscall function, the Current Privilege Level (CPL) is 3, as it is the privilege level of user-mode code in x86 systems.\n",
      "\n",
      "When the int 0x30 instruction is executed, it triggers a software interrupt to transition from user mode to kernel mode. During this transition, the CPL changes from 3 (user mode) to 0 (kernel mode).\n",
      "\n",
      "Therefore, the correct answer is:\n",
      "[ ] 3 0\n",
      "--------------------------------Question 13--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : Last year Professor Ueli von Gruy\\`{e}res worked hard to to obtain an estimator $\\Alg$  to estimate the total cheese consumption of fondue lovers in Switzerland. For a small $\\epsilon >0$, his estimator \\Alg only  asks $3/\\epsilon^2$ random persons and have the following guarantee: if we  let $W$ denote the true answer and let $X$ be the random output of \\Alg then \\begin{align*} \\Pr[|X - W| \\geq \\epsilon W] \\leq 1/3\\,. %\\qquad \\mbox{ where $\\epsilon > 0$ is a small constant.} \\end{align*} However, Ueli is now stuck because the error probability of $1/3$ is too high.  We are  therefore going to help Ueli by designing a new estimator with a much higher success probability while still only asking relatively few persons. For a fixed small parameter $\\delta >0$, your task is to design and analyze an estimator that outputs a random value $Y$ with the following guarantee: \\begin{align} \\label{eq:guarantee2} \\Pr[|Y - W| \\geq \\epsilon W] \\leq \\delta\\,. %\\qquad \\mbox{ where $\\epsilon > 0$ is a small constant.} \\end{align} Your estimator should ask at most $3000\\log(1/\\delta)/\\epsilon^2$ persons about their preferences.  \\\\ While you should explain why your estimator works and what tools to use to analyze it, \\emph{you do not need to do any detailed calculations.} \\\\ {\\em (In this problem you are asked to (i) design an estimator that asks  at most $3000 \\log(1/\\delta)/\\epsilon^2$ persons  and (ii) explain why it satisfies the guarantee~\\eqref{eq:guarantee2}. Recall that you are allowed to refer to material covered in the lecture notes.)}\n",
      "[SOLUTION] : \n",
      "To design an estimator with a higher success probability, we can use the Chernoff bound. Specifically, we can use Hoeffding's inequality to guarantee the desired probability in Eq. \\ref{eq:guarantee2}. \n",
      "\n",
      "By applying Hoeffding's inequality, we can show that the probability of deviation of the estimator $Y$ from the true answer $W$ by more than $\\epsilon W$ decreases exponentially with the number of samples. \n",
      "\n",
      "By setting the number of samples to be at most $3000\\log(1/\\delta)/\\epsilon^2$, we ensure that the probability of a large deviation is bounded by $\\delta$, as required in Eq. \\ref{eq:guarantee2}.\n",
      "\n",
      "Therefore, by using the Chernoff bound and selecting an appropriate number of samples, we can design an estimator with a much higher success probability while still only asking a relatively small number of persons.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Last year Professor Ueli von Gruy\\`{e}res worked hard to to obtain an estimator $\\Alg$  to estimate the total cheese consumption of fondue lovers in Switzerland. For a small $\\epsilon >0$, his estimator \\Alg only  asks $3/\\epsilon^2$ random persons and have the following guarantee: if we  let $W$ denote the true answer and let $X$ be the random output of \\Alg then \\begin{align*} \\Pr[|X - W| \\geq \\epsilon W] \\leq 1/3\\,. %\\qquad \\mbox{ where $\\epsilon > 0$ is a small constant.} \\end{align*} However, Ueli is now stuck because the error probability of $1/3$ is too high.  We are  therefore going to help Ueli by designing a new estimator with a much higher success probability while still only asking relatively few persons. For a fixed small parameter $\\delta >0$, your task is to design and analyze an estimator that outputs a random value $Y$ with the following guarantee: \\begin{align} \\label{eq:guarantee2} \\Pr[|Y - W| \\geq \\epsilon W] \\leq \\delta\\,. %\\qquad \\mbox{ where $\\epsilon > 0$ is a small constant.} \\end{align} Your estimator should ask at most $3000\\log(1/\\delta)/\\epsilon^2$ persons about their preferences.  \\\\ While you should explain why your estimator works and what tools to use to analyze it, \\emph{you do not need to do any detailed calculations.} \\\\ {\\em (In this problem you are asked to (i) design an estimator that asks  at most $3000 \\log(1/\\delta)/\\epsilon^2$ persons  and (ii) explain why it satisfies the guarantee~\\eqref{eq:guarantee2}. Recall that you are allowed to refer to material covered in the lecture notes.)}\n",
      "To design a new estimator with a higher success probability, we can use the technique of \"repeated sampling\" or \"voting\" to reduce the error probability. Here is the algorithm:\n",
      "\n",
      "1. Sample $k = 1000\\log(1/\\delta)$ independent sets of $3/\\epsilon^2$ persons each. Let the total number of persons sampled be $n = 3000\\log(1/\\delta)/\\epsilon^2$.\n",
      "\n",
      "2. For each set of persons, calculate the estimate of total cheese consumption using the estimator $\\Alg$ provided by Professor Ueli von Gruyères.\n",
      "\n",
      "3. Let $Y$ be the average of all the estimates obtained from the $k$ sets.\n",
      "\n",
      "Now, let's analyze why this new estimator satisfies the guarantee \\eqref{eq:guarantee2}.\n",
      "\n",
      "Let $W$ be the true total cheese consumption, and let $Y$ be the random output of our estimator. We want to show that \n",
      "\\[\\Pr[|Y - W| \\geq \\epsilon W] \\leq \\delta.\\]\n",
      "\n",
      "By the union bound, we have\n",
      "\\begin{align*}\n",
      "\\Pr\\left[\\bigcup_{i=1}^{k} \\left\\{|X_i - W| \\geq \\epsilon W\\right\\}\\right] \n",
      "&\\leq \\sum_{i=1}^{k} \\Pr\\left[|X_i - W| \\geq \\epsilon W\\right] \\\\\n",
      "&= k \\cdot \\Pr\\left[|X - W| \\geq \\epsilon W\\right] \\\\\n",
      "&\\leq k \\cdot \\frac{1}{3},\n",
      "\\end{align*}\n",
      "where $X_i$ are the estimates obtained from each set and $X$ is the average estimate $Y$.\n",
      "\n",
      "Since $k = 1000\\log(1/\\delta)$, we can choose $\\delta$ such that $k/3 \\leq \\delta$. Therefore, the error probability of the new estimator is bounded by $\\delta$, as required.\n",
      "\n",
      "This approach leverages the power of averaging multiple estimates to reduce the error probability, while still maintaining a relatively small sample size.\n",
      "--------------------------------Question 14--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : Up to which linguistic processing level can each of the following sentences be considered as correct? The glass broke its leg, I no go rain, The cook put cherry stones in the cake, Cars flow beautifully; syntactic, pragmatic, syntactic, semantic, lexical\n",
      "[SOLUTION] : \n",
      "- The glass broke its leg: Syntactic level (grammatically correct)\n",
      "- I no go rain: Syntactic level (grammatically incorrect)\n",
      "- The cook put cherry stones in the cake: Semantic level (semantically incorrect)\n",
      "- Cars flow beautifully: Pragmatic level (contextually incorrect)\n",
      "-lexical: N/A\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Up to which linguistic processing level can each of the following sentences be considered as correct? The glass broke its leg, I no go rain, The cook put cherry stones in the cake, Cars flow beautifully; syntactic, pragmatic, syntactic, semantic, lexical\n",
      "1. \"The glass broke its leg\" - Syntactic level: The sentence is syntactically correct as it follows the basic structure of subject-verb-object. However, semantically it is incorrect as glasses do not have legs and cannot break them.\n",
      "\n",
      "2. \"I no go rain\" - Syntactic level: The sentence is syntactically incorrect as it does not follow proper English grammar rules. It should be \"I am not going to rain.\" Pragmatically, it may be understood in a colloquial or dialectal context but it is not standard English.\n",
      "\n",
      "3. \"The cook put cherry stones in the cake\" - Syntactic level: The sentence is syntactically correct as it follows the basic structure of subject-verb-object. However, semantically it is incorrect as cherry stones are not typically put in cakes.\n",
      "\n",
      "4. \"Cars flow beautifully\" - Syntactic level: The sentence is syntactically correct as it follows the basic structure of subject-verb-adverb. Semantically, it is also correct as it can be interpreted figuratively to mean that cars are moving smoothly and gracefully.\n",
      "\n",
      "So, for the sentences provided:\n",
      "- \"The glass broke its leg\": Syntactic level\n",
      "- \"I no go rain\": Pragmatic level\n",
      "- \"The cook put cherry stones in the cake\": Syntactic level\n",
      "- \"Cars flow beautifully\": Semantic level\n",
      "--------------------------------Question 15--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Tick the \\textbf{false} statement : \n",
      "[ ] As a defender of a machine learning model you should be more worried about black-box effective attacks than white-box effective attacks.\n",
      "[ ] Privacy problems in machine learning stem solely from the need for data to train models.\n",
      "[ ] Poisoning attacks can be used to increase vulnerability to adversarial examples.\n",
      "[SOLUTION] : The false statement is : Privacy problems in machine learning stem solely from the need for data to train models. Data collection for training is one of many privacy attack vectors in machine learning. There exist attacks on models and outputs; and naturally exposing data for test is a risk in itself. The first statement is true, an adversary performing a black-box attack needs much less resources and capabilities than a white-box adversary. This is much more dangerous, as the adversary only needs the ability to interact with the model. The last statement is also true because by providing poisoning inputs, the adversary gets to shape the boundaries of the model. Thus, she can carve this boundary to facilitate classification errors. In fact, you can understand a backdoor attack as a particular instance of an adversarial example.\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : Which of the following provides forward secrecy.\n",
      "[ ] Transferring keys in plain.\n",
      "[ ] Ephemeral Diffie-Hellman.\n",
      "[ ] Semi-static Diffie-Hellman.\n",
      "[ ] Static Diffie-Hellman.\n",
      "[SOLUTION] : \n",
      "Ephemeral Diffie-Hellman provides forward secrecy.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Which of the following provides forward secrecy.\n",
      "[ ] Transferring keys in plain.\n",
      "[ ] Ephemeral Diffie-Hellman.\n",
      "[ ] Semi-static Diffie-Hellman.\n",
      "[ ] Static Diffie-Hellman.\n",
      "Ephemeral Diffie-Hellman provides forward secrecy because it generates new session keys for each communication session, ensuring that even if an attacker obtains the long-term private key, they cannot decrypt past communications. Static Diffie-Hellman and Semi-static Diffie-Hellman do not provide forward secrecy as they use fixed or semi-fixed keys for multiple sessions. Transferring keys in plain also does not provide forward secrecy as the keys are exposed to potential interception.\n",
      "--------------------------------Question 16--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Considering a sequence of n tokens, the computational complexity of the masked attention mechanism in BERT language models is: (select the smallest correct complexity)\n",
      "[ ] O(n^3)\n",
      "[ ] O(nlog(n))\n",
      "[ ] O(n)\n",
      "[ ] O(n^(1/2))\n",
      "[ ] O(n^2)\n",
      "[SOLUTION] : Masked attention is quadratic in the sequence length n because it computes the attention between all pairs of tokens, therefore O(n^2).\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Let $n$ be an integer. Which of the following is \\emph{not} a group in the general case?\n",
      "[ ] $(\\mathbf{R},+)$\n",
      "[ ] $(\\mathbf{Q}\\setminus \\{0\\},\\times)$\n",
      "[ ] $(\\mathbf{Z}_n,+ \\pmod{n})$\n",
      "[ ] $(\\mathbf{Z}_n,\\times \\pmod{n})$\n",
      "[SOLUTION] : \n",
      "$(\\mathbf{Q}\\setminus \\{0\\},\\times)$ is not a group in the general case. While the set of non-zero rational numbers under multiplication is closed under the operation of multiplication and has an identity element and inverses, it does not satisfy the associative property, which is a necessary condition for a set to be a group.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Let $n$ be an integer. Which of the following is \\emph{not} a group in the general case?\n",
      "[ ] $(\\mathbf{R},+)$\n",
      "[ ] $(\\mathbf{Q}\\setminus \\{0\\},\\times)$\n",
      "[ ] $(\\mathbf{Z}_n,+ \\pmod{n})$\n",
      "[ ] $(\\mathbf{Z}_n,\\times \\pmod{n})$\n",
      "To determine if a given set equipped with an operation forms a group, we need to check the four group axioms:\n",
      "\n",
      "1. Closure: For all $a, b$ in the set, $a \\cdot b$ (or $a + b$) is also in the set.\n",
      "2. Associativity: The operation is associative, i.e., $(a \\cdot b) \\cdot c = a \\cdot (b \\cdot c)$ for all $a, b, c$ in the set.\n",
      "3. Identity Element: There exists an identity element $e$ in the set such that for any element $a$ in the set, $a \\cdot e = e \\cdot a = a$.\n",
      "4. Inverses: For each element $a$ in the set, there exists an inverse $b$ such that $a \\cdot b = b \\cdot a = e$.\n",
      "\n",
      "Let's analyze each of the given sets:\n",
      "\n",
      "1. $(\\mathbf{R},+)$:\n",
      "    - This set forms an abelian group under addition. It satisfies all the group axioms, so it is a group.\n",
      "\n",
      "2. $(\\mathbf{Q}\\setminus \\{0\\},\\times)$:\n",
      "    - This set forms a group under multiplication. It satisfies all the group axioms, including the existence of inverses for every element, except for 0. Since 0 is not included in the set, the set forms a group.\n",
      "\n",
      "3. $(\\mathbf{Z}_n,+ \\pmod{n})$:\n",
      "    - This set forms a group under addition modulo $n$. It satisfies all the group axioms, so it is a group.\n",
      "\n",
      "4. $(\\mathbf{Z}_n,\\times \\pmod{n})$:\n",
      "    - This set may not form a group in the general case. To be a group, the set must satisfy the closure, associativity, identity, and inverses properties. In this case, whether this set forms a group depends on the choice of $n$.\n",
      "  \n",
      "Therefore, the set that is \\emph{not} a group in the general case is $(\\mathbf{Z}_n,\\times \\pmod{n})$.\n",
      "--------------------------------Question 17--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : A rigid and homogeneous horizontal rod of mass M, of length L, of negligible thickness e, i.e. e << L, is rotating in a horizontal plane around the vertical axis $C e_3$ at angular velocity $\\Omega=\\dot{\\psioldsymbol{e}3$. The moment of inertia of the rod with respect to the vertical principal axis that contains its centre of mass G is $I{G,3}=\frac1{12}ML^{2}$. Let C be the point of contact between the extremity of the rod and the rotation axis, and P the point at the other extremity. The unit vector $e_1$ is oriented along the rod and the vector $e_2$ is orthogonal to $e_1$. The unit vectors $e_1$, $e_2$ and $e_3$, attached to the rod at point C, are the principal axis frame of the rod. We consider that there is no friction and we do not take explicitly into account the influence of the gravitational field. Give the expression of the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis of rotation $C e_3$ in terms of the scalar quantities M and L.\n",
      "[SOLUTION] : Applying the Huygens-Steiner theorem, we determine the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis $C e_3$ taking into account the fact that d = L/2 is the distance separating points G and C and that $I_{G,3}=\frac1{12}ML^{2}$,\n",
      "ight)^2=\frac{1}{12}ML^2+\frac{1}{4}ML^2=\frac{1}{3}ML^2$\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : how can the results from a classifier impact the metric (precision) used? What could be a better suited metric to use with imbalanced data?\n",
      "[SOLUTION] : \n",
      "The results from a classifier can impact the precision metric by potentially misleading the evaluation of the model's performance, especially in the case of imbalanced data. Precision is calculated as TP / (TP + FP), where TP is the number of true positives and FP is the number of false positives. In the case of imbalanced data, where one class significantly outnumbers the other, precision may not accurately reflect the classifier's performance. \n",
      "\n",
      "A better suited metric to use with imbalanced data is the F1 score, which is the harmonic mean of precision and recall. The F1 score takes into account both false positives and false negatives, providing a more balanced evaluation of the classifier's performance. It is calculated as 2 * (precision * recall) / (precision + recall), where recall is TP / (TP + FN), with FN being the number of false negatives. \n",
      "\n",
      "Using the F1 score in addition to precision can provide a more comprehensive evaluation of a classifier's performance, especially in cases of imbalanced data where precision alone may not be sufficient.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "how can the results from a classifier impact the metric (precision) used? What could be a better suited metric to use with imbalanced data?\n",
      "When the results from a classifier are imbalanced, meaning the classes in the dataset are not equally represented, it can impact the precision metric. Precision is calculated as the number of true positive predictions divided by the total number of positive predictions (true positives + false positives). In imbalanced datasets, if one class is much more prevalent than the other, the classifier may have a bias towards predicting the majority class more frequently. This can lead to high precision for the majority class but low precision for the minority class.\n",
      "\n",
      "In such cases, precision may not be the most suitable metric to evaluate the performance of the classifier. Instead, metrics like recall, F1-score, or area under the precision-recall curve (PR AUC) could be more informative. These metrics take into account both false positives and false negatives, providing a more balanced view of the classifier's performance on imbalanced data.\n",
      "\n",
      "For imbalanced data, the F1-score is often preferred as it combines precision and recall into a single metric. It is calculated as the harmonic mean of precision and recall, giving equal weight to both metrics. This makes the F1-score a good choice for evaluating classifiers on imbalanced datasets, as it considers both false positives and false negatives.\n",
      "\n",
      "In summary, when dealing with imbalanced data, it is important to consider metrics like recall, F1-score, or PR AUC in addition to precision to get a comprehensive understanding of the classifier's performance.\n",
      "--------------------------------Question 18--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : Design an algorithm that implements consensus using multiple TRB instances.\n",
      "[SOLUTION] : \n",
      "One possible algorithm to implement consensus using multiple TRB instances is as follows:\n",
      "\n",
      "1. Initialize each TRB instance with its own unique identifier and a list of values to be proposed.\n",
      "\n",
      "2. Each TRB instance broadcasts its proposed value to all other TRB instances.\n",
      "\n",
      "3. Upon receiving proposed values from all other TRB instances, each TRB instance calculates the median value of the proposed values.\n",
      "\n",
      "4. Each TRB instance broadcasts the calculated median value to all other TRB instances.\n",
      "\n",
      "5. Upon receiving median values from all other TRB instances, each TRB instance checks if the received median values are within an acceptable range of each other. If the median values are within the acceptable range, the TRB instance accepts the median value as the final consensus value. If the median values are not within the acceptable range, the TRB instance repeats the process.\n",
      "\n",
      "6. Repeat steps 2-5 until all TRB instances have reached a final consensus value that is accepted by all instances.\n",
      "\n",
      "This algorithm ensures that consensus is reached using multiple TRB instances by iteratively proposing values, calculating medians, and accepting a final consensus value that is within an acceptable range of all TRB instances.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Design an algorithm that implements consensus using multiple TRB instances.\n",
      "To achieve consensus using multiple TRB (Threshold Relay Blockchain) instances, we can use a variation of the traditional Byzantine Fault Tolerant (BFT) algorithm. Here's a high-level outline of the algorithm:\n",
      "\n",
      "1. Setup:\n",
      "   - Initialize a set of TRB instances, each with its own set of validators.\n",
      "   - Define a threshold for the number of instances that need to agree on a decision for it to be considered final.\n",
      "\n",
      "2. Communication:\n",
      "   - Validators in each TRB instance communicate their proposed transactions or blocks with the other instances.\n",
      "\n",
      "3. Agreement Phase:\n",
      "   - Each TRB instance collects proposed transactions or blocks from validators.\n",
      "   - Validators in each instance run a consensus algorithm, such as Practical Byzantine Fault Tolerance (PBFT) or HoneyBadger BFT, to reach agreement on the proposed transactions or blocks.\n",
      "   - Once a TRB instance reaches consensus internally, it broadcasts the decision to other instances.\n",
      "\n",
      "4. Cross-Instance Communication:\n",
      "   - Validators in each instance exchange the decisions reached by their respective instances.\n",
      "   - Validators in each instance verify the decisions received from other instances and check if the threshold for the number of concurring instances is met.\n",
      "\n",
      "5. Final Decision:\n",
      "   - If the threshold for the number of concurring instances is met, the decision is considered final.\n",
      "   - If the threshold is not met, validators may need to repeat the process by proposing new transactions or blocks and going through the agreement phase again.\n",
      "\n",
      "This algorithm ensures that decisions are only considered final when a sufficient number of TRB instances agree on them. This approach helps to increase the security and reliability of the consensus mechanism by leveraging multiple instances and thresholds.\n",
      "--------------------------------Question 19--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : A rigid and homogeneous horizontal rod of mass M, of length L, of negligible thickness e, i.e. e << L, is rotating in a horizontal plane around the vertical axis $C e_3$ at angular velocity $\\Omega=\\dot{\\psioldsymbol{e}3$. The moment of inertia of the rod with respect to the vertical principal axis that contains its centre of mass G is $I{G,3}=\frac1{12}ML^{2}$. Let C be the point of contact between the extremity of the rod and the rotation axis, and P the point at the other extremity. The unit vector $e_1$ is oriented along the rod and the vector $e_2$ is orthogonal to $e_1$. The unit vectors $e_1$, $e_2$ and $e_3$, attached to the rod at point C, are the principal axis frame of the rod. We consider that there is no friction and we do not take explicitly into account the influence of the gravitational field. Give the expression of the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis of rotation $C e_3$ in terms of the scalar quantities M and L.\n",
      "[SOLUTION] : Applying the Huygens-Steiner theorem, we determine the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis $C e_3$ taking into account the fact that d = L/2 is the distance separating points G and C and that $I_{G,3}=\frac1{12}ML^{2}$,\n",
      "ight)^2=\frac{1}{12}ML^2+\frac{1}{4}ML^2=\frac{1}{3}ML^2$\n",
      "[QUESTION] : Write the dual of the following linear program: \\begin{align*} \\text{Maximize}  \\quad &6x_1 + 14 x_2 + 13 x_3\\\\ \\text{Subject to} \\quad & x_1 + 3x_2 + x_3 \\leq 24 \\\\ & x_1 + 2x_2 + 4 x_3 \\leq 60 \\\\ & x_1, x_2, x_3 \\geq 0 \\end{align*} Hint: How can you convince your friend that the above linear program has optimum value at most $z$?\n",
      "[SOLUTION] : \n",
      "The dual of a linear program is obtained by flipping the direction of the inequalities and swapping the roles of the variables and constraints. \n",
      "\n",
      "The dual of the given linear program is:\n",
      "\n",
      "\\begin{align*}\n",
      "\\text{Minimize} \\quad & 24y_1 + 60y_2 \\\\\n",
      "\\text{Subject to} \\quad & y_1 + y_2 \\geq 6 \\\\\n",
      "& 3y_1 + 2y_2 \\geq 14 \\\\\n",
      "& y_1 + 4y_2 \\geq 13 \\\\\n",
      "& y_1, y_2 \\geq 0\n",
      "\\end{align*}\n",
      "\n",
      "To convince a friend that the original linear program has an optimum value at most $z$, we can show that the dual linear program has an optimum value of at most $z$ as well. This is because of the strong duality theorem in linear programming, which states that the optimal value of the primal linear program is equal to the optimal value of the dual linear program.\n",
      "\n",
      "Therefore, by solving the dual linear program and showing that its optimum value is at most $z$, we can indirectly demonstrate that the original linear program also has an optimum value at most $z.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Write the dual of the following linear program: \\begin{align*} \\text{Maximize}  \\quad &6x_1 + 14 x_2 + 13 x_3\\\\ \\text{Subject to} \\quad & x_1 + 3x_2 + x_3 \\leq 24 \\\\ & x_1 + 2x_2 + 4 x_3 \\leq 60 \\\\ & x_1, x_2, x_3 \\geq 0 \\end{align*} Hint: How can you convince your friend that the above linear program has optimum value at most $z$?\n",
      "To write the dual of the given linear program, we first rewrite the primal program in standard form by converting the maximization problem to a minimization problem:\n",
      "\n",
      "\\begin{align*} \\text{Minimize}  \\quad &-6x_1 - 14 x_2 - 13 x_3\\\\ \\text{Subject to} \\quad & x_1 + 3x_2 + x_3 \\leq 24 \\\\ & x_1 + 2x_2 + 4 x_3 \\leq 60 \\\\ & x_1, x_2, x_3 \\geq 0 \\end{align*}\n",
      "\n",
      "Next, we introduce the dual variables $y_1$ and $y_2$ corresponding to the constraints in the primal problem. The dual of the given linear program is:\n",
      "\n",
      "\\begin{align*} \\text{Maximize}  \\quad &24y_1 + 60y_2\\\\ \\text{Subject to} \\quad & y_1 + y_2 \\leq -6 \\\\ & 3y_1 + 2y_2 \\leq -14 \\\\ & y_1 + 4y_2 \\leq -13 \\\\ & y_1, y_2 \\geq 0 \\end{align*}\n",
      "\n",
      "To convince a friend that the primal linear program has an optimum value at most $z$, where $z$ is a given value, we can use the weak duality theorem. The weak duality theorem states that for any feasible primal and dual solutions, the objective value of the dual at those points is always less than or equal to the objective value of the primal at those points.\n",
      "\n",
      "Therefore, if we can find feasible solutions for both the primal and dual programs such that the objective value of the dual at those points is less than or equal to $z$, then we have shown that the primal program has an optimum value at most $z.\n",
      "--------------------------------Question 20--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : A vehicle is in linear motion. The scalar velocity as a function of time is given by\n",
      "\n",
      "\\begin{equation*}\n",
      "v(t) = b_0t^2 -\\,a_0t\\ ,\n",
      "\\end{equation*}\n",
      "\n",
      "where $b_0$ and $a_0$ are positive constants. Determine the average velocity $\\bar{v}(t)$ at time $t$.\n",
      "\n",
      "[SOLUTION] : \n",
      "The average velocity $\\bar{v}(t)$ at time $t$ is given by the formula:\n",
      "\n",
      "\\begin{equation}\n",
      "\\bar{v}(t) = \\frac{1}{t} \\int_{0}^{t} v(t) dt\n",
      "\\end{equation}\n",
      "\n",
      "Substitute the given velocity function into the formula:\n",
      "\n",
      "\\begin{equation}\n",
      "\\bar{v}(t) = \\frac{1}{t} \\int_{0}^{t} (b_0t^2 - a_0t) dt\n",
      "\\end{equation}\n",
      "\n",
      "Solving the integral:\n",
      "\n",
      "\\begin{equation}\n",
      "\\bar{v}(t) = \\frac{1}{t} \\left[\\frac{b_0}{3}t^3 - \\frac{a_0}{2}t^2 \\right]_{0}^{t}\n",
      "\\end{equation}\n",
      "\n",
      "\\begin{equation}\n",
      "\\bar{v}(t) = \\frac{1}{t} \\left(\\frac{b_0}{3}t^3 - \\frac{a_0}{2}t^2 - 0 \\right)\n",
      "\\end{equation}\n",
      "\n",
      "\\begin{equation}\n",
      "\\bar{v}(t) = \\frac{1}{t} \\left(\\frac{b_0}{3}t^3 - \\frac{a_0}{2}t^2 \\right)\n",
      "\\end{equation}\n",
      "\n",
      "\\begin{equation}\n",
      "\\bar{v}(t) = \\frac{b_0}{3}t^2 - \\frac{a_0}{2}t\n",
      "\\end{equation}\n",
      "\n",
      "Therefore, the average velocity $\\bar{v}(t)$ at time $t$ is $\\frac{b_0}{3}t^2 - \\frac{a_0}{2}t$.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "A vehicle is in linear motion. The scalar velocity as a function of time is given by\n",
      "\n",
      "\\begin{equation*}\n",
      "v(t) = b_0t^2 -\\,a_0t\\ ,\n",
      "\\end{equation*}\n",
      "\n",
      "where $b_0$ and $a_0$ are positive constants. Determine the average velocity $\\bar{v}(t)$ at time $t$.\n",
      "\n",
      "To determine the average velocity $\\bar{v}(t)$ at time $t$, we need to find the total displacement of the vehicle over a certain time interval and then divide it by the total time taken. \n",
      "\n",
      "The total displacement $\\Delta x$ of the vehicle over a time interval from $t_1$ to $t_2$ can be calculated by integrating the velocity function $v(t)$ over that time interval:\n",
      "\n",
      "\\[\\Delta x = \\int_{t_1}^{t_2} v(t)dt = \\int_{t_1}^{t_2} (b_0t^2 - a_0t)dt\\]\n",
      "\n",
      "This gives us the change in position of the vehicle during the time interval from $t_1$ to $t_2$. \n",
      "\n",
      "The average velocity $\\bar{v}(t)$ at time $t$ can then be calculated as:\n",
      "\n",
      "\\[\\bar{v}(t) = \\frac{\\Delta x}{\\Delta t}\\]\n",
      "\n",
      "where $\\Delta t = t_2 - t_1$ is the time interval over which the displacement occurs.\n",
      "\n",
      "Therefore, to determine the average velocity at time $t$, we need to specify the time interval over which we want to calculate the average velocity.\n",
      "--------------------------------Question 21--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : You have been publishing a daily column for the Gazette over the last few years and have recently reached a milestone --- your 1000th column! Realizing you'd like to go skiing more often, you decide it might be easier to automate your job by training a story generation system on the columns you've already written. Then, whenever your editor pitches you a title for a column topic, you'll just be able to give the title to your story generation system, produce the text body of the column, and publish it to the website!\n",
      "Your column generation system has become quite successful and you've managed to automate most of your job simply by typing your editor's title pitches into your model to produce your column every day. Two years later, during the COVID--25 pandemic, your editor proposes to use your system to generate an information sheet about the pandemic for anyone looking for information about symptoms, treatments, testing sites, medical professionals, etc. Given the similarity to a previous pandemic many years before, COVID--19, you train your model on all news articles published about COVID--19 between the years of 2019--2022. Then, you generate the information page from your trained model.\n",
      "Give an example of a potential harm that your model could produce from the perspective of human interaction harms.\n",
      "[SOLUTION] : \n",
      "One potential harm that could arise from using a story generation system trained on past columns to generate information about the COVID-19 pandemic is the dissemination of inaccurate or outdated information. As the system is trained on articles from 2019-2022 about COVID-19, it may not be equipped to provide up-to-date information about the COVID-25 pandemic. This could lead to confusion or misinformation among readers who rely on the generated information sheet for accurate and current information. This could potentially harm human interaction by spreading false information and impacting decision-making related to health and safety during the pandemic.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "You have been publishing a daily column for the Gazette over the last few years and have recently reached a milestone --- your 1000th column! Realizing you'd like to go skiing more often, you decide it might be easier to automate your job by training a story generation system on the columns you've already written. Then, whenever your editor pitches you a title for a column topic, you'll just be able to give the title to your story generation system, produce the text body of the column, and publish it to the website!\n",
      "Your column generation system has become quite successful and you've managed to automate most of your job simply by typing your editor's title pitches into your model to produce your column every day. Two years later, during the COVID--25 pandemic, your editor proposes to use your system to generate an information sheet about the pandemic for anyone looking for information about symptoms, treatments, testing sites, medical professionals, etc. Given the similarity to a previous pandemic many years before, COVID--19, you train your model on all news articles published about COVID--19 between the years of 2019--2022. Then, you generate the information page from your trained model.\n",
      "Give an example of a potential harm that your model could produce from the perspective of human interaction harms.\n",
      "One potential harm that could arise from using an AI-generated information page on COVID-25, trained on news articles about COVID-19, is the dissemination of inaccurate or misleading information. While AI models can be incredibly powerful tools for processing and generating vast amounts of data, they are not immune to biases or errors in the training data.\n",
      "\n",
      "If the model is not properly vetted or supervised, it could inadvertently generate misinformation or promote certain biases present in the training data. This could lead to harmful consequences such as spreading inaccurate information about COVID-25 symptoms, treatments, or testing sites, potentially causing confusion or even harm to individuals seeking reliable information.\n",
      "\n",
      "Additionally, relying solely on an AI-generated information page without human oversight or intervention could also lead to a lack of empathy or understanding in the communication of important health information. AI models lack the emotional intelligence and nuanced understanding of human interactions that humans possess, which could result in a cold or impersonal tone in the information presented, potentially alienating or upsetting readers who are seeking guidance and support during a challenging time like a pandemic.\n",
      "\n",
      "Therefore, it is crucial to ensure that AI-generated content, especially when it comes to sensitive topics like healthcare information, is carefully monitored, fact-checked, and supplemented with human oversight to mitigate the risks of disseminating harmful or misleading information and to maintain a human touch in communication.\n",
      "--------------------------------Question 22--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : A rigid and homogeneous horizontal rod of mass M, of length L, of negligible thickness e, i.e. e << L, is rotating in a horizontal plane around the vertical axis $C e_3$ at angular velocity $\\Omega=\\dot{\\psioldsymbol{e}3$. The moment of inertia of the rod with respect to the vertical principal axis that contains its centre of mass G is $I{G,3}=\frac1{12}ML^{2}$. Let C be the point of contact between the extremity of the rod and the rotation axis, and P the point at the other extremity. The unit vector $e_1$ is oriented along the rod and the vector $e_2$ is orthogonal to $e_1$. The unit vectors $e_1$, $e_2$ and $e_3$, attached to the rod at point C, are the principal axis frame of the rod. We consider that there is no friction and we do not take explicitly into account the influence of the gravitational field. Give the expression of the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis of rotation $C e_3$ in terms of the scalar quantities M and L.\n",
      "[SOLUTION] : Applying the Huygens-Steiner theorem, we determine the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis $C e_3$ taking into account the fact that d = L/2 is the distance separating points G and C and that $I_{G,3}=\frac1{12}ML^{2}$,\n",
      "ight)^2=\frac{1}{12}ML^2+\frac{1}{4}ML^2=\frac{1}{3}ML^2$\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : Suppose that Alice and Bob have two documents $d_A$ and $d_B$ respectively, and Charlie wants to learn about the difference between them. We represent each document by its word frequency vector as follows. We assume that words in $d_A$ and $d_B$ come from some dictionary of size $n$, and let $x\\in \\mathbb{R}^n$ be a vector such that for every word $i\\in [n]$\\footnote{We let $[n]:=\\{1,2,\\ldots, n\\}$.} the entry $x_i$ equals the number of times the $i$-th word in the dictionary occurs in $d_A$. Similarly, let $y\\in \\mathbb{R}^n$ be a vector such that for every word $i\\in [n]$ the entry $y_i$ denotes the number of times the $i$-th word in the dictionary occurs in $d_B$. We assume that the number of words in each document is bounded by a polynomial in $n$. Suppose that there exists $i^*\\in [n]$ such that for all $i\\in [n]\\setminus \\{i^*\\}$ one has $|x_i-y_i|\\leq 2$, and for $i^*$ one has $|x_{i^*}-y_{i^*}|\\geq n^{1/2}$.  Show that Alice and Bob can each send a $O(\\log^2 n)$-bit message to Charlie, from which Charlie can recover the identity of the special word $i^*$. Your solution must succeed with probability at least $9/10$. You may assume that Alice, Bob and Charlie have a source of shared random bits.\n",
      "[SOLUTION] : \n",
      "To solve this problem, Alice and Bob can use the following protocol:\n",
      "\n",
      "1. Alice and Bob agree on a random hash function $h: [n] \\rightarrow [2\\log n]$ that maps each word index to a binary string of length $2\\log n$.\n",
      "\n",
      "2. Alice computes the hash values $h(x_1), h(x_2), \\ldots, h(x_n)$ and sends the set of hashed values $\\{h(x_i)\\}_{i=1}^n$ to Charlie.\n",
      "\n",
      "3. Bob computes the hash values $h(y_1), h(y_2), \\ldots, h(y_n)$ and sends the set of hashed values $\\{h(y_i)\\}_{i=1}^n$ to Charlie.\n",
      "\n",
      "4. Charlie checks if there exists an index $i^*$ such that $|h(x_{i^*}) - h(y_{i^*})| \\geq 2\\log n$. If such an index exists, Charlie outputs $i^*$. Otherwise, Charlie outputs \"No special word found.\"\n",
      "\n",
      "This protocol works with high probability because:\n",
      "- If $i = i^*$, then $|h(x_i) - h(y_i)| \\geq 2\\log n$ with high probability due to the properties of hash functions.\n",
      "- If $i \\neq i^*$, then $|h(x_i) - h(y_i)| \\leq 2$ with high probability due to the given condition $|x_i - y_i| \\leq 2$ for all $i \\neq i^*$.\n",
      "\n",
      "Therefore, Alice and Bob can each send a $O(\\log^2 n)$-bit message to Charlie, from which Charlie can recover the identity of the special word $i^*$ with probability at least $9/10$.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Suppose that Alice and Bob have two documents $d_A$ and $d_B$ respectively, and Charlie wants to learn about the difference between them. We represent each document by its word frequency vector as follows. We assume that words in $d_A$ and $d_B$ come from some dictionary of size $n$, and let $x\\in \\mathbb{R}^n$ be a vector such that for every word $i\\in [n]$\\footnote{We let $[n]:=\\{1,2,\\ldots, n\\}$.} the entry $x_i$ equals the number of times the $i$-th word in the dictionary occurs in $d_A$. Similarly, let $y\\in \\mathbb{R}^n$ be a vector such that for every word $i\\in [n]$ the entry $y_i$ denotes the number of times the $i$-th word in the dictionary occurs in $d_B$. We assume that the number of words in each document is bounded by a polynomial in $n$. Suppose that there exists $i^*\\in [n]$ such that for all $i\\in [n]\\setminus \\{i^*\\}$ one has $|x_i-y_i|\\leq 2$, and for $i^*$ one has $|x_{i^*}-y_{i^*}|\\geq n^{1/2}$.  Show that Alice and Bob can each send a $O(\\log^2 n)$-bit message to Charlie, from which Charlie can recover the identity of the special word $i^*$. Your solution must succeed with probability at least $9/10$. You may assume that Alice, Bob and Charlie have a source of shared random bits.\n",
      "Let's break down the problem into steps:\n",
      "\n",
      "1. **Construct a Protocol**: We need to come up with a protocol that allows Alice and Bob to send messages to Charlie such that Charlie can identify the special word $i^*$ with high probability.\n",
      "\n",
      "2. **Analyze the Protocol**: We need to analyze the protocol to ensure that it succeeds with probability at least $9/10$.\n",
      "\n",
      "3. **Calculate the Communication Complexity**: We need to determine the number of bits that Alice and Bob need to send to Charlie in this protocol.\n",
      "\n",
      "Let's start by constructing a protocol:\n",
      "\n",
      "1. **Protocol**:\n",
      "    - Alice and Bob agree on a random hash function $h: [n] \\rightarrow [k]$ where $k = O(\\log n)$.\n",
      "    - Alice computes $h(i)$ for all $i \\in [n]$ and sends the tuple $(h(i), x_i)$ to Charlie.\n",
      "    - Bob computes $h(i)$ for all $i \\in [n]$ and sends the tuple $(h(i), y_i)$ to Charlie.\n",
      "    - Upon receiving the messages from Alice and Bob, Charlie performs the following steps:\n",
      "        1. For each $j \\in [k]$, let $S_j^A$ be the set of words $i$ such that $h(i) = j$ in the message from Alice, and $S_j^B$ be the set of words $i$ such that $h(i) = j$ in the message from Bob.\n",
      "        2. Let $C_j = |S_j^A \\cap S_j^B|$ for each $j \\in [k]$.\n",
      "        3. Find the index $j^*$ such that $C_{j^*} = \\max_{j\\in [k]} C_j$.\n",
      "        4. Output $i^* = \\text{argmax}_{i\\in S_{j^*}^A \\cup S_{j^*}^B} |x_i - y_i|$.\n",
      "\n",
      "Now, let's analyze the protocol:\n",
      "\n",
      "2. **Analysis**:\n",
      "    - By the definition of the protocol, if there exists $i^*$ such that $|x_{i^*} - y_{i^*}| \\geq n^{1/2}$, then $i^*$ will be in the set $S_{j^*}^A \\cup S_{j^*}^B$ with high probability.\n",
      "    - Since $|x_i - y_i| \\leq 2$ for all $i \\neq i^*$, the maximum difference occurs at $i^*$.\n",
      "    - The protocol succeeds if $i^*$ is correctly identified in $S_{j^*}^A \\cup S_{j^*}^B$.\n",
      "    - The probability of error in identifying $i^*$ is at most $1/10$ by Chernoff bound.\n",
      "\n",
      "Finally, let's calculate the communication complexity:\n",
      "\n",
      "3. **Communication Complexity**:\n",
      "    - Alice and Bob each send $O(kn) = O(\\log n \\cdot n)$ bits to Charlie.\n",
      "    - The total communication complexity is $O(\\log n \\cdot n)$ bits, which is $O(\\log^2 n)$.\n",
      "\n",
      "Therefore, we have successfully constructed a protocol that allows Alice and Bob to send messages to Charlie, from which Charlie can recover the identity of the special word $i^*$ with high probability and a communication complexity of $O(\\log^2 n)$ bits.\n",
      "--------------------------------Question 23--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Tick the false assertion. Bluetooth ... \n",
      "[ ] uses a stream cipher for encryption.\n",
      "[ ] has secure integrity protection for secure communication.\n",
      "[ ] has devices which use the same secret key with any other device.uses the SAFER+ block cipher in a one-way mode.\n",
      "[SOLUTION] : The false assertion is : has secure integrity protection for secure communication. Bluetooth is indeed a secure protocol which relies on the E0 stream cipher for privacy. In Bluetooth, the encryption process involves the Long Term Key (LTK), which is a secret key shared and stored by both connected devices. Bluetooth implements confidentiality, authentication and key derivation with custom algorithms based on a SAFER+ block cipher\n",
      "[QUESTION] : Tick the \\textbf{false} statement : \n",
      "[ ] As a defender of a machine learning model you should be more worried about black-box effective attacks than white-box effective attacks.\n",
      "[ ] Privacy problems in machine learning stem solely from the need for data to train models.\n",
      "[ ] Poisoning attacks can be used to increase vulnerability to adversarial examples.\n",
      "[SOLUTION] : The false statement is : Privacy problems in machine learning stem solely from the need for data to train models. Data collection for training is one of many privacy attack vectors in machine learning. There exist attacks on models and outputs; and naturally exposing data for test is a risk in itself. The first statement is true, an adversary performing a black-box attack needs much less resources and capabilities than a white-box adversary. This is much more dangerous, as the adversary only needs the ability to interact with the model. The last statement is also true because by providing poisoning inputs, the adversary gets to shape the boundaries of the model. Thus, she can carve this boundary to facilitate classification errors. In fact, you can understand a backdoor attack as a particular instance of an adversarial example.\n",
      "[QUESTION] : Tick the \\textbf{false} statement.\n",
      "[ ] Cryptographic primitives used in Bluetooth are provably secure.\n",
      "[ ] In WEP, authentication is done with the pre-shared keys.\n",
      "[ ] The security of Bluetooth 2.0 pairing is based on PIN.\n",
      "[ ] Due to memory limitations, dummy devices can share the same key with everyone.\n",
      "[SOLUTION] : \n",
      "The false statement is: Cryptographic primitives used in Bluetooth are provably secure. While Bluetooth does use cryptographic primitives for security, there have been vulnerabilities and weaknesses discovered in Bluetooth protocols over the years. It is important to regularly update and improve security measures in Bluetooth technology.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Tick the \\textbf{false} statement.\n",
      "[ ] Cryptographic primitives used in Bluetooth are provably secure.\n",
      "[ ] In WEP, authentication is done with the pre-shared keys.\n",
      "[ ] The security of Bluetooth 2.0 pairing is based on PIN.\n",
      "[ ] Due to memory limitations, dummy devices can share the same key with everyone.\n",
      "The false statement is: \n",
      "\n",
      "[ ] Cryptographic primitives used in Bluetooth are provably secure.\n",
      "--------------------------------Question 24--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : You heard about electrons and point charges in the lecture. Explain in your own words what an electron and what a point charge is and what their respective properties are. What is the difference and what are the similarities of electrons and point charges?\n",
      "\n",
      "[SOLUTION] : \n",
      "An electron is a subatomic particle that carries a negative electric charge. It is one of the fundamental components of an atom, located outside the nucleus in the electron cloud. Electrons have properties such as mass, charge, and spin.\n",
      "\n",
      "A point charge, on the other hand, is a theoretical concept used in physics to describe a particle with a specific amount of charge concentrated at a single point in space. Point charges do not have physical dimensions and are used to simplify calculations in electrostatics.\n",
      "\n",
      "The main similarity between electrons and point charges is that they both carry electric charge. However, the key difference is that electrons are actual subatomic particles with mass and volume, while point charges are idealized particles with no physical size. Both electrons and point charges interact through the electromagnetic force, influencing the motion of other charged particles in their vicinity.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "You heard about electrons and point charges in the lecture. Explain in your own words what an electron and what a point charge is and what their respective properties are. What is the difference and what are the similarities of electrons and point charges?\n",
      "\n",
      "An electron is a subatomic particle that carries a negative electric charge. It is one of the fundamental components of matter and is found in the outer regions of an atom. The electron is extremely small and has a mass that is almost 2000 times smaller than that of a proton or neutron.\n",
      "\n",
      "A point charge, on the other hand, is a theoretical concept used in physics to represent a particle or object with all its charge concentrated at a single point in space. This simplification is often used to analyze the behavior of electric fields and interactions between charged particles.\n",
      "\n",
      "The similarities between electrons and point charges lie in their fundamental property of carrying electric charge. Both electrons and point charges interact with other charged particles through the electromagnetic force. They can attract or repel each other based on the principles of electrostatics.\n",
      "\n",
      "The main difference between electrons and point charges is that electrons are actual physical particles with mass and other properties, whereas a point charge is a conceptual model that simplifies the analysis of electric fields and interactions. While electrons have a specific mass and are confined to the structure of an atom, a point charge is an idealized representation of a charged object with no physical size or structure.\n",
      "\n",
      "In summary, electrons are specific subatomic particles with negative charge and mass, while point charges are theoretical constructs used to simplify the analysis of electric interactions. Both share the property of carrying electric charge and interact with other charged particles through the electromagnetic force.\n",
      "--------------------------------Question 25--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : Consider the following context-free grammar \\(G\\) (where \\(\\text{S}\\) is the top-level symbol):\n",
      "\n",
      "\\(R_{01}: \\text{S} \\rightarrow \\text{NP VP}\\)\n",
      "\\(R_{02}: \\text{NP} \\rightarrow \\text{NP0}\\)\n",
      "\\(R_{03}: \\text{NP} \\rightarrow \\text{Det NP0}\\)\n",
      "\\(R_{04}: \\text{NP0} \\rightarrow \\text{N}\\)\n",
      "\\(R_{05}: \\text{NP0} \\rightarrow \\text{Adj N}\\)\n",
      "\\(R_{06}: \\text{NP0} \\rightarrow \\text{NP0 PNP}\\)\n",
      "\\(R_{07}: \\text{VP} \\rightarrow \\text{V}\\)\n",
      "\\(R_{08}: \\text{VP} \\rightarrow \\text{V NP}\\)\n",
      "\\(R_{09}: \\text{VP} \\rightarrow \\text{V NP PNP}\\)\n",
      "\\(R_{10}: \\text{PNP} \\rightarrow \\text{Prep NP}\\)\n",
      "\n",
      "complemented by the lexicon \\(L\\):\n",
      "a        : Det\n",
      "blue     : Adj, N\n",
      "drink    : N, V\n",
      "drinks   : N, V\n",
      "friends  : N\n",
      "from     : Prep\n",
      "gave     : V\n",
      "letter   : N\n",
      "my       : Det\n",
      "neighbor : N\n",
      "nice     : Adj, N\n",
      "of       : Prep\n",
      "postman  : N\n",
      "ran      : V\n",
      "the      : Det\n",
      "to       : PrepHow many (syntactic and lexical) rules does the extended Chomsky Normal Form grammar equivalent to \\(G\\) contain, if produced as described in the parsing lecture?\n",
      "[ ] the grammar \\(G\\) cannot be converted to extended Chomsky Normal Form\n",
      "[ ] the grammar \\(G\\) already is in extended Chomsky Normal Form\n",
      "[ ] 11 rules\n",
      "[ ] 31 rules\n",
      "[ ] 48 rules\n",
      "[SOLUTION] : \n",
      "To convert the given context-free grammar \\(G\\) to Extended Chomsky Normal Form (ECNF), we need to eliminate the rules with more than two symbols on the right-hand side. Here is the breakdown of the rules in the given grammar:\n",
      "\n",
      "- \\(R_{01}\\) has 2 symbols on the right-hand side\n",
      "- \\(R_{02}\\) has 2 symbols on the right-hand side\n",
      "- \\(R_{03}\\) has 3 symbols on the right-hand side\n",
      "- \\(R_{04}\\) has 1 symbol on the right-hand side\n",
      "- \\(R_{05}\\) has 2 symbols on the right-hand side\n",
      "- \\(R_{06}\\) has 3 symbols on the right-hand side\n",
      "- \\(R_{07}\\) has 1 symbol on the right-hand side\n",
      "- \\(R_{08}\\) has 2 symbols on the right-hand side\n",
      "- \\(R_{09}\\) has 3 symbols on the right-hand side\n",
      "- \\(R_{10}\\) has 2 symbols on the right-hand side\n",
      "\n",
      "Therefore, the total number of rules in the given grammar is 10. To convert this grammar to ECNF, we need to add additional rules for unit productions and rules with more than two symbols on the right-hand side. The exact number of rules in the ECNF equivalent grammar will depend on the specific transformations applied during the conversion process. The correct answer is not provided in the options given.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Consider the following context-free grammar \\(G\\) (where \\(\\text{S}\\) is the top-level symbol):\n",
      "\n",
      "\\(R_{01}: \\text{S} \\rightarrow \\text{NP VP}\\)\n",
      "\\(R_{02}: \\text{NP} \\rightarrow \\text{NP0}\\)\n",
      "\\(R_{03}: \\text{NP} \\rightarrow \\text{Det NP0}\\)\n",
      "\\(R_{04}: \\text{NP0} \\rightarrow \\text{N}\\)\n",
      "\\(R_{05}: \\text{NP0} \\rightarrow \\text{Adj N}\\)\n",
      "\\(R_{06}: \\text{NP0} \\rightarrow \\text{NP0 PNP}\\)\n",
      "\\(R_{07}: \\text{VP} \\rightarrow \\text{V}\\)\n",
      "\\(R_{08}: \\text{VP} \\rightarrow \\text{V NP}\\)\n",
      "\\(R_{09}: \\text{VP} \\rightarrow \\text{V NP PNP}\\)\n",
      "\\(R_{10}: \\text{PNP} \\rightarrow \\text{Prep NP}\\)\n",
      "\n",
      "complemented by the lexicon \\(L\\):\n",
      "a        : Det\n",
      "blue     : Adj, N\n",
      "drink    : N, V\n",
      "drinks   : N, V\n",
      "friends  : N\n",
      "from     : Prep\n",
      "gave     : V\n",
      "letter   : N\n",
      "my       : Det\n",
      "neighbor : N\n",
      "nice     : Adj, N\n",
      "of       : Prep\n",
      "postman  : N\n",
      "ran      : V\n",
      "the      : Det\n",
      "to       : PrepHow many (syntactic and lexical) rules does the extended Chomsky Normal Form grammar equivalent to \\(G\\) contain, if produced as described in the parsing lecture?\n",
      "[ ] the grammar \\(G\\) cannot be converted to extended Chomsky Normal Form\n",
      "[ ] the grammar \\(G\\) already is in extended Chomsky Normal Form\n",
      "[ ] 11 rules\n",
      "[ ] 31 rules\n",
      "[ ] 48 rules\n",
      "To convert a context-free grammar to Chomsky Normal Form (CNF), we need to ensure that each rule is in one of the following forms:\n",
      "\n",
      "1. \\(A \\rightarrow BC\\) where \\(A, B, C\\) are non-terminal symbols\n",
      "2. \\(A \\rightarrow a\\) where \\(A\\) is a non-terminal symbol and \\(a\\) is a terminal symbol\n",
      "3. \\(S \\rightarrow \\varepsilon\\) where \\(S\\) is the start symbol and \\(\\varepsilon\\) is the empty string\n",
      "\n",
      "Given the context-free grammar \\(G\\) and the lexicon \\(L\\), let's convert it to Chomsky Normal Form:\n",
      "\n",
      "1. Introduce new non-terminal symbols for terminals:\n",
      "   - \\(Noun \\rightarrow \\text{blue} | \\text{friends} | \\text{letter} | \\text{neighbor} | \\text{postman}\\)\n",
      "   - \\(Verb \\rightarrow \\text{drink} | \\text{drinks} | \\text{gave} | \\text{ran}\\)\n",
      "   - \\(Adjective \\rightarrow \\text{blue} | \\text{nice}\\)\n",
      "   - \\(Preposition \\rightarrow \\text{from} | \\text{of} | \\text{to}\\)\n",
      "   - \\(Determiner \\rightarrow \\text{a} | \\text{my} | \\text{the}\\)\n",
      "\n",
      "2. Rewrite the grammar rules in CNF:\n",
      "   - \\(R_{01}: \\text{S} \\rightarrow \\text{NP VP}\\)\n",
      "   - \\(R_{02}: \\text{NP} \\rightarrow \\text{NP0}\\)\n",
      "   - \\(R_{03}: \\text{NP} \\rightarrow \\text{Det NP0}\\)\n",
      "   - \\(R_{04}: \\text{NP0} \\rightarrow \\text{Noun}\\)\n",
      "   - \\(R_{05}: \\text{NP0} \\rightarrow \\text{Adjective Noun}\\)\n",
      "   - \\(R_{06}: \\text{NP0} \\rightarrow \\text{NP0 PNP}\\)\n",
      "   - \\(R_{07}: \\text{VP} \\rightarrow \\text{Verb}\\)\n",
      "   - \\(R_{08}: \\text{VP} \\rightarrow \\text{Verb NP}\\)\n",
      "   - \\(R_{09}: \\text{VP} \\rightarrow \\text{Verb NP PNP}\\)\n",
      "   - \\(R_{10}: \\text{PNP} \\rightarrow \\text{Preposition NP}\\)\n",
      "\n",
      "After converting the grammar to CNF, we have the following rules:\n",
      "\n",
      "- 10 original rules\n",
      "- 5 rules for introducing new non-terminal symbols for terminals\n",
      "- 10 rules for rewriting the original grammar rules in CNF\n",
      "\n",
      "Therefore, the total number of rules in the extended Chomsky Normal Form grammar equivalent to \\(G\\) is \\(10 + 5 + 10 = 25\\). \n",
      "\n",
      "Hence, the correct option is:\n",
      "[ ] 31 rules\n",
      "--------------------------------Question 26--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : Determine the lines of current $y = y(x)$ and the acceleration $\\vec{a}(x,y)$ for a stationary bidimensional flow described by the velocity field :\n",
      "\\begin{equation*} \n",
      "{\\bf v} = (\\frac{{v_0 }}{l})(x\\vec e_x  - y\\vec e_y)~.\n",
      "\\end{equation*}\n",
      "\n",
      "[SOLUTION] : \n",
      "To determine the lines of current, we need to find the streamlines of the flow. Streamlines are defined by the equation $\\frac{dx}{v_x} = \\frac{dy}{v_y}$, where $v_x$ and $v_y$ are the components of the velocity field.\n",
      "\n",
      "Given the velocity field ${\\bf v} = (\\frac{{v_0 }}{l})(x\\vec e_x  - y\\vec e_y)$, we have $v_x = \\frac{{v_0 }}{l}x$ and $v_y = -\\frac{{v_0 }}{l}y$.\n",
      "\n",
      "Therefore, the equation for the streamlines is:\n",
      "\\begin{equation*} \n",
      "\\frac{dx}{\\frac{{v_0 }}{l}x} = \\frac{dy}{-\\frac{{v_0 }}{l}y}\n",
      "\\end{equation*}\n",
      "\n",
      "Integrating both sides, we get:\n",
      "\\begin{equation*} \n",
      "\\ln|x| = -\\ln|y| + C\n",
      "\\end{equation*}\n",
      "\n",
      "Solving for y, we get the equation for the lines of current $y(x)$.\n",
      "\n",
      "To determine the acceleration $\\vec{a}(x,y)$, we use the acceleration formula in fluid dynamics which is given by:\n",
      "\\begin{equation*} \n",
      "\\vec{a} = \\frac{D\\vec{v}}{Dt} = \\frac{\\partial \\vec{v}}{\\partial t} + (\\vec{v} \\cdot \\nabla) \\vec{v}\n",
      "\\end{equation*}\n",
      "\n",
      "Given that the flow is stationary (time-independent), the first term $\\frac{\\partial \\vec{v}}{\\partial t}$ is zero. Therefore, we only need to calculate the convective acceleration term $(\\vec{v} \\cdot \\nabla) \\vec{v$.\n",
      "\n",
      "Calculating the convective acceleration term, we get:\n",
      "\\begin{equation*} \n",
      "(\\vec{v} \\cdot \\nabla) \\vec{v} = (v_x \\frac{\\partial}{\\partial x} + v_y \\frac{\\partial}{\\partial y})\\vec{v}\n",
      "\\end{equation*}\n",
      "\n",
      "Substitute the expressions for $v_x$ and $v_y$ in terms of x and y, and simplify to get the acceleration $\\vec{a}(x,y)$.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Determine the lines of current $y = y(x)$ and the acceleration $\\vec{a}(x,y)$ for a stationary bidimensional flow described by the velocity field :\n",
      "\\begin{equation*} \n",
      "{\\bf v} = (\\frac{{v_0 }}{l})(x\\vec e_x  - y\\vec e_y)~.\n",
      "\\end{equation*}\n",
      "\n",
      "To determine the streamlines (lines of current) for the stationary bidimensional flow, we need to find the equation of the streamlines by setting the velocity vector field equal to the tangent vector to the streamlines. \n",
      "\n",
      "The velocity field is given as ${\\bf v} = \\left(\\frac{{v_0 }}{l}\\right)(x\\vec e_x  - y\\vec e_y)$.\n",
      "\n",
      "The equation of the streamlines is given by $\\frac{{dx}}{{v_x}} = \\frac{{dy}}{{v_y}}$, where $v_x$ and $v_y$ are the components of velocity in the $x$ and $y$ directions respectively.\n",
      "\n",
      "In this case, $v_x = \\frac{{v_0 }}{l}x$ and $v_y = -\\frac{{v_0 }}{l}y$.\n",
      "\n",
      "Therefore, the equation of the streamlines is:\n",
      "\\begin{align*} \n",
      "\\frac{{dx}}{{\\frac{{v_0 }}{l}x}} &= \\frac{{dy}}{{-\\frac{{v_0 }}{l}y}} \\\\\n",
      "\\frac{{dx}}{{x}} &= -\\frac{{dy}}{{y}} \\\\\n",
      "\\ln|x| &= -\\ln|y| + C \\\\\n",
      "\\ln\\left|\\frac{{x}}{y}\\right| &= C \\\\\n",
      "\\frac{{x}}{y} &= e^C\n",
      "\\end{align*}\n",
      "\n",
      "So, the equation of the streamlines is $\\frac{{x}}{y} = C$, where $C$ is a constant. This represents a family of hyperbolic curves.\n",
      "\n",
      "Next, let's find the acceleration vector $\\vec{a}(x,y)$ for this flow. The acceleration is given by the material derivative of the velocity field with respect to time, which can be expressed as:\n",
      "\n",
      "\\begin{align*} \n",
      "\\vec{a}(x,y) &= \\frac{{D\\vec{v}}}{{Dt}} \\\\\n",
      "&= \\frac{{\\partial\\vec{v}}}{{\\partial t}} + \\left(\\vec{v}\\cdot\\nabla\\right)\\vec{v} \\\\\n",
      "&= \\frac{{\\partial\\vec{v}}}{{\\partial t}} + \\left(v_x\\frac{{\\partial}}{{\\partial x}} + v_y\\frac{{\\partial}}{{\\partial y}}\\right)\\vec{v}\n",
      "\\end{align*}\n",
      "\n",
      "Since the flow is stationary (time-independent), the first term on the right-hand side is zero. We can now calculate the acceleration vector using the given velocity field. \n",
      "\n",
      "Let's calculate the terms in the acceleration vector $\\vec{a}(x,y)$ one by one.\n",
      "--------------------------------Question 27--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : Implement a uniform reliable broadcast algorithm without using any failure detector, i.e., using only BestEffort-Broadcast(BEB).\n",
      "[SOLUTION] : \n",
      "One way to implement a uniform reliable broadcast algorithm without using any failure detector is to use the following approach:\n",
      "\n",
      "1. Let `n` be the number of processes in the system.\n",
      "2. Each process `p_i` maintains a set `delivered_i` to keep track of messages it has delivered.\n",
      "3. When a process `p_i` wants to broadcast a message `m`, it first sends the message using BEB to all other processes.\n",
      "4. Upon receiving a message `m` from process `p_j`, process `p_i` delivers `m` to its application layer if `m` has not been delivered before and adds `m` to `delivered_i`.\n",
      "5. Each process `p_i` periodically piggybacks its `delivered_i` set in its BEB messages to all other processes.\n",
      "6. Upon receiving a message with piggybacked delivered set from process `p_i`, process `p_j` checks if all messages in `delivered_i` have been delivered. If not, process `p_j` requests missing messages from `p_i`.\n",
      "7. Process `p_i` re-broadcasts missing messages to process `p_j` upon receiving a request.\n",
      "\n",
      "This way, by piggybacking delivered sets in BEB messages and requesting missing messages, each process can ensure that all messages are reliably delivered to all processes in the system without using any failure detector.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Implement a uniform reliable broadcast algorithm without using any failure detector, i.e., using only BestEffort-Broadcast(BEB).\n",
      "To implement a uniform reliable broadcast without using any failure detector, we can leverage the BestEffort-Broadcast (BEB) primitive along with additional acknowledgments to achieve reliability. Here is a step-by-step guide to implementing a uniform reliable broadcast algorithm using BEB:\n",
      "\n",
      "1. **Initialization**:\n",
      "   - Each process in the system maintains a list of delivered messages and a list of pending messages.\n",
      "\n",
      "2. **Broadcast**:\n",
      "   - When a process wants to broadcast a message, it first sends the message using BEB to all other processes in the system.\n",
      "   - Upon receiving a message from BEB, a process appends the message to its pending list.\n",
      "\n",
      "3. **Deliver**:\n",
      "   - When a process receives a message through BEB, it checks if the message has already been delivered. If not, it delivers the message to the application layer.\n",
      "   - After delivering the message, the process broadcasts an acknowledgment using BEB to all other processes.\n",
      "\n",
      "4. **Acknowledgment**:\n",
      "   - Upon receiving an acknowledgment from BEB, a process marks the message as delivered in its list of pending messages.\n",
      "   - If the acknowledgment is for a message that was already delivered, the process ignores the acknowledgment.\n",
      "\n",
      "5. **Reliability**:\n",
      "   - To ensure reliability, a process waits for acknowledgments for each message it broadcasts before marking it as delivered. This way, if a process fails before sending an acknowledgment, the message will be rebroadcasted by the sender.\n",
      "\n",
      "By using this algorithm, we can achieve reliable broadcast without relying on any failure detector. The acknowledgment mechanism ensures that messages are reliably delivered to all correct processes in the system.\n",
      "--------------------------------Question 28--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Considering a sequence of n tokens, the computational complexity of the masked attention mechanism in BERT language models is: (select the smallest correct complexity)\n",
      "[ ] O(n^3)\n",
      "[ ] O(nlog(n))\n",
      "[ ] O(n)\n",
      "[ ] O(n^(1/2))\n",
      "[ ] O(n^2)\n",
      "[SOLUTION] : Masked attention is quadratic in the sequence length n because it computes the attention between all pairs of tokens, therefore O(n^2).\n",
      "[QUESTION] : Tick the false assertion. Bluetooth ... \n",
      "[ ] uses a stream cipher for encryption.\n",
      "[ ] has secure integrity protection for secure communication.\n",
      "[ ] has devices which use the same secret key with any other device.uses the SAFER+ block cipher in a one-way mode.\n",
      "[SOLUTION] : The false assertion is : has secure integrity protection for secure communication. Bluetooth is indeed a secure protocol which relies on the E0 stream cipher for privacy. In Bluetooth, the encryption process involves the Long Term Key (LTK), which is a secret key shared and stored by both connected devices. Bluetooth implements confidentiality, authentication and key derivation with custom algorithms based on a SAFER+ block cipher\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : For two $\\ell$-bit numbers, the \\textbf{tightest} complexity to compute their gcd is\n",
      "[ ] $\\mathcal{O}(2^{\\ell})$.\n",
      "[ ] $\\mathcal{O}(\\ell^3)$.\n",
      "[ ] $\\mathcal{O}(\\ell^2)$.\n",
      "[ ] $\\mathcal{O}(\\log{\\ell}^2)$.\n",
      "[SOLUTION] : \n",
      "The tightest complexity to compute the gcd of two $\\ell$-bit numbers is $\\mathcal{O}(\\ell^3)$. This is because algorithms like Euclid's algorithm have a complexity of $\\mathcal{O}(\\log{ab})$ where $a$ and $b$ are the input numbers. Since the input numbers have $\\ell$ bits each, the complexity can be written as $\\mathcal{O}(\\log{2^{\\ell}\\cdot 2^{\\ell}}) = \\mathcal{O}(\\log{2^{2\\ell}}) = \\mathcal{O}(2\\ell) = \\mathcal{O}(\\ell)$. So, the tightest complexity is $\\mathcal{O}(\\ell^3)$.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "For two $\\ell$-bit numbers, the \\textbf{tightest} complexity to compute their gcd is\n",
      "[ ] $\\mathcal{O}(2^{\\ell})$.\n",
      "[ ] $\\mathcal{O}(\\ell^3)$.\n",
      "[ ] $\\mathcal{O}(\\ell^2)$.\n",
      "[ ] $\\mathcal{O}(\\log{\\ell}^2)$.\n",
      "To compute the gcd of two $\\ell$-bit numbers, we can use the Euclidean algorithm. The Euclidean algorithm has a complexity of $\\mathcal{O}(\\log{\\min(a, b)})$ where $a$ and $b$ are the two input numbers.\n",
      "\n",
      "In this case, the input numbers are $\\ell$-bit numbers. Since the numbers are $\\ell$-bit, the minimum of the two numbers is at most $2^{\\ell}$.\n",
      "\n",
      "Therefore, the tightest complexity to compute their gcd would be $\\mathcal{O}(\\log{2^{\\ell}}) = \\mathcal{O}(\\ell)$. \n",
      "\n",
      "So, the correct option is:\n",
      "[ ] $\\mathcal{O}(\\ell)$.\n",
      "--------------------------------Question 29--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : In an automated email router of a company, we want to make the distinction between three kind of\n",
      "emails: technical (about computers), financial, and the rest ('irrelevant'). For this we plan to use a\n",
      "Naive Bayes approach.\n",
      "What is the main assumption made by Naive Bayes classifiers? Why is it 'Naive'?\n",
      "\n",
      "We will consider the following three messages:\n",
      "\n",
      "The Dow industrials tumbled 120.54 to 10924.74, hurt by GM's sales forecast\n",
      "and two economic reports. Oil rose to $71.92.\n",
      "\n",
      "BitTorrent Inc. is boosting its network capacity as it prepares to become a centralized hub for legal video content. In May, BitTorrent announced a deal with\n",
      "Warner Brothers to distribute its TV and movie content via the BT platform. It\n",
      "has now lined up IP transit for streaming videos at a few gigabits per second\n",
      "\n",
      "Intel will sell its XScale PXAxxx applications processor and 3G baseband processor businesses to Marvell for $600 million, plus existing liabilities. The deal\n",
      "could make Marvell the top supplier of 3G and later smartphone processors, and\n",
      "enable Intel to focus on its core x86 and wireless LAN chipset businesses, the\n",
      "companies say.\n",
      "\n",
      "Suppose we have collected the following statistics $3^{3}$ about the word frequencies within the corresponding classes, where '0.00...' stands for some very small value:\n",
      "\\begin{center}\n",
      "\\begin{tabular}{|c|c|c|c|c|c|c|c|}\n",
      "\\hline\n",
      " & technical & financial & irrelevant &  & technical & financial & irrelevan \\\\\n",
      "\\hline\n",
      "$\\$<$ number $>$ & 0.01 & 0.07 & 0.05 & deal & 0.01 & 0.02 & $0.00 \\ldots$ \\\\\n",
      "\\hline\n",
      "Dow & $0.00 \\ldots$ & 0.08 & $0.00 \\ldots$ & forecast & $0.00 \\ldots$ & 0.03 & 0.01 \\\\\n",
      "\\hline\n",
      "GM & $0.00 \\ldots$ & 0.03 & $0.00 \\ldots$ & gigabit & 0.03 & $0.00 \\ldots$ & $0.00 \\ldots$ \\\\\n",
      "\\hline\n",
      "IP & 0.03 & $0.00 \\ldots$ & $0.00 \\ldots$ & hub & 0.06 & $0.00 \\ldots$ & 0.01 \\\\\n",
      "\\hline\n",
      "Intel & 0.02 & 0.02 & $0.00 \\ldots$ & network & 0.04 & 0.01 & $0.00 \\ldots$ \\\\\n",
      "\\hline\n",
      "business & 0.01 & 0.07 & 0.04 & processor & 0.07 & 0.01 & $0.00 \\ldots$ \\\\\n",
      "\\hline\n",
      "capacity & 0.01 & $0.00 \\ldots$ & $0.00 \\ldots$ & smartphone & 0.04 & 0.04 & 0.01 \\\\\n",
      "\\hline\n",
      "chipset & 0.04 & 0.01 & $0.00 \\ldots$ & wireless & 0.02 & 0.01 & $0.00 \\ldots$ \\\\\n",
      "\\hline\n",
      "company & 0.01 & 0.04 & 0.05 & sen & re & . & . \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{center}\n",
      "\n",
      "We now want to specifically focus on the processing of compounds such as 'network capacity' in\n",
      "the second text.\n",
      "\n",
      "Outline how you would build a pre-processor for compound words\n",
      "[SOLUTION] : \n",
      "A pre-processor for compound words in text data involves breaking down the compound words into their individual components to improve the accuracy of the Naive Bayes classifier. Here's an outline of how you can build a pre-processor for compound words:\n",
      "\n",
      "1. Tokenization: Tokenize the text data into individual words using whitespace or punctuation as delimiters.\n",
      "\n",
      "2. Identify Compound Words: Look for patterns in the text data that indicate compound words, such as words separated by spaces or hyphens.\n",
      "\n",
      "3. Extract Components: For compound words identified, extract the individual components by splitting the compound word based on the identified pattern.\n",
      "\n",
      "4. Update Word Frequencies: Update the word frequency statistics for the individual components of the compound words in the corresponding classes.\n",
      "\n",
      "5. Remove Compound Words: Replace the compound words in the text data with their individual components to create a new text dataset.\n",
      "\n",
      "By following these steps, you can preprocess the text data to handle compound words effectively in a Naive Bayes classifier. This approach helps improve the accuracy of the classifier by treating compound words as separate features rather than single entities.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "In an automated email router of a company, we want to make the distinction between three kind of\n",
      "emails: technical (about computers), financial, and the rest ('irrelevant'). For this we plan to use a\n",
      "Naive Bayes approach.\n",
      "What is the main assumption made by Naive Bayes classifiers? Why is it 'Naive'?\n",
      "\n",
      "We will consider the following three messages:\n",
      "\n",
      "The Dow industrials tumbled 120.54 to 10924.74, hurt by GM's sales forecast\n",
      "and two economic reports. Oil rose to $71.92.\n",
      "\n",
      "BitTorrent Inc. is boosting its network capacity as it prepares to become a centralized hub for legal video content. In May, BitTorrent announced a deal with\n",
      "Warner Brothers to distribute its TV and movie content via the BT platform. It\n",
      "has now lined up IP transit for streaming videos at a few gigabits per second\n",
      "\n",
      "Intel will sell its XScale PXAxxx applications processor and 3G baseband processor businesses to Marvell for $600 million, plus existing liabilities. The deal\n",
      "could make Marvell the top supplier of 3G and later smartphone processors, and\n",
      "enable Intel to focus on its core x86 and wireless LAN chipset businesses, the\n",
      "companies say.\n",
      "\n",
      "Suppose we have collected the following statistics $3^{3}$ about the word frequencies within the corresponding classes, where '0.00...' stands for some very small value:\n",
      "\\begin{center}\n",
      "\\begin{tabular}{|c|c|c|c|c|c|c|c|}\n",
      "\\hline\n",
      " & technical & financial & irrelevant &  & technical & financial & irrelevan \\\\\n",
      "\\hline\n",
      "$\\$<$ number $>$ & 0.01 & 0.07 & 0.05 & deal & 0.01 & 0.02 & $0.00 \\ldots$ \\\\\n",
      "\\hline\n",
      "Dow & $0.00 \\ldots$ & 0.08 & $0.00 \\ldots$ & forecast & $0.00 \\ldots$ & 0.03 & 0.01 \\\\\n",
      "\\hline\n",
      "GM & $0.00 \\ldots$ & 0.03 & $0.00 \\ldots$ & gigabit & 0.03 & $0.00 \\ldots$ & $0.00 \\ldots$ \\\\\n",
      "\\hline\n",
      "IP & 0.03 & $0.00 \\ldots$ & $0.00 \\ldots$ & hub & 0.06 & $0.00 \\ldots$ & 0.01 \\\\\n",
      "\\hline\n",
      "Intel & 0.02 & 0.02 & $0.00 \\ldots$ & network & 0.04 & 0.01 & $0.00 \\ldots$ \\\\\n",
      "\\hline\n",
      "business & 0.01 & 0.07 & 0.04 & processor & 0.07 & 0.01 & $0.00 \\ldots$ \\\\\n",
      "\\hline\n",
      "capacity & 0.01 & $0.00 \\ldots$ & $0.00 \\ldots$ & smartphone & 0.04 & 0.04 & 0.01 \\\\\n",
      "\\hline\n",
      "chipset & 0.04 & 0.01 & $0.00 \\ldots$ & wireless & 0.02 & 0.01 & $0.00 \\ldots$ \\\\\n",
      "\\hline\n",
      "company & 0.01 & 0.04 & 0.05 & sen & re & . & . \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{center}\n",
      "\n",
      "We now want to specifically focus on the processing of compounds such as 'network capacity' in\n",
      "the second text.\n",
      "\n",
      "Outline how you would build a pre-processor for compound words\n",
      "The main assumption made by Naive Bayes classifiers is that the features are conditionally independent given the class label. This assumption is 'naive' because it simplifies the model by assuming that the presence of a particular feature in a class is independent of the presence of other features.\n",
      "\n",
      "To build a pre-processor for compound words like 'network capacity' in the text, you can follow these steps:\n",
      "\n",
      "1. Tokenization: Break down the text into individual words or tokens. This step is important to separate compound words into their constituent parts.\n",
      "\n",
      "2. Identify Compound Words: Look for patterns in the tokens that indicate compound words. In the given example, the pattern 'word1 word2' can be a clue that the two words together form a compound word.\n",
      "\n",
      "3. Merge Compound Words: Once compound words are identified, merge them into a single token to represent the compound concept. For example, 'network capacity' can be merged into a single token 'network_capacity'.\n",
      "\n",
      "4. Update Word Frequencies: Update the word frequency statistics for the compound words based on the merged tokens. This will ensure that the Naive Bayes classifier can learn the association between the compound words and the corresponding class labels.\n",
      "\n",
      "5. Feature Extraction: Use the pre-processed tokens, including the merged compound words, as features for training the Naive Bayes classifier. This will help the classifier learn how different words and compound words are associated with the specific classes.\n",
      "\n",
      "By building a pre-processor that specifically handles compound words like 'network capacity', you can improve the accuracy of the Naive Bayes classifier in distinguishing between technical, financial, and irrelevant emails based on the content of the messages.\n",
      "--------------------------------Question 30--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Tick the \\textbf{false} statement : \n",
      "[ ] As a defender of a machine learning model you should be more worried about black-box effective attacks than white-box effective attacks.\n",
      "[ ] Privacy problems in machine learning stem solely from the need for data to train models.\n",
      "[ ] Poisoning attacks can be used to increase vulnerability to adversarial examples.\n",
      "[SOLUTION] : The false statement is : Privacy problems in machine learning stem solely from the need for data to train models. Data collection for training is one of many privacy attack vectors in machine learning. There exist attacks on models and outputs; and naturally exposing data for test is a risk in itself. The first statement is true, an adversary performing a black-box attack needs much less resources and capabilities than a white-box adversary. This is much more dangerous, as the adversary only needs the ability to interact with the model. The last statement is also true because by providing poisoning inputs, the adversary gets to shape the boundaries of the model. Thus, she can carve this boundary to facilitate classification errors. In fact, you can understand a backdoor attack as a particular instance of an adversarial example.\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : Tick the \\textit{wrong} assertion.\n",
      "[ ] If $\\Big(\\frac{b}{n}\\Big)=+$1 for $b \\in \\mathbb{Z}_n^* $, then $b$ is a quadratic residue.\n",
      "[ ] If $\\Big(\\frac{b}{p}\\Big)=+$1 for $b \\in \\mathbb{Z}_p^* $, then $b$ is a quadratic residue, where $p$ is prime.\n",
      "[ ] If $b$ is a quadratic residue for $b \\in \\mathbb{Z}_n^* $, then $\\Big(\\frac{b}{n}\\Big)=+1$.\n",
      "[ ] If $b$ is a quadratic residue for $b \\in \\mathbb{Z}_p^* $, then $\\Big(\\frac{b}{p}\\Big)=+1$, where $p$ is prime.\n",
      "[SOLUTION] : \n",
      "The wrong assertion is: If $b$ is a quadratic residue for $b \\in \\mathbb{Z}_n^*$, then $\\Big(\\frac{b}{n}\\Big)=+1$. This is incorrect because if $b$ is a quadratic residue modulo $n$, then $\\Big(\\frac{b}{n}\\Big)$ can be either +1 or -1, depending on the specific value of $b$ and $n$.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Tick the \\textit{wrong} assertion.\n",
      "[ ] If $\\Big(\\frac{b}{n}\\Big)=+$1 for $b \\in \\mathbb{Z}_n^* $, then $b$ is a quadratic residue.\n",
      "[ ] If $\\Big(\\frac{b}{p}\\Big)=+$1 for $b \\in \\mathbb{Z}_p^* $, then $b$ is a quadratic residue, where $p$ is prime.\n",
      "[ ] If $b$ is a quadratic residue for $b \\in \\mathbb{Z}_n^* $, then $\\Big(\\frac{b}{n}\\Big)=+1$.\n",
      "[ ] If $b$ is a quadratic residue for $b \\in \\mathbb{Z}_p^* $, then $\\Big(\\frac{b}{p}\\Big)=+1$, where $p$ is prime.\n",
      "The wrong assertion is:\n",
      "\n",
      "[ ] If $b$ is a quadratic residue for $b \\in \\mathbb{Z}_n^* $, then $\\Big(\\frac{b}{n}\\Big)=+1$. \n",
      "\n",
      "This is incorrect because the Legendre symbol is defined for odd primes $n$, not for all integers $n$.\n",
      "--------------------------------Question 31--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Tick the false assertion. Bluetooth ... \n",
      "[ ] uses a stream cipher for encryption.\n",
      "[ ] has secure integrity protection for secure communication.\n",
      "[ ] has devices which use the same secret key with any other device.uses the SAFER+ block cipher in a one-way mode.\n",
      "[SOLUTION] : The false assertion is : has secure integrity protection for secure communication. Bluetooth is indeed a secure protocol which relies on the E0 stream cipher for privacy. In Bluetooth, the encryption process involves the Long Term Key (LTK), which is a secret key shared and stored by both connected devices. Bluetooth implements confidentiality, authentication and key derivation with custom algorithms based on a SAFER+ block cipher\n",
      "[QUESTION] : Considering a sequence of n tokens, the computational complexity of the masked attention mechanism in BERT language models is: (select the smallest correct complexity)\n",
      "[ ] O(n^3)\n",
      "[ ] O(nlog(n))\n",
      "[ ] O(n)\n",
      "[ ] O(n^(1/2))\n",
      "[ ] O(n^2)\n",
      "[SOLUTION] : Masked attention is quadratic in the sequence length n because it computes the attention between all pairs of tokens, therefore O(n^2).\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Let $E$ be an elliptic curve. Solving which of the following problems would help you to break Elliptic Curve Diffie-Hellman (ECDH) over $E$?\n",
      "[ ] Let $P,R \\in E$. Given $P$ and $P+R$, compute $R$.\n",
      "[ ] Let $P,Q \\in E$. Given $P$ and $Q$, compute the product between $P$ and $Q$, i.e., $P \\times Q$.\n",
      "[ ] Let $P \\in E$ and $\\ell \\in \\mathbb{N}$. Given $P$ and $\\ell P$, compute $\\ell$.\n",
      "[ ] Find a point which is not on the curve $E$.\n",
      "[SOLUTION] : \n",
      "Finding a point which is not on the curve E would help break Elliptic Curve Diffie-Hellman (ECDH) over E. This is because if an attacker can find a point not on the curve, they can potentially create a trapdoor and break the security of the ECDH key exchange protocol. The other options do not directly relate to breaking ECDH over E.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Let $E$ be an elliptic curve. Solving which of the following problems would help you to break Elliptic Curve Diffie-Hellman (ECDH) over $E$?\n",
      "[ ] Let $P,R \\in E$. Given $P$ and $P+R$, compute $R$.\n",
      "[ ] Let $P,Q \\in E$. Given $P$ and $Q$, compute the product between $P$ and $Q$, i.e., $P \\times Q$.\n",
      "[ ] Let $P \\in E$ and $\\ell \\in \\mathbb{N}$. Given $P$ and $\\ell P$, compute $\\ell$.\n",
      "[ ] Find a point which is not on the curve $E$.\n",
      "The problem that would help break Elliptic Curve Diffie-Hellman (ECDH) over $E$ is:\n",
      "[ ] Let $P \\in E$ and $\\ell \\in \\mathbb{N}$. Given $P$ and $\\ell P$, compute $\\ell$.\n",
      "\n",
      "This problem would allow an attacker to calculate the discrete logarithm, which is the key operation underlying the security of ECDH. If an attacker can efficiently compute the discrete logarithm, they can break the security of the ECDH scheme.\n",
      "--------------------------------Question 32--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : A rigid and homogeneous horizontal rod of mass M, of length L, of negligible thickness e, i.e. e << L, is rotating in a horizontal plane around the vertical axis $C e_3$ at angular velocity $\\Omega=\\dot{\\psioldsymbol{e}3$. The moment of inertia of the rod with respect to the vertical principal axis that contains its centre of mass G is $I{G,3}=\frac1{12}ML^{2}$. Let C be the point of contact between the extremity of the rod and the rotation axis, and P the point at the other extremity. The unit vector $e_1$ is oriented along the rod and the vector $e_2$ is orthogonal to $e_1$. The unit vectors $e_1$, $e_2$ and $e_3$, attached to the rod at point C, are the principal axis frame of the rod. We consider that there is no friction and we do not take explicitly into account the influence of the gravitational field. Give the expression of the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis of rotation $C e_3$ in terms of the scalar quantities M and L.\n",
      "[SOLUTION] : Applying the Huygens-Steiner theorem, we determine the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis $C e_3$ taking into account the fact that d = L/2 is the distance separating points G and C and that $I_{G,3}=\frac1{12}ML^{2}$,\n",
      "ight)^2=\frac{1}{12}ML^2+\frac{1}{4}ML^2=\frac{1}{3}ML^2$\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : Determine the relation between pressure and height for a gas for : $T=T(z)$ but no exchange of heat in the gas (adiabatic atmosphere).\n",
      "Estimate the pressure at an altitude of 10 km. Consider the atmosphere as an ideal, biatomic gas of molecular mass 28.\n",
      "\n",
      "N.A.: R = 8.2 J/mol K ; T$_0$=293 K.\\\\\n",
      "\n",
      "[SOLUTION] : \n",
      "For an adiabatic atmosphere, the relation between pressure and height can be expressed using the ideal gas law and the adiabatic process equation. The ideal gas law is given by:\n",
      "\n",
      "\\[ PV = nRT \\]\n",
      "\n",
      "Where P is the pressure, V is the volume, n is the number of moles, R is the gas constant, and T is the temperature.\n",
      "\n",
      "For an adiabatic process, we have the relation:\n",
      "\n",
      "\\[ PV^\\gamma = \\text{constant} \\]\n",
      "\n",
      "Where γ is the ratio of specific heats.\n",
      "\n",
      "For a biatomic gas, γ = 7/5.\n",
      "\n",
      "Given that T = T(z), we can express T as a function of z by using the temperature lapse rate:\n",
      "\n",
      "\\[ \\frac{dT}{dz} = - \\frac{g}{C_p} \\]\n",
      "\n",
      "Where g is the acceleration due to gravity and Cp is the specific heat at constant pressure.\n",
      "\n",
      "Integrating the above equation, we get:\n",
      "\n",
      "\\[ T(z) = T_0 - \\frac{g}{C_p}z \\]\n",
      "\n",
      "Substitute this expression for T(z) into the ideal gas law to get the relation between pressure and height.\n",
      "\n",
      "To estimate the pressure at an altitude of 10 km, we can use the relation between pressure and height derived above and the given values for R, T0, and the molecular mass of the gas. Calculate the temperature at 10 km altitude using the temperature lapse rate equation and then use the ideal gas law to find the pressure at that altitude.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Determine the relation between pressure and height for a gas for : $T=T(z)$ but no exchange of heat in the gas (adiabatic atmosphere).\n",
      "Estimate the pressure at an altitude of 10 km. Consider the atmosphere as an ideal, biatomic gas of molecular mass 28.\n",
      "\n",
      "N.A.: R = 8.2 J/mol K ; T$_0$=293 K.\\\\\n",
      "\n",
      "To determine the relation between pressure and height for an adiabatic atmosphere, we can use the ideal gas law and the equation of state for an adiabatic process. \n",
      "\n",
      "The ideal gas law is given by: \n",
      "\\[ PV = nRT \\]\n",
      "where P is the pressure, V is the volume, n is the number of moles, R is the gas constant, and T is the temperature.\n",
      "\n",
      "For an adiabatic process, we have: \n",
      "\\[ PV^{\\gamma} = \\text{constant} \\]\n",
      "where \\(\\gamma\\) is the adiabatic index and is given by: \n",
      "\\[ \\gamma = \\frac{C_p}{C_v} \\]\n",
      "where \\(C_p\\) and \\(C_v\\) are the specific heat capacities at constant pressure and constant volume, respectively.\n",
      "\n",
      "For a diatomic gas, such as the one described in the problem, the specific heat capacities are: \n",
      "\\[ C_p = \\frac{5}{2} R \\]\n",
      "\\[ C_v = \\frac{3}{2} R \\]\n",
      "\n",
      "Substituting the expressions for \\(C_p\\) and \\(C_v\\) into the equation for \\(\\gamma\\), we get: \n",
      "\\[ \\gamma = \\frac{5}{3} \\]\n",
      "\n",
      "Now, we can express the pressure as a function of height using the ideal gas law and the adiabatic equation: \n",
      "\\[ P(z)V(z)^{\\gamma} = nRT(z) \\]\n",
      "\\[ P(z) = \\frac{nRT(z)}{V(z)^{\\gamma}} \\]\n",
      "\\[ P(z) = \\frac{m}{M} \\frac{RT(z)}{V(z)^{\\gamma}} \\]\n",
      "\\[ P(z) = \\frac{m}{M} \\frac{RT(z)}{\\left(\\frac{m}{\\rho}\\right)^{\\gamma}} \\]\n",
      "\\[ P(z) = \\left(\\frac{RT(z)}{M}\\right) \\left(\\frac{\\rho}{m}\\right)^{\\gamma} \\]\n",
      "\\[ P(z) = \\frac{R\\rho}{M} T(z) \\left(\\frac{\\rho}{m}\\right)^{\\gamma} \\]\n",
      "\n",
      "where \\(m\\) is the mass of the gas, \\(M\\) is the molar mass, \\(\\rho\\) is the density of the gas, and we have used the relation \\(V = \\frac{m}{\\rho}\\).\n",
      "\n",
      "To estimate the pressure at an altitude of 10 km, we need to know the temperature profile \\(T(z)\\) and the density profile \\(\\rho(z)\\) of the atmosphere. Without these profiles, we cannot provide an exact numerical value for the pressure at 10 km. \n",
      "\n",
      "However, we can provide a general expression for the pressure at 10 km using the derived relation above and the given parameters in the problem.\n",
      "--------------------------------Question 33--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Tick the \\textbf{false} statement : \n",
      "[ ] As a defender of a machine learning model you should be more worried about black-box effective attacks than white-box effective attacks.\n",
      "[ ] Privacy problems in machine learning stem solely from the need for data to train models.\n",
      "[ ] Poisoning attacks can be used to increase vulnerability to adversarial examples.\n",
      "[SOLUTION] : The false statement is : Privacy problems in machine learning stem solely from the need for data to train models. Data collection for training is one of many privacy attack vectors in machine learning. There exist attacks on models and outputs; and naturally exposing data for test is a risk in itself. The first statement is true, an adversary performing a black-box attack needs much less resources and capabilities than a white-box adversary. This is much more dangerous, as the adversary only needs the ability to interact with the model. The last statement is also true because by providing poisoning inputs, the adversary gets to shape the boundaries of the model. Thus, she can carve this boundary to facilitate classification errors. In fact, you can understand a backdoor attack as a particular instance of an adversarial example.\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : Which of the following apply to recent Android-based mobile systems but not\n",
      "    to Linux-based desktop systems?\n",
      "[ ] Apps should use the binder interface to communicate with other\n",
      "            apps.\n",
      "[ ] By default, each app runs as its own user.\n",
      "[ ] All apps run in a strict container with only limited system\n",
      "            calls available.\n",
      "[ ] Arbitrary apps can exchange files through shared\n",
      "            directories.\n",
      "[SOLUTION] : \n",
      "[ ] Apps should use the binder interface to communicate with other apps.\n",
      "[X] By default, each app runs as its own user.\n",
      "[X] All apps run in a strict container with only limited system calls available.\n",
      "[ ] Arbitrary apps can exchange files through shared directories.\n",
      "\n",
      "The binder interface is used for inter-process communication in Android systems, but not specific to Android only. The other three statements are specific to recent Android-based mobile systems.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Which of the following apply to recent Android-based mobile systems but not\n",
      "    to Linux-based desktop systems?\n",
      "[ ] Apps should use the binder interface to communicate with other\n",
      "            apps.\n",
      "[ ] By default, each app runs as its own user.\n",
      "[ ] All apps run in a strict container with only limited system\n",
      "            calls available.\n",
      "[ ] Arbitrary apps can exchange files through shared\n",
      "            directories.\n",
      "The following applies to recent Android-based mobile systems but not to Linux-based desktop systems:\n",
      "\n",
      "- [ ] Apps should use the binder interface to communicate with other apps.\n",
      "- [ ] By default, each app runs as its own user.\n",
      "- [ ] All apps run in a strict container with only limited system calls available.\n",
      "--------------------------------Question 34--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Tick the false assertion. Bluetooth ... \n",
      "[ ] uses a stream cipher for encryption.\n",
      "[ ] has secure integrity protection for secure communication.\n",
      "[ ] has devices which use the same secret key with any other device.uses the SAFER+ block cipher in a one-way mode.\n",
      "[SOLUTION] : The false assertion is : has secure integrity protection for secure communication. Bluetooth is indeed a secure protocol which relies on the E0 stream cipher for privacy. In Bluetooth, the encryption process involves the Long Term Key (LTK), which is a secret key shared and stored by both connected devices. Bluetooth implements confidentiality, authentication and key derivation with custom algorithms based on a SAFER+ block cipher\n",
      "[QUESTION] : Tick the \\textbf{false} statement : \n",
      "[ ] As a defender of a machine learning model you should be more worried about black-box effective attacks than white-box effective attacks.\n",
      "[ ] Privacy problems in machine learning stem solely from the need for data to train models.\n",
      "[ ] Poisoning attacks can be used to increase vulnerability to adversarial examples.\n",
      "[SOLUTION] : The false statement is : Privacy problems in machine learning stem solely from the need for data to train models. Data collection for training is one of many privacy attack vectors in machine learning. There exist attacks on models and outputs; and naturally exposing data for test is a risk in itself. The first statement is true, an adversary performing a black-box attack needs much less resources and capabilities than a white-box adversary. This is much more dangerous, as the adversary only needs the ability to interact with the model. The last statement is also true because by providing poisoning inputs, the adversary gets to shape the boundaries of the model. Thus, she can carve this boundary to facilitate classification errors. In fact, you can understand a backdoor attack as a particular instance of an adversarial example.\n",
      "[QUESTION] : Which of the following operation is not part of AES?\n",
      "[ ] AddRoundKey\n",
      "[ ] SubBytes\n",
      "[ ] MixColumns\n",
      "[ ] MulRoundKey\n",
      "[SOLUTION] : \n",
      "The operation that is not part of AES is MulRoundKey. The correct operations in AES are AddRoundKey, SubBytes, and MixColumns.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Which of the following operation is not part of AES?\n",
      "[ ] AddRoundKey\n",
      "[ ] SubBytes\n",
      "[ ] MixColumns\n",
      "[ ] MulRoundKey\n",
      "The operation \"MulRoundKey\" is not part of the AES algorithm. The correct operations in AES are:\n",
      "\n",
      "- AddRoundKey\n",
      "- SubBytes\n",
      "- MixColumns\n",
      "\n",
      "\"MulRoundKey\" is not a standard operation in AES.\n",
      "--------------------------------Question 35--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Considering a sequence of n tokens, the computational complexity of the masked attention mechanism in BERT language models is: (select the smallest correct complexity)\n",
      "[ ] O(n^3)\n",
      "[ ] O(nlog(n))\n",
      "[ ] O(n)\n",
      "[ ] O(n^(1/2))\n",
      "[ ] O(n^2)\n",
      "[SOLUTION] : Masked attention is quadratic in the sequence length n because it computes the attention between all pairs of tokens, therefore O(n^2).\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Which of the following integers has the square roots $\\{2,3\\}$ when taken modulo $5$ \\textbf{and} the square roots $\\{3,10\\}$ when taken modulo $13$.\n",
      "[ ] $4$.\n",
      "[ ] $9$.\n",
      "[ ] $6$.\n",
      "[ ] $5$.\n",
      "[SOLUTION] : \n",
      "$4$. \n",
      "\n",
      "First, we check for the square roots {2,3} modulo 5:\n",
      "- For $4^2 \\equiv 1 \\pmod{5}$, $4$ is a square root of $2$ modulo $5$.\n",
      "- For $4^2 \\equiv 1 \\pmod{5}$, $4$ is a square root of $3$ modulo $5$.\n",
      "\n",
      "Next, we check for the square roots {3,10} modulo 13:\n",
      "- For $4^2 \\equiv 3 \\pmod{13}$, $4$ is not a square root of $3$ modulo $13$.\n",
      "- For $9^2 \\equiv 3 \\pmod{13}$, $9$ is a square root of $3$ modulo $13$.\n",
      "- For $4^2 \\equiv 3 \\pmod{13}$, $4$ is not a square root of $10$ modulo $13$.\n",
      "- For $9^2 \\equiv 3 \\pmod{13}$, $9$ is not a square root of $10$ modulo $13$.\n",
      "\n",
      "Therefore, the integer $4$ satisfies the conditions given in the question.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Which of the following integers has the square roots $\\{2,3\\}$ when taken modulo $5$ \\textbf{and} the square roots $\\{3,10\\}$ when taken modulo $13$.\n",
      "[ ] $4$.\n",
      "[ ] $9$.\n",
      "[ ] $6$.\n",
      "[ ] $5$.\n",
      "Let's analyze each option one by one:\n",
      "\n",
      "1. If we take the square roots of $4$ modulo $5$, we get $\\{2,3\\}$ as $2^2 \\equiv 4 \\equiv 9 \\equiv 3^2 \\pmod{5}$. However, when we take the square roots of $4$ modulo $13$, we get $\\{2,11\\}$, not $\\{3,10\\}$. So, $4$ is not the correct answer.\n",
      "\n",
      "2. If we take the square roots of $9$ modulo $5$, we get $\\{2,3\\}$ as $2^2 \\equiv 4 \\equiv 9 \\equiv 1 \\equiv 3^2 \\pmod{5}$. When we take the square roots of $9$ modulo $13$, we get $\\{3,10\\}$ as $3^2 \\equiv 9 \\equiv 22 \\equiv 10 \\pmod{13}$. Thus, $9$ satisfies the given conditions.\n",
      "\n",
      "3. If we take the square roots of $6$ modulo $5$, we get $\\{1,4\\}$, not $\\{2,3\\}$. Additionally, the square roots of $6$ modulo $13$ are $\\{4,9\\}$, not $\\{3,10\\}$. So, $6$ is not the correct answer.\n",
      "\n",
      "4. If we take the square roots of $5$ modulo $5$, we get $\\{0,0\\}$, not $\\{2,3\\}$. Additionally, the square roots of $5$ modulo $13$ are $\\{4,9\\}$, not $\\{3,10\\}$. So, $5$ is not the correct answer.\n",
      "\n",
      "Therefore, the integer that satisfies all the given conditions is $\\boxed{9}$.\n",
      "--------------------------------Question 36--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : A rigid and homogeneous horizontal rod of mass M, of length L, of negligible thickness e, i.e. e << L, is rotating in a horizontal plane around the vertical axis $C e_3$ at angular velocity $\\Omega=\\dot{\\psioldsymbol{e}3$. The moment of inertia of the rod with respect to the vertical principal axis that contains its centre of mass G is $I{G,3}=\frac1{12}ML^{2}$. Let C be the point of contact between the extremity of the rod and the rotation axis, and P the point at the other extremity. The unit vector $e_1$ is oriented along the rod and the vector $e_2$ is orthogonal to $e_1$. The unit vectors $e_1$, $e_2$ and $e_3$, attached to the rod at point C, are the principal axis frame of the rod. We consider that there is no friction and we do not take explicitly into account the influence of the gravitational field. Give the expression of the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis of rotation $C e_3$ in terms of the scalar quantities M and L.\n",
      "[SOLUTION] : Applying the Huygens-Steiner theorem, we determine the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis $C e_3$ taking into account the fact that d = L/2 is the distance separating points G and C and that $I_{G,3}=\frac1{12}ML^{2}$,\n",
      "ight)^2=\frac{1}{12}ML^2+\frac{1}{4}ML^2=\frac{1}{3}ML^2$\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : You have been publishing a daily column for the Gazette over the last few years and have recently reached a milestone --- your 1000th column! Realizing you'd like to go skiing more often, you decide it might be easier to automate your job by training a story generation system on the columns you've already written. Then, whenever your editor pitches you a title for a column topic, you'll just be able to give the title to your story generation system, produce the text body of the column, and publish it to the website!\n",
      "Your column generation system has become quite successful and you've managed to automate most of your job simply by typing your editor's title pitches into your model to produce your column every day. Two years later, during the COVID--25 pandemic, your editor proposes to use your system to generate an information sheet about the pandemic for anyone looking for information about symptoms, treatments, testing sites, medical professionals, etc. Given the similarity to a previous pandemic many years before, COVID--19, you train your model on all news articles published about COVID--19 between the years of 2019--2022. Then, you generate the information page from your trained model.\n",
      "Give an example of a potential harm that your model could produce from the perspective of leaking private information.\n",
      "[SOLUTION] : \n",
      "One potential harm that could arise from using a story generation system trained on personal data such as columns or news articles is the unintentional leakage of private information. If the model inadvertently generates content that includes personal details, sensitive information, or confidential data from the columns or news articles it was trained on, this could lead to privacy breaches and compromise the security of individuals involved. This could have serious consequences for both the individuals whose information is leaked and the organization responsible for using the model. It is crucial to implement strong data protection measures and ethical guidelines when training and deploying such models to mitigate the risk of leaking private information.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "You have been publishing a daily column for the Gazette over the last few years and have recently reached a milestone --- your 1000th column! Realizing you'd like to go skiing more often, you decide it might be easier to automate your job by training a story generation system on the columns you've already written. Then, whenever your editor pitches you a title for a column topic, you'll just be able to give the title to your story generation system, produce the text body of the column, and publish it to the website!\n",
      "Your column generation system has become quite successful and you've managed to automate most of your job simply by typing your editor's title pitches into your model to produce your column every day. Two years later, during the COVID--25 pandemic, your editor proposes to use your system to generate an information sheet about the pandemic for anyone looking for information about symptoms, treatments, testing sites, medical professionals, etc. Given the similarity to a previous pandemic many years before, COVID--19, you train your model on all news articles published about COVID--19 between the years of 2019--2022. Then, you generate the information page from your trained model.\n",
      "Give an example of a potential harm that your model could produce from the perspective of leaking private information.\n",
      "One potential harm that could arise from using a story generation system trained on personal columns and news articles is the inadvertent leakage of private information. For example, if your previous columns contained personal anecdotes, details about your life, or information about individuals you know, there is a risk that the model could generate content that inadvertently reveals sensitive or private information.\n",
      "\n",
      "If the model is not properly trained to filter out private or confidential details, it could generate stories that expose personal relationships, health issues, financial matters, or other sensitive information that was originally shared in your columns. This could lead to violations of privacy, breaches of trust, and potential legal implications if the leaked information is sensitive or confidential.\n",
      "\n",
      "It is essential to implement strict data privacy protocols and ethical guidelines when using AI models trained on personal or sensitive data to prevent the unintentional disclosure of private information and to safeguard the privacy and confidentiality of individuals involved.\n",
      "--------------------------------Question 37--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Tick the \\textbf{false} statement : \n",
      "[ ] As a defender of a machine learning model you should be more worried about black-box effective attacks than white-box effective attacks.\n",
      "[ ] Privacy problems in machine learning stem solely from the need for data to train models.\n",
      "[ ] Poisoning attacks can be used to increase vulnerability to adversarial examples.\n",
      "[SOLUTION] : The false statement is : Privacy problems in machine learning stem solely from the need for data to train models. Data collection for training is one of many privacy attack vectors in machine learning. There exist attacks on models and outputs; and naturally exposing data for test is a risk in itself. The first statement is true, an adversary performing a black-box attack needs much less resources and capabilities than a white-box adversary. This is much more dangerous, as the adversary only needs the ability to interact with the model. The last statement is also true because by providing poisoning inputs, the adversary gets to shape the boundaries of the model. Thus, she can carve this boundary to facilitate classification errors. In fact, you can understand a backdoor attack as a particular instance of an adversarial example.\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : Tick the \\emph{false} assertion.\n",
      "[ ] RSA-PSS is a signature scheme.\n",
      "[ ] RSA-OAEP is an encryption scheme.\n",
      "[ ] The RSA based encryption scheme of the standard PKCS \\#1 v1.5 is vulnerable to a side channel attack.\n",
      "[ ] The RSA based scheme ISO/IEC 9796 is an encryption scheme.\n",
      "[SOLUTION] : \n",
      "The false assertion is : The RSA based encryption scheme of the standard PKCS \\#1 v1.5 is vulnerable to a side channel attack. The RSA-PSS is a signature scheme, RSA-OAEP is an encryption scheme, and the RSA based scheme ISO/IEC 9796 is an encryption scheme. The RSA based encryption scheme of the standard PKCS \\#1 v1.5 is indeed vulnerable to a padding oracle attack, which is a type of side channel attack.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Tick the \\emph{false} assertion.\n",
      "[ ] RSA-PSS is a signature scheme.\n",
      "[ ] RSA-OAEP is an encryption scheme.\n",
      "[ ] The RSA based encryption scheme of the standard PKCS \\#1 v1.5 is vulnerable to a side channel attack.\n",
      "[ ] The RSA based scheme ISO/IEC 9796 is an encryption scheme.\n",
      "- [ ] The RSA based encryption scheme of the standard PKCS \\#1 v1.5 is vulnerable to a side channel attack.\n",
      "--------------------------------Question 38--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Considering a sequence of n tokens, the computational complexity of the masked attention mechanism in BERT language models is: (select the smallest correct complexity)\n",
      "[ ] O(n^3)\n",
      "[ ] O(nlog(n))\n",
      "[ ] O(n)\n",
      "[ ] O(n^(1/2))\n",
      "[ ] O(n^2)\n",
      "[SOLUTION] : Masked attention is quadratic in the sequence length n because it computes the attention between all pairs of tokens, therefore O(n^2).\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Consider a classification problem on linearly separable data. We train an SVM model and a logistic regression model. For logistic regression (LR) we add a small regularization term (penalty on weights) in order to make the optimum well-defined. Each model gives us a margin. Consider a datapoint $\\mathbf{x}_{0}$ that is correctly classified and strictly outside both margins Which one of the following statements is incorrect ?\n",
      "[ ] There exists a direction in which we can slightly move $\\mathbf{x}_{0}$ without changing the LR decision boundary after retraining.\n",
      "[ ] $\\mathbf{x}_{0}$ isn't a support vector\n",
      "[ ] There exists a direction in which we can arbitrarily move $\\mathbf{x}_{0}$ without changing the SVM decision boundary after retraining.\n",
      "[ ] If we remove $\\mathbf{x}_{0}$ from the dataset and retrain, this will change the LR decision boundary.\n",
      "[ ] If we remove $\\mathbf{x}_{0}$ from the dataset and retrain, this will not change the SVM decision boundary.\n",
      "[SOLUTION] : \n",
      "The incorrect statement is: There exists a direction in which we can arbitrarily move $\\mathbf{x}_{0}$ without changing the SVM decision boundary after retraining. \n",
      "\n",
      "In SVM, the decision boundary is determined by the support vectors, which are the data points closest to the decision boundary. By moving $\\mathbf{x}_{0}$ arbitrarily, we may change the support vectors and hence the decision boundary.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Consider a classification problem on linearly separable data. We train an SVM model and a logistic regression model. For logistic regression (LR) we add a small regularization term (penalty on weights) in order to make the optimum well-defined. Each model gives us a margin. Consider a datapoint $\\mathbf{x}_{0}$ that is correctly classified and strictly outside both margins Which one of the following statements is incorrect ?\n",
      "[ ] There exists a direction in which we can slightly move $\\mathbf{x}_{0}$ without changing the LR decision boundary after retraining.\n",
      "[ ] $\\mathbf{x}_{0}$ isn't a support vector\n",
      "[ ] There exists a direction in which we can arbitrarily move $\\mathbf{x}_{0}$ without changing the SVM decision boundary after retraining.\n",
      "[ ] If we remove $\\mathbf{x}_{0}$ from the dataset and retrain, this will change the LR decision boundary.\n",
      "[ ] If we remove $\\mathbf{x}_{0}$ from the dataset and retrain, this will not change the SVM decision boundary.\n",
      "Let's analyze each statement:\n",
      "\n",
      "1. There exists a direction in which we can slightly move $\\mathbf{x}_{0}$ without changing the LR decision boundary after retraining.\n",
      "- This statement is correct. Since logistic regression with a small regularization term is continuous, small movements of $\\mathbf{x}_{0}$ may not change the decision boundary significantly.\n",
      "\n",
      "2. $\\mathbf{x}_{0}$ isn't a support vector\n",
      "- This statement is correct. Since $\\mathbf{x}_{0}$ is strictly outside both margins, it is not a support vector for either the SVM or the logistic regression model.\n",
      "\n",
      "3. There exists a direction in which we can arbitrarily move $\\mathbf{x}_{0}$ without changing the SVM decision boundary after retraining.\n",
      "- This statement is incorrect. In SVM, the decision boundary is determined by the support vectors, and moving a point that is not a support vector arbitrarily can change the decision boundary.\n",
      "\n",
      "4. If we remove $\\mathbf{x}_{0}$ from the dataset and retrain, this will change the LR decision boundary.\n",
      "- This statement is correct. Removing $\\mathbf{x}_{0}$ from the dataset can change the logistic regression decision boundary as the model will be trained on a different set of data points.\n",
      "\n",
      "5. If we remove $\\mathbf{x}_{0}$ from the dataset and retrain, this will not change the SVM decision boundary.\n",
      "- This statement is incorrect. Since $\\mathbf{x}_{0}$ is not a support vector, removing it from the dataset may not change the SVM decision boundary, as the decision boundary is determined by the support vectors.\n",
      "\n",
      "Therefore, the incorrect statement is: \"There exists a direction in which we can arbitrarily move $\\mathbf{x}_{0}$ without changing the SVM decision boundary after retraining.\"\n",
      "--------------------------------Question 39--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : Consider the following matrix-factorization problem. For the observed ratings $r_{u m}$ for a given pair $(u, m)$ of a user $u$ and a movie $m$, one typically tries to estimate the score by $$ f_{u m}=\\left\\langle\\mathbf{v}_{u}, \\mathbf{w}_{m}\\right\\rangle+b_{u}+b_{m} $$ Here $\\mathbf{v}_{u}$ and $\\mathbf{w}_{m}$ are vectors in $\\mathbb{R}^{D}$ and $b_{u}$ and $b_{m}$ are scalars, indicating the bias. Assume that our objective is given by $$ \\frac{1}{2} \\sum_{u \\sim m}\\left(f_{u m}-r_{u m}\\right)^{2}+\\frac{\\lambda}{2}\\left[\\sum_{u \\in \\mathbf{U}}\\left(b_{u}^{2}+\\left\\|\\mathbf{v}_{u}\\right\\|^{2}\\right)+\\sum_{m \\in \\mathbf{M}}\\left(b_{m}^{2}+\\left\\|\\mathbf{w}_{m}\\right\\|^{2}\\right)\\right] $$ where $\\lambda>0$. Here $\\mathbf{U}$ denotes the set of all users, $M$ the set of all movies, and $u \\sim m$ represents the sum over all $(u, m)$ pairs for which a rating exists. Write the optimal values of $b_{u}$, provided that all other values are fixed.\n",
      "[SOLUTION] : \n",
      "To find the optimal value of $b_u$, we need to take the derivative of the objective function with respect to $b_u$ and set it equal to zero. The objective function is given by:\n",
      "\n",
      "$$\\frac{1}{2} \\sum_{u \\sim m}(f_{u m}-r_{u m})^{2}+\\frac{\\lambda}{2}\\left[\\sum_{u \\in \\mathbf{U}}(b_{u}^{2}+\\|\\mathbf{v}_{u}\\|^{2})+\\sum_{m \\in \\mathbf{M}}(b_{m}^{2}+\\|\\mathbf{w}_{m}\\|^{2})\\right]$$\n",
      "\n",
      "Taking the derivative with respect to $b_u$, we get:\n",
      "\n",
      "$$\\frac{\\partial}{\\partial b_u}\\left[\\frac{1}{2} \\sum_{u \\sim m}(f_{u m}-r_{u m})^{2}+\\frac{\\lambda}{2}\\sum_{u \\in \\mathbf{U}}(b_{u}^{2}+\\|\\mathbf{v}_{u}\\|^{2})\\right] = \\lambda b_u + \\sum_{m \\sim u}(f_{u m}-r_{u m})$$\n",
      "\n",
      "Setting this derivative equal to zero and solving for $b_u$, we get:\n",
      "\n",
      "$$\\lambda b_u + \\sum_{m \\sim u}(f_{u m}-r_{u m}) = 0$$\n",
      "$$b_u = -\\frac{1}{\\lambda} \\sum_{m \\sim u}(f_{u m}-r_{u m})$$\n",
      "\n",
      "Therefore, the optimal value of $b_u$ is given by the above expression.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Consider the following matrix-factorization problem. For the observed ratings $r_{u m}$ for a given pair $(u, m)$ of a user $u$ and a movie $m$, one typically tries to estimate the score by $$ f_{u m}=\\left\\langle\\mathbf{v}_{u}, \\mathbf{w}_{m}\\right\\rangle+b_{u}+b_{m} $$ Here $\\mathbf{v}_{u}$ and $\\mathbf{w}_{m}$ are vectors in $\\mathbb{R}^{D}$ and $b_{u}$ and $b_{m}$ are scalars, indicating the bias. Assume that our objective is given by $$ \\frac{1}{2} \\sum_{u \\sim m}\\left(f_{u m}-r_{u m}\\right)^{2}+\\frac{\\lambda}{2}\\left[\\sum_{u \\in \\mathbf{U}}\\left(b_{u}^{2}+\\left\\|\\mathbf{v}_{u}\\right\\|^{2}\\right)+\\sum_{m \\in \\mathbf{M}}\\left(b_{m}^{2}+\\left\\|\\mathbf{w}_{m}\\right\\|^{2}\\right)\\right] $$ where $\\lambda>0$. Here $\\mathbf{U}$ denotes the set of all users, $M$ the set of all movies, and $u \\sim m$ represents the sum over all $(u, m)$ pairs for which a rating exists. Write the optimal values of $b_{u}$, provided that all other values are fixed.\n",
      "To find the optimal value of $b_{u}$, we differentiate the objective function with respect to $b_{u}$ and set it to zero. Let's calculate the derivative:\n",
      "\n",
      "Given the objective function: \n",
      "\n",
      "$$ \\frac{1}{2} \\sum_{u \\sim m}\\left(f_{u m}-r_{u m}\\right)^{2}+\\frac{\\lambda}{2}\\left[\\sum_{u \\in \\mathbf{U}}\\left(b_{u}^{2}+\\left\\|\\mathbf{v}_{u}\\right\\|^{2}\\right)+\\sum_{m \\in \\mathbf{M}}\\left(b_{m}^{2}+\\left\\|\\mathbf{w}_{m}\\right\\|^{2}\\right)\\right] $$\n",
      "\n",
      "The partial derivative of the objective function with respect to $b_{u}$ is:\n",
      "\n",
      "$$ \\frac{\\partial}{\\partial b_{u}} = \\sum_{u \\sim m} (f_{um} - r_{um}) + \\lambda b_{u} $$\n",
      "\n",
      "Setting this derivative to zero, we get:\n",
      "\n",
      "$$ \\sum_{u \\sim m} (f_{um} - r_{um}) + \\lambda b_{u} = 0 $$\n",
      "\n",
      "Solving for $b_{u}$, we get:\n",
      "\n",
      "$$ b_{u} = -\\frac{1}{\\lambda} \\sum_{u \\sim m} (f_{um} - r_{um}) $$\n",
      "\n",
      "Therefore, the optimal value of $b_{u}$, provided that all other values are fixed, is:\n",
      "\n",
      "$$ b_{u} = -\\frac{1}{\\lambda} \\sum_{u \\sim m} (f_{um} - r_{um}) $$\n",
      "\n",
      "This is the expression for updating the bias term $b_{u}$ in the matrix factorization problem.\n",
      "--------------------------------Question 40--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : A rigid and homogeneous horizontal rod of mass M, of length L, of negligible thickness e, i.e. e << L, is rotating in a horizontal plane around the vertical axis $C e_3$ at angular velocity $\\Omega=\\dot{\\psioldsymbol{e}3$. The moment of inertia of the rod with respect to the vertical principal axis that contains its centre of mass G is $I{G,3}=\frac1{12}ML^{2}$. Let C be the point of contact between the extremity of the rod and the rotation axis, and P the point at the other extremity. The unit vector $e_1$ is oriented along the rod and the vector $e_2$ is orthogonal to $e_1$. The unit vectors $e_1$, $e_2$ and $e_3$, attached to the rod at point C, are the principal axis frame of the rod. We consider that there is no friction and we do not take explicitly into account the influence of the gravitational field. Give the expression of the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis of rotation $C e_3$ in terms of the scalar quantities M and L.\n",
      "[SOLUTION] : Applying the Huygens-Steiner theorem, we determine the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis $C e_3$ taking into account the fact that d = L/2 is the distance separating points G and C and that $I_{G,3}=\frac1{12}ML^{2}$,\n",
      "ight)^2=\frac{1}{12}ML^2+\frac{1}{4}ML^2=\frac{1}{3}ML^2$\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : You are responsible for a project aiming at providing on-line recommendations to the customers of\n",
      "a on-line book selling company.\n",
      "The general idea behind this recommendation system is to cluster books according to both customers\n",
      "and content similarities, so as to propose books similar to the books already bought by a given\n",
      "customer. The core of the recommendation system is a clustering algorithm aiming at regrouping\n",
      "books likely to be appreciate by the same person. This clustering should not only be achieved\n",
      "based on the purchase history of customers, but should also be refined by the content of the books\n",
      "themselves. It's that latter aspect we want to address in this exam question.\n",
      "\n",
      "Consider the following six 'documents' (toy example):\n",
      "d1: 'Because cows are not sorted as they return from the fields to their home pen, cow flows\n",
      "are improved.'\n",
      "d2: 'He was convinced that if he owned the fountain pen that he'd seen in the shop window for years, he could write fantastic stories with it. That was the kind of pen you cannot forget.'\n",
      "d3: 'With this book you will learn how to draw humans, animals (cows, horses, etc.) and flowers with a charcoal pen.'\n",
      "d4: 'The cows were kept in pens behind the farm, hidden from the road. That was the typical kind of pen made for cows.'\n",
      "d5: 'If Dracula wrote with a fountain pen, this would be the kind of pen he would write with, filled with blood red ink. It was the pen she chose for my punishment, the pen of my torment. What a mean cow!'\n",
      "d6: 'What pen for what cow? A red pen for a red cow, a black pen for a black cow, a brown pen for a brown cow, ... Understand?'\n",
      "\n",
      "and suppose (toy example) that they are indexed only by the two words: pen and cow.\n",
      "\n",
      "What are their vector representations?\n",
      "[SOLUTION] : \n",
      "To represent the documents as vectors, we can use the Bag of Words (BoW) model. First, we need to create a vocabulary consisting of all unique words in the documents. In this case, the vocabulary would be {because, cows, are, not, sorted, as, they, return, from, the, fields, to, their, home, pen, cow, flows, improved, he, was, convinced, that, if, owned, fountain, he'd, seen, in, shop, window, for, years, could, write, fantastic, stories, with, it, kind, of, you, cannot, forget, this, book, will, learn, how, draw, humans, animals, horses, etc, flowers, charcoal, were, kept, pens, behind, farm, hidden, road, typical, made, Dracula, wrote, blood, red, ink, she, chose, my, punishment, torment, mean, what, black, brown, Understand}.\n",
      "\n",
      "Then, we can represent each document as a vector where each element corresponds to the frequency of the corresponding word in the document. For example:\n",
      "- d1: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "- d2: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "You are responsible for a project aiming at providing on-line recommendations to the customers of\n",
      "a on-line book selling company.\n",
      "The general idea behind this recommendation system is to cluster books according to both customers\n",
      "and content similarities, so as to propose books similar to the books already bought by a given\n",
      "customer. The core of the recommendation system is a clustering algorithm aiming at regrouping\n",
      "books likely to be appreciate by the same person. This clustering should not only be achieved\n",
      "based on the purchase history of customers, but should also be refined by the content of the books\n",
      "themselves. It's that latter aspect we want to address in this exam question.\n",
      "\n",
      "Consider the following six 'documents' (toy example):\n",
      "d1: 'Because cows are not sorted as they return from the fields to their home pen, cow flows\n",
      "are improved.'\n",
      "d2: 'He was convinced that if he owned the fountain pen that he'd seen in the shop window for years, he could write fantastic stories with it. That was the kind of pen you cannot forget.'\n",
      "d3: 'With this book you will learn how to draw humans, animals (cows, horses, etc.) and flowers with a charcoal pen.'\n",
      "d4: 'The cows were kept in pens behind the farm, hidden from the road. That was the typical kind of pen made for cows.'\n",
      "d5: 'If Dracula wrote with a fountain pen, this would be the kind of pen he would write with, filled with blood red ink. It was the pen she chose for my punishment, the pen of my torment. What a mean cow!'\n",
      "d6: 'What pen for what cow? A red pen for a red cow, a black pen for a black cow, a brown pen for a brown cow, ... Understand?'\n",
      "\n",
      "and suppose (toy example) that they are indexed only by the two words: pen and cow.\n",
      "\n",
      "What are their vector representations?\n",
      "To represent the documents as vectors, we can use the Bag-of-Words model. In this model, each document is represented as a vector where each element corresponds to the frequency of a specific word in the document.\n",
      "\n",
      "In this case, we have two words of interest: \"pen\" and \"cow\". We can create a vector representation for each document based on the occurrence of these two words.\n",
      "\n",
      "Let's calculate the vector representations for the given documents:\n",
      "\n",
      "- d1: [1, 1] (pen appears once, cow appears once)\n",
      "- d2: [2, 0] (pen appears twice, cow does not appear)\n",
      "- d3: [1, 1] (pen appears once, cow appears once)\n",
      "- d4: [1, 1] (pen appears once, cow appears once)\n",
      "- d5: [2, 1] (pen appears twice, cow appears once)\n",
      "- d6: [1, 1] (pen appears once, cow appears once)\n",
      "\n",
      "So, the vector representations for the given documents based on the occurrences of the words \"pen\" and \"cow\" are:\n",
      "\n",
      "- d1: [1, 1]\n",
      "- d2: [2, 0]\n",
      "- d3: [1, 1]\n",
      "- d4: [1, 1]\n",
      "- d5: [2, 1]\n",
      "- d6: [1, 1]\n",
      "\n",
      "These vectors represent the documents in a simplified manner based on the presence of the words \"pen\" and \"cow\" in each document.\n",
      "--------------------------------Question 41--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Tick the false assertion. Bluetooth ... \n",
      "[ ] uses a stream cipher for encryption.\n",
      "[ ] has secure integrity protection for secure communication.\n",
      "[ ] has devices which use the same secret key with any other device.uses the SAFER+ block cipher in a one-way mode.\n",
      "[SOLUTION] : The false assertion is : has secure integrity protection for secure communication. Bluetooth is indeed a secure protocol which relies on the E0 stream cipher for privacy. In Bluetooth, the encryption process involves the Long Term Key (LTK), which is a secret key shared and stored by both connected devices. Bluetooth implements confidentiality, authentication and key derivation with custom algorithms based on a SAFER+ block cipher\n",
      "[QUESTION] : Tick the \\textbf{false} statement : \n",
      "[ ] As a defender of a machine learning model you should be more worried about black-box effective attacks than white-box effective attacks.\n",
      "[ ] Privacy problems in machine learning stem solely from the need for data to train models.\n",
      "[ ] Poisoning attacks can be used to increase vulnerability to adversarial examples.\n",
      "[SOLUTION] : The false statement is : Privacy problems in machine learning stem solely from the need for data to train models. Data collection for training is one of many privacy attack vectors in machine learning. There exist attacks on models and outputs; and naturally exposing data for test is a risk in itself. The first statement is true, an adversary performing a black-box attack needs much less resources and capabilities than a white-box adversary. This is much more dangerous, as the adversary only needs the ability to interact with the model. The last statement is also true because by providing poisoning inputs, the adversary gets to shape the boundaries of the model. Thus, she can carve this boundary to facilitate classification errors. In fact, you can understand a backdoor attack as a particular instance of an adversarial example.\n",
      "[QUESTION] : Which of the following is/are true about fuzzing?\n",
      "[ ] Fuzzers may get ``stuck'' and cannot easily detect that they are\n",
      "               no longer improving coverage\n",
      "[ ] The efficacy of a fuzzing campaign scales with its speed (executions per second)\n",
      "[ ] Fuzzers generally determine the exploitability of a crash.\n",
      "[ ] There is little to no benefit in running fuzzers in parallel.\n",
      "[SOLUTION] : \n",
      "The true statements about fuzzing are:\n",
      "\n",
      "- Fuzzers may get \"stuck\" and cannot easily detect that they are no longer improving coverage\n",
      "- The efficacy of a fuzzing campaign scales with its speed (executions per second)\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Which of the following is/are true about fuzzing?\n",
      "[ ] Fuzzers may get ``stuck'' and cannot easily detect that they are\n",
      "               no longer improving coverage\n",
      "[ ] The efficacy of a fuzzing campaign scales with its speed (executions per second)\n",
      "[ ] Fuzzers generally determine the exploitability of a crash.\n",
      "[ ] There is little to no benefit in running fuzzers in parallel.\n",
      "1. [X] Fuzzers may get ``stuck'' and cannot easily detect that they are no longer improving coverage.\n",
      "- True. Fuzzers can sometimes get stuck in a particular part of the program and may not be able to detect that they are not making progress in finding new vulnerabilities.\n",
      "\n",
      "2. [X] The efficacy of a fuzzing campaign scales with its speed (executions per second).\n",
      "- True. The faster a fuzzer can execute test cases, the more likely it is to find vulnerabilities within a given timeframe.\n",
      "\n",
      "3. [ ] Fuzzers generally determine the exploitability of a crash.\n",
      "- False. Fuzzers are designed to generate input to trigger crashes, but determining the exploitability of a crash typically requires further manual analysis.\n",
      "\n",
      "4. [ ] There is little to no benefit in running fuzzers in parallel.\n",
      "- False. Running fuzzers in parallel can help increase coverage and find vulnerabilities more efficiently by exploring different paths simultaneously.\n",
      "--------------------------------Question 42--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Tick the false assertion. Bluetooth ... \n",
      "[ ] uses a stream cipher for encryption.\n",
      "[ ] has secure integrity protection for secure communication.\n",
      "[ ] has devices which use the same secret key with any other device.uses the SAFER+ block cipher in a one-way mode.\n",
      "[SOLUTION] : The false assertion is : has secure integrity protection for secure communication. Bluetooth is indeed a secure protocol which relies on the E0 stream cipher for privacy. In Bluetooth, the encryption process involves the Long Term Key (LTK), which is a secret key shared and stored by both connected devices. Bluetooth implements confidentiality, authentication and key derivation with custom algorithms based on a SAFER+ block cipher\n",
      "[QUESTION] : Tick the \\textbf{false} statement : \n",
      "[ ] As a defender of a machine learning model you should be more worried about black-box effective attacks than white-box effective attacks.\n",
      "[ ] Privacy problems in machine learning stem solely from the need for data to train models.\n",
      "[ ] Poisoning attacks can be used to increase vulnerability to adversarial examples.\n",
      "[SOLUTION] : The false statement is : Privacy problems in machine learning stem solely from the need for data to train models. Data collection for training is one of many privacy attack vectors in machine learning. There exist attacks on models and outputs; and naturally exposing data for test is a risk in itself. The first statement is true, an adversary performing a black-box attack needs much less resources and capabilities than a white-box adversary. This is much more dangerous, as the adversary only needs the ability to interact with the model. The last statement is also true because by providing poisoning inputs, the adversary gets to shape the boundaries of the model. Thus, she can carve this boundary to facilitate classification errors. In fact, you can understand a backdoor attack as a particular instance of an adversarial example.\n",
      "[QUESTION] : If we pick independent random numbers in $\\{1, 2, \\dots, N\\}$ with uniform distribution, $\\theta \\sqrt{N}$ times, we get at least one number twice with probability\\dots\n",
      "[ ] $e^{\\theta ^2}$\n",
      "[ ] $1-e^{\\theta ^2}$\n",
      "[ ] $e^{-\\theta ^2 /2}$\n",
      "[ ] $1-e^{-\\theta ^2 /2}$\n",
      "[SOLUTION] : \n",
      "The probability that we do not get any repeated numbers when picking $\\theta \\sqrt{N}$ independent random numbers from $\\{1, 2, \\dots, N\\}$ with uniform distribution is given by:\n",
      "\n",
      "$1 - \\frac{N}{N} \\cdot \\frac{N-1}{N} \\cdot \\frac{N-2}{N} \\dots \\frac{N-\\theta \\sqrt{N}+1}{N}$\n",
      "\n",
      "Simplifying this expression gives:\n",
      "\n",
      "$1 - \\frac{N!}{N^{\\theta \\sqrt{N}}(N-\\theta \\sqrt{N})!}$\n",
      "\n",
      "Using the approximation $n! \\approx \\sqrt{2\\pi n}(\\frac{n}{e})^n$, we can further simplify this expression to get:\n",
      "\n",
      "$1 - e^{-\\frac{\\theta^2}{2}}$\n",
      "\n",
      "Therefore, the correct answer is: $1 - e^{-\\frac{\\theta^2}{2}}$\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "If we pick independent random numbers in $\\{1, 2, \\dots, N\\}$ with uniform distribution, $\\theta \\sqrt{N}$ times, we get at least one number twice with probability\\dots\n",
      "[ ] $e^{\\theta ^2}$\n",
      "[ ] $1-e^{\\theta ^2}$\n",
      "[ ] $e^{-\\theta ^2 /2}$\n",
      "[ ] $1-e^{-\\theta ^2 /2}$\n",
      "To solve this problem, we can consider the probability that no number is repeated in the $\\theta \\sqrt{N}$ draws. \n",
      "\n",
      "In the first draw, we have $N$ choices. In the second draw, we have $N-1$ choices (since we cannot repeat the number we chose in the first draw). In the $\\theta \\sqrt{N}$ draws, we have $(N)(N-1)(N-2) \\cdots (N - \\theta \\sqrt{N} + 1)$ choices.\n",
      "\n",
      "Therefore, the probability that no number is repeated is given by:\n",
      "\n",
      "$$P(\\text{no number is repeated}) = \\frac{N(N-1)(N-2) \\cdots (N - \\theta \\sqrt{N} + 1)}{N^{\\theta \\sqrt{N}}}$$\n",
      "\n",
      "Now, we can use the fact that $e^{-x} = 1 - x + \\frac{x^2}{2!} - \\frac{x^3}{3!} + \\cdots$, and for small $x$, we can approximate $e^{-x} \\approx 1 - x$.\n",
      "\n",
      "Therefore, for small values of $\\theta$, we can approximate the above expression as:\n",
      "\n",
      "$$P(\\text{no number is repeated}) \\approx 1 - \\frac{\\theta \\sqrt{N}}{N} = 1 - \\frac{\\theta}{\\sqrt{N}}$$\n",
      "\n",
      "Since the probability of getting at least one number repeated is the complement of the probability of no number being repeated, we have:\n",
      "\n",
      "$$P(\\text{at least one number is repeated}) = 1 - P(\\text{no number is repeated}) \\approx \\frac{\\theta}{\\sqrt{N}}$$\n",
      "\n",
      "Therefore, the correct choice is:\n",
      "[ ] $e^{\\theta ^2}$\n",
      "[ ] $1-e^{\\theta ^2}$\n",
      "[ ] $e^{-\\theta ^2 /2}$\n",
      "[ ] $1-e^{-\\theta ^2 /2}$\n",
      "\n",
      "The correct choice is:\n",
      "[ ] $e^{\\theta ^2}$\n",
      "[ ] $1-e^{\\theta ^2}$\n",
      "[ ] $e^{-\\theta ^2 /2}$\n",
      "[ ] $1-e^{-\\theta ^2 /2}$\n",
      "--------------------------------Question 43--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : Assume you are working in a company on the back-end of a mobile application. You are tasked with improving the integration of the authentication via Google in your app, but your manager tells you:\n",
      "\"Don't run any tests today, we only have a few API calls left for today's rate limit, we need to preserve those for customers.\"\n",
      "In 1-2 sentences, propose a change to the codebase to avoid this problem.\n",
      "[SOLUTION] : \n",
      "One solution could be to implement local testing environments that mimic the behavior of the Google authentication API, allowing developers to test the integration without using up the limited API calls.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Assume you are working in a company on the back-end of a mobile application. You are tasked with improving the integration of the authentication via Google in your app, but your manager tells you:\n",
      "\"Don't run any tests today, we only have a few API calls left for today's rate limit, we need to preserve those for customers.\"\n",
      "In 1-2 sentences, propose a change to the codebase to avoid this problem.\n",
      "One approach could be to temporarily disable the Google authentication feature in the app's development environment while working on improvements, so that API calls are not being consumed unnecessarily and the team can continue developing and testing without exceeding the rate limit.\n",
      "--------------------------------Question 44--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : Assume you are working on SuperQuiz, a trendy app that lets everyone design quizzes and share them with friends! Your first assignment is to add a new feature that is requested by users. You are given the following transcript of an interview with a customer of your product:\n",
      "> Hi!\n",
      "> So you're the developer of this quiz app?\n",
      "> The one where you write questions and answers and get your friends to guess?\n",
      "> It's fun, but I can't use it as much as I'd like.\n",
      "> I'm a firefighter, I don't have time for this app during the day, but I wish I could use it at home.\n",
      "> See, when I come back home after work, I have a bunch of stuff to do, cleaning, cooking, ...\n",
      "> And when I'm doing these tasks, I'm rather busy. Not like when I'm watching TV.\n",
      "> I don't always have my phone in my hands! Sometimes I even forget where I put it.\n",
      "> Maybe if you made it so I could talk to the app? You know, many apps have that feature now.\n",
      "> Then I could multitask! Think about quizzes while I'm cooking!\n",
      "> Otherwise, I won't use the app much.\n",
      "\n",
      "Write down a user story, as a single sentence that follows the following guidelines:\n",
      "1) A user story that summarizes all necessary information from the feedback\n",
      "2) the user story does not contain any unnecessary information\n",
      "[SOLUTION] : \n",
      "As a firefighter user, I want to be able to use the quiz app hands-free by implementing voice command functionality, so that I can multitask and enjoy the app while doing chores at home.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Assume you are working on SuperQuiz, a trendy app that lets everyone design quizzes and share them with friends! Your first assignment is to add a new feature that is requested by users. You are given the following transcript of an interview with a customer of your product:\n",
      "> Hi!\n",
      "> So you're the developer of this quiz app?\n",
      "> The one where you write questions and answers and get your friends to guess?\n",
      "> It's fun, but I can't use it as much as I'd like.\n",
      "> I'm a firefighter, I don't have time for this app during the day, but I wish I could use it at home.\n",
      "> See, when I come back home after work, I have a bunch of stuff to do, cleaning, cooking, ...\n",
      "> And when I'm doing these tasks, I'm rather busy. Not like when I'm watching TV.\n",
      "> I don't always have my phone in my hands! Sometimes I even forget where I put it.\n",
      "> Maybe if you made it so I could talk to the app? You know, many apps have that feature now.\n",
      "> Then I could multitask! Think about quizzes while I'm cooking!\n",
      "> Otherwise, I won't use the app much.\n",
      "\n",
      "Write down a user story, as a single sentence that follows the following guidelines:\n",
      "1) A user story that summarizes all necessary information from the feedback\n",
      "2) the user story does not contain any unnecessary information\n",
      "\"As a firefighter user, I want to be able to use the quiz app hands-free through voice commands so that I can multitask and engage with the app while doing household chores.\"\n",
      "--------------------------------Question 45--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : Considering a sequence of n tokens, the computational complexity of the masked attention mechanism in BERT language models is: (select the smallest correct complexity)\n",
      "[ ] O(n^3)\n",
      "[ ] O(nlog(n))\n",
      "[ ] O(n)\n",
      "[ ] O(n^(1/2))\n",
      "[ ] O(n^2)\n",
      "[SOLUTION] : Masked attention is quadratic in the sequence length n because it computes the attention between all pairs of tokens, therefore O(n^2).\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Tick the \\emph{incorrect} statement. When $x\\rightarrow+\\infty$ \\ldots\n",
      "[ ] $x^3 + 2x + 5 = \\mathcal{O}(x^3)$.\n",
      "[ ] $\\frac{1}{x^2} = \\mathcal{O}(\\frac{1}{x})$.\n",
      "[ ] $2^{\\frac{x}{\\log x}} = \\mathcal{O}(2^x)$.\n",
      "[ ] $n^x = \\mathcal{O}(x^n)$ for any constant $n>1$.\n",
      "[SOLUTION] : \n",
      "The incorrect statement is: $n^x = \\mathcal{O}(x^n)$ for any constant $n>1$. This is not true as $n^x$ grows faster than $x^n$ for any constant $n>1$ as $x\\rightarrow+\\infty$.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Tick the \\emph{incorrect} statement. When $x\\rightarrow+\\infty$ \\ldots\n",
      "[ ] $x^3 + 2x + 5 = \\mathcal{O}(x^3)$.\n",
      "[ ] $\\frac{1}{x^2} = \\mathcal{O}(\\frac{1}{x})$.\n",
      "[ ] $2^{\\frac{x}{\\log x}} = \\mathcal{O}(2^x)$.\n",
      "[ ] $n^x = \\mathcal{O}(x^n)$ for any constant $n>1$.\n",
      "The incorrect statement is: \n",
      "\n",
      "[ ] $n^x = \\mathcal{O}(x^n)$ for any constant $n>1$. \n",
      "\n",
      "This statement is incorrect because $n^x$ grows faster than $x^n$ for any constant $n>1$ as $x\\rightarrow+\\infty$.\n",
      "--------------------------------Question 46--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Tick the \\emph{incorrect} assertion regarding the Diffie-Hellman key exchange\n",
      "[ ] It is secure under a passive adversary.\n",
      "[ ] It is secure when working in a subgroup of $\\mathbb{Z}_p^*$ of big prime order.\n",
      "[ ] It is secure under an active Man-In-The-Middle attack.\n",
      "[ ] It is not secure when working in $\\mathbb{Z}_n$ with $n$ having only small prime factors.\n",
      "[SOLUTION] : \n",
      "It is secure under an active Man-In-The-Middle attack. \n",
      "\n",
      "The Diffie-Hellman key exchange is vulnerable to a Man-In-The-Middle attack if an adversary intercepts the communication between the two parties and establishes separate key exchanges with each party, allowing them to decrypt and read the messages.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Tick the \\emph{incorrect} assertion regarding the Diffie-Hellman key exchange\n",
      "[ ] It is secure under a passive adversary.\n",
      "[ ] It is secure when working in a subgroup of $\\mathbb{Z}_p^*$ of big prime order.\n",
      "[ ] It is secure under an active Man-In-The-Middle attack.\n",
      "[ ] It is not secure when working in $\\mathbb{Z}_n$ with $n$ having only small prime factors.\n",
      "The \\emph{incorrect} assertion regarding the Diffie-Hellman key exchange is:\n",
      "\n",
      "\\[ \\text{\\textbf{[ ] It is secure under an active Man-In-The-Middle attack.}} \\]\n",
      "\n",
      "Diffie-Hellman key exchange is vulnerable to Man-In-The-Middle attacks if not properly authenticated.\n",
      "--------------------------------Question 47--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : Can we devise a Best-effort Broadcast algorithm that satisfies the causal delivery property, without being a causal broadcast algorithm, i.e., without satisfying the agreement property of a reliable broadcast?\n",
      "[SOLUTION] : \n",
      "Yes, it is possible to devise a Best-effort Broadcast algorithm that satisfies the causal delivery property without being a causal broadcast algorithm. In a Best-effort Broadcast algorithm, messages are delivered to all correct processes in the system, but there is no guarantee of agreement on the order of delivery. By implementing causal delivery, messages are delivered in a causal order, meaning that if message m1 causally precedes message m2, then m1 will be delivered before m2. However, without satisfying the agreement property of a reliable broadcast, there is no guarantee that all correct processes will deliver the same set of messages in the same order. This allows for some flexibility in the delivery order while still ensuring causal consistency.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Can we devise a Best-effort Broadcast algorithm that satisfies the causal delivery property, without being a causal broadcast algorithm, i.e., without satisfying the agreement property of a reliable broadcast?\n",
      "Yes, we can devise a Best-effort Broadcast algorithm that satisfies the causal delivery property without being a causal broadcast algorithm. In a Best-effort Broadcast algorithm, messages are delivered to all correct processes in the system, but there is no guarantee of the order in which messages are delivered. \n",
      "\n",
      "To achieve causal delivery in a Best-effort Broadcast algorithm, we can use a causal ordering of messages based on the happened-before relation. When a process broadcasts a message, it includes the causal information of the message, such as the message itself and the timestamp indicating the order in which events occurred. Upon receiving a message, a process delivers it only if all preceding messages in the causal order have been delivered.\n",
      "\n",
      "This approach ensures that messages are delivered in a causally consistent order, satisfying the causal delivery property. However, since Best-effort Broadcast does not guarantee agreement, there may be cases where different processes have different sets of delivered messages due to message losses or failures.\n",
      "--------------------------------Question 48--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Tick the \\textbf{false} statement : \n",
      "[ ] As a defender of a machine learning model you should be more worried about black-box effective attacks than white-box effective attacks.\n",
      "[ ] Privacy problems in machine learning stem solely from the need for data to train models.\n",
      "[ ] Poisoning attacks can be used to increase vulnerability to adversarial examples.\n",
      "[SOLUTION] : The false statement is : Privacy problems in machine learning stem solely from the need for data to train models. Data collection for training is one of many privacy attack vectors in machine learning. There exist attacks on models and outputs; and naturally exposing data for test is a risk in itself. The first statement is true, an adversary performing a black-box attack needs much less resources and capabilities than a white-box adversary. This is much more dangerous, as the adversary only needs the ability to interact with the model. The last statement is also true because by providing poisoning inputs, the adversary gets to shape the boundaries of the model. Thus, she can carve this boundary to facilitate classification errors. In fact, you can understand a backdoor attack as a particular instance of an adversarial example.\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : Select the \\emph{incorrect} statement. Pedersen Commitment is\n",
      "[ ] unconditionally hiding.\n",
      "[ ] computationally binding.\n",
      "[ ] based on the hardness of the discrete logarithm problem.\n",
      "[ ] based on DSA.\n",
      "[SOLUTION] : \n",
      "The incorrect statement is: based on DSA. Pedersen Commitment is not based on the Digital Signature Algorithm (DSA), but rather on the hardness of the discrete logarithm problem.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Select the \\emph{incorrect} statement. Pedersen Commitment is\n",
      "[ ] unconditionally hiding.\n",
      "[ ] computationally binding.\n",
      "[ ] based on the hardness of the discrete logarithm problem.\n",
      "[ ] based on DSA.\n",
      "The incorrect statement is:\n",
      "[ ] based on DSA.\n",
      "\n",
      "Pedersen Commitment is not based on DSA; it is based on the hardness of the discrete logarithm problem.\n",
      "--------------------------------Question 49--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : The goal of the 4 following questions is to prove that the methods map and mapTr are equivalent. The\n",
      "former is the version seen in class and is specified by the lemmas MapNil and MapCons. The later version\n",
      "is a tail-recursive version and is specified by the lemmas MapTrNil and MapTrCons.\n",
      "All lemmas on this page hold for all x: Int, y: Int, xs: List[Int], ys: List[Int], l: List\n",
      "[Int] and f: Int => Int.\n",
      "Given the following lemmas:\n",
      "\n",
      "(MapNil) Nil.map(f) === Nil\n",
      "(MapCons) (x :: xs).map(f) === f(x) :: xs.map(f)\n",
      "(MapTrNil) Nil.mapTr(f, ys) === ys\n",
      "(MapTrCons) (x :: xs).mapTr(f, ys) === xs.mapTr(f, ys ++ (f(x) :: Nil))\n",
      "(NilAppend) Nil ++ xs === xs\n",
      "(ConsAppend) (x :: xs) ++ ys === x :: (xs ++ ys)\n",
      "Let us first prove the following lemma:\n",
      "\n",
      "(AccOut) l.mapTr(f, y :: ys) === y :: l.mapTr(f, ys)\n",
      "\n",
      "We prove it by induction on l.\n",
      "Induction step: l is x :: xs. Therefore, we need to prove:\n",
      "(x :: xs).mapTr(f, y :: ys) === y :: (x :: xs).mapTr(f, ys)\n",
      "\n",
      "We name the induction hypothesis IH.\n",
      "What exact sequence of lemmas should we apply to rewrite the left hand-side ((x :: xs).mapTr(f, y\n",
      ":: ys)) to the right hand-side (y :: (x :: xs).mapTr(f, ys))?\n",
      "[SOLUTION] : \n",
      "To rewrite the left hand-side ((x :: xs).mapTr(f, y :: ys)) to the right hand-side (y :: (x :: xs).mapTr(f, ys)), we should apply the following sequence of lemmas:\n",
      "\n",
      "1. (MapTrCons) - Apply (x :: xs).mapTr(f, y :: ys) = xs.mapTr(f, y :: ys ++ (f(x) :: Nil)) by using (MapTrCons) with x = x, xs = xs, f = f, ys = y :: ys.\n",
      "2. (ConsAppend) - Simplify ys ++ (f(x) :: Nil) to y :: (ys ++ (f(x) :: Nil)) by using (ConsAppend) with x = y, xs = ys, ys = f(x) :: Nil.\n",
      "3. (IH) - Substitute xs.mapTr(f, y :: (ys ++ (f(x) :: Nil))) with y :: xs.mapTr(f, ys) using the induction hypothesis (IH).\n",
      "\n",
      "By applying this sequence of lemmas, we can rewrite the left hand-side to the right hand-side as required.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "The goal of the 4 following questions is to prove that the methods map and mapTr are equivalent. The\n",
      "former is the version seen in class and is specified by the lemmas MapNil and MapCons. The later version\n",
      "is a tail-recursive version and is specified by the lemmas MapTrNil and MapTrCons.\n",
      "All lemmas on this page hold for all x: Int, y: Int, xs: List[Int], ys: List[Int], l: List\n",
      "[Int] and f: Int => Int.\n",
      "Given the following lemmas:\n",
      "\n",
      "(MapNil) Nil.map(f) === Nil\n",
      "(MapCons) (x :: xs).map(f) === f(x) :: xs.map(f)\n",
      "(MapTrNil) Nil.mapTr(f, ys) === ys\n",
      "(MapTrCons) (x :: xs).mapTr(f, ys) === xs.mapTr(f, ys ++ (f(x) :: Nil))\n",
      "(NilAppend) Nil ++ xs === xs\n",
      "(ConsAppend) (x :: xs) ++ ys === x :: (xs ++ ys)\n",
      "Let us first prove the following lemma:\n",
      "\n",
      "(AccOut) l.mapTr(f, y :: ys) === y :: l.mapTr(f, ys)\n",
      "\n",
      "We prove it by induction on l.\n",
      "Induction step: l is x :: xs. Therefore, we need to prove:\n",
      "(x :: xs).mapTr(f, y :: ys) === y :: (x :: xs).mapTr(f, ys)\n",
      "\n",
      "We name the induction hypothesis IH.\n",
      "What exact sequence of lemmas should we apply to rewrite the left hand-side ((x :: xs).mapTr(f, y\n",
      ":: ys)) to the right hand-side (y :: (x :: xs).mapTr(f, ys))?\n",
      "To rewrite the left hand-side ((x :: xs).mapTr(f, y :: ys)) to the right hand-side (y :: (x :: xs).mapTr(f, ys)), we can follow these steps using the provided lemmas:\n",
      "\n",
      "1. Apply the MapTrCons lemma with x, xs, f, and (y :: ys) as arguments:\n",
      "   - (x :: xs).mapTr(f, y :: ys) === xs.mapTr(f, y :: ys ++ (f(x) :: Nil))\n",
      "\n",
      "2. Apply the definition of list concatenation (ConsAppend) to the right-hand side:\n",
      "   - xs.mapTr(f, y :: ys ++ (f(x) :: Nil)) === xs.mapTr(f, y :: (ys ++ (f(x) :: Nil)))\n",
      "\n",
      "3. Apply the induction hypothesis (AccOut) with xs, f, y, and ys as arguments:\n",
      "   - xs.mapTr(f, y :: (ys ++ (f(x) :: Nil))) === y :: xs.mapTr(f, ys ++ (f(x) :: Nil))\n",
      "\n",
      "Therefore, the exact sequence of lemmas to apply to rewrite the left-hand side to the right-hand side is as follows:\n",
      "MapTrCons, ConsAppend, AccOut.\n",
      "--------------------------------Question 50--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : A rigid and homogeneous horizontal rod of mass M, of length L, of negligible thickness e, i.e. e << L, is rotating in a horizontal plane around the vertical axis $C e_3$ at angular velocity $\\Omega=\\dot{\\psioldsymbol{e}3$. The moment of inertia of the rod with respect to the vertical principal axis that contains its centre of mass G is $I{G,3}=\frac1{12}ML^{2}$. Let C be the point of contact between the extremity of the rod and the rotation axis, and P the point at the other extremity. The unit vector $e_1$ is oriented along the rod and the vector $e_2$ is orthogonal to $e_1$. The unit vectors $e_1$, $e_2$ and $e_3$, attached to the rod at point C, are the principal axis frame of the rod. We consider that there is no friction and we do not take explicitly into account the influence of the gravitational field. Give the expression of the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis of rotation $C e_3$ in terms of the scalar quantities M and L.\n",
      "[SOLUTION] : Applying the Huygens-Steiner theorem, we determine the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis $C e_3$ taking into account the fact that d = L/2 is the distance separating points G and C and that $I_{G,3}=\frac1{12}ML^{2}$,\n",
      "ight)^2=\frac{1}{12}ML^2+\frac{1}{4}ML^2=\frac{1}{3}ML^2$\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : When you're running and you need to stop all of a sudden, where does the force stopping you come from?\n",
      "\n",
      "\n",
      "[SOLUTION] : \n",
      "When you need to stop all of a sudden while running, the force stopping you comes from the friction between your feet and the ground. As you decelerate, the force of friction between your shoes and the ground acts in the opposite direction of your motion, helping to bring you to a stop. This force of friction converts your kinetic energy into heat and work, ultimately allowing you to come to a halt.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "When you're running and you need to stop all of a sudden, where does the force stopping you come from?\n",
      "\n",
      "\n",
      "When you need to stop suddenly while running, the force that stops you comes from a combination of factors:\n",
      "\n",
      "1. **Friction**: The primary force that stops you is friction between your feet and the ground. As you apply a braking force by pushing your feet backward against the ground, the friction between your shoes and the ground helps to slow you down.\n",
      "\n",
      "2. **Muscular force**: Your muscles also play a significant role in stopping your body's forward motion. When you decide to stop, your leg muscles contract to generate the force needed to slow down and eventually come to a stop.\n",
      "\n",
      "3. **Inertia**: Inertia is the tendency of an object to resist changes in its motion. When you stop suddenly, your body's inertia is also a factor that needs to be overcome by the force exerted by your muscles and the friction with the ground.\n",
      "\n",
      "Overall, the force that stops you when running comes from a combination of friction, muscular force, and overcoming your body's inertia.\n",
      "--------------------------------Question 51--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : Assume that you are part of a team developing a mobile app using Scrum.\n",
      "When using the app, you identified multiple bugs and features which you think should be implemented, and took some notes. You want to\n",
      "share these with the Product Owner. Your backlog of tasks includes the following task:\n",
      "- [ ] [Bug] The landing page doesn't render well, if the language of my device is not English.\n",
      "Is this item suitable to be submitted to the Product Backlog? Why?\n",
      "[SOLUTION] : \n",
      "Yes, this item is suitable to be submitted to the Product Backlog. The Product Backlog is a list of all desired work on the project, and includes bugs, new features, improvements, and other tasks. Identifying a bug in the landing page that affects the user experience is important for the Product Owner to be aware of and prioritize for fixing. By adding it to the Product Backlog, the team can track and address this issue in future sprints.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Assume that you are part of a team developing a mobile app using Scrum.\n",
      "When using the app, you identified multiple bugs and features which you think should be implemented, and took some notes. You want to\n",
      "share these with the Product Owner. Your backlog of tasks includes the following task:\n",
      "- [ ] [Bug] The landing page doesn't render well, if the language of my device is not English.\n",
      "Is this item suitable to be submitted to the Product Backlog? Why?\n",
      "Yes, the item \"The landing page doesn't render well if the language of my device is not English\" is suitable to be submitted to the Product Backlog. \n",
      "\n",
      "In Scrum, the Product Backlog is a prioritized list of all the work to be done on the project. It contains all features, bugs, improvements, and any other tasks that need to be addressed. The purpose of the Product Backlog is to ensure transparency and provide a clear understanding of the work that needs to be done.\n",
      "\n",
      "Since the item you mentioned is a bug that affects the functionality of the app, it is important to have it recorded in the Product Backlog so that it can be prioritized, estimated, and eventually worked on by the development team. This will allow the Product Owner to understand the issues that users are facing and prioritize them accordingly.\n",
      "--------------------------------Question 52--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : Which of the following is equivalent to \\((10001)_2\\) ? (Multiple answers can be correct)\n",
      "[ ] \\(  (17)_{10}  \\)\n",
      "[ ] \\(  (F0)_{16}  \\)\n",
      "[ ] \\(  (23)_{8}  \\)\n",
      "[ ] \\(  (101)_{4}  \\)\n",
      "[SOLUTION] : \n",
      "[ ] \\(  (17)_{10}  \\)\n",
      "[ ] \\(  (F0)_{16}  \\)\n",
      "[x] \\(  (23)_{8}  \\)\n",
      "[ ] \\(  (101)_{4}  \\)\n",
      "\n",
      "To convert \\( (10001)_2 \\) to base 10, we can use the formula \\( \\sum_{i=0}^{n} d_i \\times 2^i \\), where \\( d_i \\) is the digit at position i. This gives us \\( 1 \\times 2^4 + 0 \\times 2^3 + 0 \\times 2^2 + 0 \\times 2^1 + 1 \\times 2^0 = 16 + 1 = 17 \\).\n",
      "\n",
      "To convert \\( (10001)_2 \\) to base 8, we can group the binary digits into groups of 3 (starting from the right) and convert each group to base 8. This gives us \\( (23)_8 \\).\n",
      "\n",
      "To convert \\( (10001)_2 \\) to base 4, we can group the binary digits into groups of 2 (starting from the right) and convert each group to base 4. This gives us \\( (101)_4 \\).\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Which of the following is equivalent to \\((10001)_2\\) ? (Multiple answers can be correct)\n",
      "[ ] \\(  (17)_{10}  \\)\n",
      "[ ] \\(  (F0)_{16}  \\)\n",
      "[ ] \\(  (23)_{8}  \\)\n",
      "[ ] \\(  (101)_{4}  \\)\n",
      "To convert the binary number \\((10001)_2\\) to decimal, we can use the positional notation of the binary system. \n",
      "\n",
      "\\((10001)_2 = 1*2^4 + 0*2^3 + 0*2^2 + 0*2^1 + 1*2^0 = 16 + 1 = 17\\)\n",
      "\n",
      "So, the decimal equivalent of \\((10001)_2\\) is \\( (17)_{10} \\).\n",
      "\n",
      "Therefore, the correct answer is:\n",
      "[ ] \\(  (17)_{10}  \\)\n",
      "--------------------------------Question 53--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Tick the false assertion. Bluetooth ... \n",
      "[ ] uses a stream cipher for encryption.\n",
      "[ ] has secure integrity protection for secure communication.\n",
      "[ ] has devices which use the same secret key with any other device.uses the SAFER+ block cipher in a one-way mode.\n",
      "[SOLUTION] : The false assertion is : has secure integrity protection for secure communication. Bluetooth is indeed a secure protocol which relies on the E0 stream cipher for privacy. In Bluetooth, the encryption process involves the Long Term Key (LTK), which is a secret key shared and stored by both connected devices. Bluetooth implements confidentiality, authentication and key derivation with custom algorithms based on a SAFER+ block cipher\n",
      "[QUESTION] : Considering a sequence of n tokens, the computational complexity of the masked attention mechanism in BERT language models is: (select the smallest correct complexity)\n",
      "[ ] O(n^3)\n",
      "[ ] O(nlog(n))\n",
      "[ ] O(n)\n",
      "[ ] O(n^(1/2))\n",
      "[ ] O(n^2)\n",
      "[SOLUTION] : Masked attention is quadratic in the sequence length n because it computes the attention between all pairs of tokens, therefore O(n^2).\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : How many different simple substitution ciphers do exist with respect to an alphabet of 26 characters?\n",
      "[ ] $26!$\n",
      "[ ] $2^{26}$\n",
      "[ ] $26^2$\n",
      "[ ] 26\n",
      "[SOLUTION] : \n",
      "There are $26!$ different simple substitution ciphers that exist with respect to an alphabet of 26 characters. This is because each letter in the alphabet can be replaced by any of the other 25 letters, and there are 26 letters in total.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "How many different simple substitution ciphers do exist with respect to an alphabet of 26 characters?\n",
      "[ ] $26!$\n",
      "[ ] $2^{26}$\n",
      "[ ] $26^2$\n",
      "[ ] 26\n",
      "To create a simple substitution cipher, we need to assign each letter in the alphabet a unique corresponding letter. Since there are 26 letters in the alphabet, the first letter can be assigned to any of the 26 letters, the second letter can be assigned to any of the remaining 25 letters, and so on.\n",
      "\n",
      "Therefore, the total number of different simple substitution ciphers that can be created with respect to an alphabet of 26 characters is $26!$, which is the total number of permutations of 26 distinct objects.\n",
      "\n",
      "So, the correct answer is:\n",
      "[ ] $26!$\n",
      "--------------------------------Question 54--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Considering a sequence of n tokens, the computational complexity of the masked attention mechanism in BERT language models is: (select the smallest correct complexity)\n",
      "[ ] O(n^3)\n",
      "[ ] O(nlog(n))\n",
      "[ ] O(n)\n",
      "[ ] O(n^(1/2))\n",
      "[ ] O(n^2)\n",
      "[SOLUTION] : Masked attention is quadratic in the sequence length n because it computes the attention between all pairs of tokens, therefore O(n^2).\n",
      "[QUESTION] : In a challenge/response protocol,\\dots\n",
      "[ ] the secret is sent in clear over the channel.\n",
      "[ ] the response is derived using a pseudo-random function.\n",
      "[ ] the response is a hash of the secret (i.e., $h(w)$ for a secret $w$).\n",
      "[ ] the size of the challenge space can be 1.\n",
      "[SOLUTION] : \n",
      "In a challenge/response protocol, the response is derived using a pseudo-random function.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "In a challenge/response protocol,\\dots\n",
      "[ ] the secret is sent in clear over the channel.\n",
      "[ ] the response is derived using a pseudo-random function.\n",
      "[ ] the response is a hash of the secret (i.e., $h(w)$ for a secret $w$).\n",
      "[ ] the size of the challenge space can be 1.\n",
      "- [ ] the secret is sent in clear over the channel.\n",
      "- [x] the response is derived using a pseudo-random function.\n",
      "- [ ] the response is a hash of the secret (i.e., $h(w)$ for a secret $w$).\n",
      "- [ ] the size of the challenge space can be 1.\n",
      "\n",
      "In a challenge/response protocol, the response is typically derived using a pseudo-random function. This ensures that the response cannot be easily predicted or forged by an attacker, even if they know the challenge and the protocol details. Sending the secret in clear over the channel is not recommended for security reasons, and having a challenge space of size 1 would not provide much variability or security in the protocol.\n",
      "--------------------------------Question 55--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : A rigid and homogeneous horizontal rod of mass M, of length L, of negligible thickness e, i.e. e << L, is rotating in a horizontal plane around the vertical axis $C e_3$ at angular velocity $\\Omega=\\dot{\\psioldsymbol{e}3$. The moment of inertia of the rod with respect to the vertical principal axis that contains its centre of mass G is $I{G,3}=\frac1{12}ML^{2}$. Let C be the point of contact between the extremity of the rod and the rotation axis, and P the point at the other extremity. The unit vector $e_1$ is oriented along the rod and the vector $e_2$ is orthogonal to $e_1$. The unit vectors $e_1$, $e_2$ and $e_3$, attached to the rod at point C, are the principal axis frame of the rod. We consider that there is no friction and we do not take explicitly into account the influence of the gravitational field. Give the expression of the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis of rotation $C e_3$ in terms of the scalar quantities M and L.\n",
      "[SOLUTION] : Applying the Huygens-Steiner theorem, we determine the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis $C e_3$ taking into account the fact that d = L/2 is the distance separating points G and C and that $I_{G,3}=\frac1{12}ML^{2}$,\n",
      "ight)^2=\frac{1}{12}ML^2+\frac{1}{4}ML^2=\frac{1}{3}ML^2$\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : Consider the following contains function defined on Iterable (in particular, it accepts both Vector and List).  def contains[A](l: Iterable[A], elem: A): Boolean =   val n = l.size   if n <= 5 then     for i <- l do       if i == elem then         return true     false   else     val (p0, p1) = parallel(       contains(l.take(n / 2), elem),       contains(l.drop(n / 2), elem)     )   p0 || p1 Let $n$$n$ be the size of l. Assume that drop and take run in $\\Theta(1)$ on Vector and $\\Theta(n)$ on List. What is the asymptotic depth of contains if it is called on a List?\n",
      "[SOLUTION] : \n",
      "The asymptotic depth of the contains function when called on a List is O(log n), where n is the size of the list. This is because the function recursively splits the list into halves and searches for the element in each half, effectively reducing the search space by half in each recursive call. Since each split operation takes O(n) time on a List, the depth of the recursion tree will be logarithmic in the size of the list.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Consider the following contains function defined on Iterable (in particular, it accepts both Vector and List).  def contains[A](l: Iterable[A], elem: A): Boolean =   val n = l.size   if n <= 5 then     for i <- l do       if i == elem then         return true     false   else     val (p0, p1) = parallel(       contains(l.take(n / 2), elem),       contains(l.drop(n / 2), elem)     )   p0 || p1 Let $n$$n$ be the size of l. Assume that drop and take run in $\\Theta(1)$ on Vector and $\\Theta(n)$ on List. What is the asymptotic depth of contains if it is called on a List?\n",
      "To determine the asymptotic depth of the `contains` function when called on a List, let's analyze the recursive structure and depth of the function.\n",
      "\n",
      "Given that `drop` and `take` run in $\\Theta(n)$ on a List, the `contains` function splits the List in half at each recursive step, leading to a binary tree structure.\n",
      "\n",
      "At each depth of the recursive tree, the size of the List is halved. Therefore, the depth of the recursive tree is $\\log_2(n)$, where $n$ is the size of the List.\n",
      "\n",
      "Since the function performs a parallel recursive call at each level of the tree, the asymptotic depth of the `contains` function when called on a List is $\\Theta(\\log(n))$.\n",
      "\n",
      "Therefore, the asymptotic depth of the `contains` function when called on a List is logarithmic, specifically $\\Theta(\\log(n))$.\n",
      "--------------------------------Question 56--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : A yoyo is made up of a disk of radius $R$ and mass $M$, around which a massless thread is wound up. The thread is attached to the ceiling and remains constantly vertical; gravity acts on the yo-yo which is free to lower down.\n",
      "\n",
      "Find the acceleration $\\vec{a}$ of the yo-yo's center of mass, as well as the thread's tension $\\vec{T}$.\n",
      "\n",
      "[SOLUTION] : \n",
      "Let's denote the tension in the string as $T$ and the acceleration of the yo-yo's center of mass as $a$. The forces acting on the yo-yo are the tension in the string $T$, the gravitational force $mg$, and the normal force $N$ from the ceiling.\n",
      "\n",
      "The net force acting on the yo-yo in the vertical direction is given by $T - mg = Ma$, where $M$ is the mass of the yo-yo.\n",
      "\n",
      "Since the yo-yo is not accelerating horizontally, the net force in the horizontal direction is zero.\n",
      "\n",
      "The tension in the string is providing the centripetal force required to keep the yo-yo in a circular motion. This force is given by $T = \\frac{Mv^2}{R}$, where $v$ is the linear velocity of the yo-yo.\n",
      "\n",
      "Combining the equations, we get $T - mg = Ma$ and $T = \\frac{Mv^2}{R}$.\n",
      "\n",
      "Solving these equations simultaneously, we can find the acceleration $a$ of the yo-yo's center of mass and the tension $T$ in the string.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "A yoyo is made up of a disk of radius $R$ and mass $M$, around which a massless thread is wound up. The thread is attached to the ceiling and remains constantly vertical; gravity acts on the yo-yo which is free to lower down.\n",
      "\n",
      "Find the acceleration $\\vec{a}$ of the yo-yo's center of mass, as well as the thread's tension $\\vec{T}$.\n",
      "\n",
      "To solve this problem, we can consider the forces acting on the yo-yo. The forces acting on the yo-yo are the tension force $\\vec{T}$ of the thread and the force of gravity $\\vec{F}_g = -Mg\\hat{j}$, where $g$ is the acceleration due to gravity and $\\hat{j}$ is the unit vector in the vertical direction.\n",
      "\n",
      "The acceleration of the yo-yo's center of mass can be found using Newton's second law:\n",
      "\n",
      "$$\\sum \\vec{F} = M\\vec{a}$$\n",
      "\n",
      "The forces acting in the vertical direction are the tension force $\\vec{T}$ and the force of gravity $\\vec{F}_g$. Since the yo-yo is free to lower down, the acceleration will be in the downward direction, so we can write the equation as:\n",
      "\n",
      "$$\\vec{T} + \\vec{F}_g = M\\vec{a}$$\n",
      "\n",
      "Breaking this equation into its components, we get:\n",
      "\n",
      "$$T - Mg = Ma$$\n",
      "\n",
      "Solving for the acceleration $a$, we get:\n",
      "\n",
      "$$a = \\frac{T - Mg}{M}$$\n",
      "\n",
      "To find the tension in the thread, we can use the rotational dynamics of the yo-yo. The torque due to the tension in the thread will cause the yo-yo to rotate. The torque $\\tau$ is given by:\n",
      "\n",
      "$$\\tau = I\\alpha$$\n",
      "\n",
      "where $I$ is the moment of inertia of the yo-yo and $\\alpha$ is the angular acceleration. For a disk rotating about its center, the moment of inertia is $I = \\frac{1}{2}MR^2$.\n",
      "\n",
      "The torque causing the rotation is due to the tension in the thread and can be written as:\n",
      "\n",
      "$$\\tau = TR$$\n",
      "\n",
      "The angular acceleration $\\alpha$ is related to the linear acceleration $a$ by $\\alpha = \\frac{a}{R}$. Substituting these into the torque equation, we get:\n",
      "\n",
      "$$TR = \\frac{1}{2}MR^2 \\frac{a}{R}$$\n",
      "\n",
      "Solving for the tension $T$, we get:\n",
      "\n",
      "$$T = \\frac{1}{2}Ma + Mg$$\n",
      "\n",
      "Substitute the expression for acceleration $a$ we found earlier, we get:\n",
      "\n",
      "$$T = \\frac{3}{2}Mg$$\n",
      "\n",
      "Therefore, the acceleration of the yo-yo's center of mass is $a = \\frac{1}{2}g$ and the tension in the thread is $T = \\frac{3}{2}Mg$.\n",
      "--------------------------------Question 57--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : (Gradient Descent) When training a Deep Neural Network, it is better to use classical gradient descent rather than stochastic gradient descent with mini-batches to optimize the parameters of the network.\n",
      "[ ] True\n",
      "[ ] False\n",
      "[SOLUTION] : False. Deep Learning requires large datasets, and going through all of the data to compute a full gradient is unnecessarily expensive, compared to many cheaper SGD steps. In addition, noisy updates for several reasons seem to perform better in the non-convex landscapes stemming from deep learning training.\n",
      "[QUESTION] : (EM Algorithm) The Expectation-Maximization (EM) algorithm is guaranteed to converge to the global maximum likelihood solution for fitting GMMs.\n",
      "[ ] True\n",
      "[ ] False\n",
      "[SOLUTION] : False. The EM algorithm for GMMs may converge to a local maximum likelihood solution, not necessarily the global maximum likelihood solution.\n",
      "[QUESTION] : (Linear regression) For linear regression with no regularization, scaling the features (e.g. as in data normalization) does not change the model's performance, assuming that we can efficiently compute the optimum model in both cases, i.e. numerical stability/efficiency of finding the optimum model is not a concern.\n",
      "[ ] True\n",
      "[ ] False\n",
      "[SOLUTION] : True. Linear regression models are scale invariant when there is no regularization. The model will learn the same relationship between inputs and outputs regardless of the scale of the data.\n",
      "ightarrow \\R^k$ such that for all $(x, x') \\in \\R \times \\R $, $K(x, x') =  \\Phi(x)^\top \\Phi(x')$. The kernel $K(x, x') = \\cos(x + x')$ is a valid kernel.\n",
      "[ ] True\n",
      "[ ] False\n",
      "[SOLUTION] : \n",
      "False. The kernel $K(x, x') = \\cos(x + x')$ is not a valid kernel because it does not satisfy Mercer's condition for positive definiteness.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "ightarrow \\R^k$ such that for all $(x, x') \\in \\R \times \\R $, $K(x, x') =  \\Phi(x)^\top \\Phi(x')$. The kernel $K(x, x') = \\cos(x + x')$ is a valid kernel.\n",
      "[ ] True\n",
      "[ ] False\n",
      "To show that the kernel $K(x, x') = \\cos(x + x')$ is a valid kernel, we need to find an integer $k$ and a feature map $\\Phi: \\R \\rightarrow \\R^k$ such that for all $(x, x') \\in \\R \\times \\R$, we have $K(x, x') = \\Phi(x)^T \\Phi(x')$.\n",
      "\n",
      "Let's try to express $K(x, x') = \\cos(x + x')$ in terms of an inner product. We know that $\\cos(\\theta) = \\frac{1}{2} (e^{i\\theta} + e^{-i\\theta})$.\n",
      "\n",
      "Therefore, we can write:\n",
      "$$\n",
      "K(x, x') = \\cos(x + x') = \\frac{1}{2} (e^{i(x + x')} + e^{-i(x + x')})\n",
      "$$\n",
      "\n",
      "Now, let's define the feature map $\\Phi: \\R \\rightarrow \\R^2$ as follows:\n",
      "$$\n",
      "\\Phi(x) = \\begin{bmatrix} \\cos(x) \\\\ \\sin(x) \\end{bmatrix}\n",
      "$$\n",
      "\n",
      "Then, we have:\n",
      "$$\n",
      "\\Phi(x)^T \\Phi(x') = \\begin{bmatrix} \\cos(x) & \\sin(x) \\end{bmatrix} \\begin{bmatrix} \\cos(x') \\\\ \\sin(x') \\end{bmatrix} = \\cos(x)\\cos(x') + \\sin(x)\\sin(x') = \\cos(x - x')\n",
      "$$\n",
      "\n",
      "Therefore, by setting $k = 2$ and using the feature map $\\Phi(x) = \\begin{bmatrix} \\cos(x) \\\\ \\sin(x) \\end{bmatrix}$, we can express $K(x, x') = \\cos(x + x')$ as an inner product of the feature map, which means that $K(x, x') = \\cos(x + x')$ is a valid kernel.\n",
      "\n",
      "So, the statement is:\n",
      "[ ] True\n",
      "[✔] False\n",
      "--------------------------------Question 58--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : If process i fails, then eventually all processes j≠i fail\n",
      "Is the following true? If no process j≠i fails, then process i has not failed\n",
      "[SOLUTION] : \n",
      "No, the statement is not necessarily true. Just because all processes j≠i have not failed does not guarantee that process i has not failed. Process i could have failed for reasons unrelated to the other processes failing. The failure of process i could be due to hardware issues, software bugs, or other factors.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "If process i fails, then eventually all processes j≠i fail\n",
      "Is the following true? If no process j≠i fails, then process i has not failed\n",
      "No, the statement is not necessarily true. The given statement is: \"If process i fails, then eventually all processes j≠i fail.\" This means that if process i fails, then all other processes will eventually fail as well.\n",
      "\n",
      "The second part of the statement is: \"If no process j≠i fails, then process i has not failed.\" This does not necessarily follow from the first part. It is possible for process i to fail even if no other process has failed. The failure of process i could be due to reasons specific to that process, unrelated to the failures of other processes.\n",
      "\n",
      "Therefore, the second part of the statement does not logically follow from the first part.\n",
      "--------------------------------Question 59--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : Consider using a parser with the following (partial) grammar:\n",
      "S -> NP VP \n",
      "VP -> V\n",
      "NP -> Det N\n",
      "VP -> VP PP\n",
      "NP -> N\n",
      "VP -> VBP VBG PP\n",
      "NP -> NP PP\n",
      "PP -> P NP\n",
      "and (also partial) lexicon:\n",
      "2012 N\n",
      "from P\n",
      "Switzerland N\n",
      "in P\n",
      "USA N \n",
      "increasing VBG\n",
      "are VBP \n",
      "the Det\n",
      "exports N \n",
      "to P\n",
      "exports V\n",
      "Using the CYK algorithm, parse the following sentence with the above lexicon/grammar:\n",
      "the exports from the USA to Switzerland are increasing in 2012\n",
      "Provide both the complete, fully filled, data structure used by the algorithm, as well as the result of\n",
      "the parsing in the form of a/the parse tree(s).\n",
      "[SOLUTION] : \n",
      "Here is the complete data structure used by the CYK algorithm for parsing the given sentence:\n",
      "\n",
      "|   | 1         | 2        | 3       | 4       | 5        | 6      | 7     | 8        |\n",
      "|---|-----------|----------|---------|---------|----------|--------|-------|----------|\n",
      "| 1 | NP(the)   |          |         |         |          |        |       |          |\n",
      "| 2 |           | NP(exports) |       |         |          |        |       |          |\n",
      "| 3 |           |          | P(from) |         |          |        |       |          |\n",
      "| 4 |           |          |         | NP(the) |          |        |       |          |\n",
      "| 5 |           |          |         |         | N(USA)   |        |       |          |\n",
      "| 6 |           |          |         |         |          | P(to) |       |          |\n",
      "| 7 |           |          |         |         |          |        | NP(Switzerland) | |\n",
      "| 8 |           |          |         |         |          |        |       | VBP(are) |\n",
      "\n",
      "And here is the parse tree for the given sentence:\n",
      "\n",
      "```\n",
      "         S\n",
      "    |---------|\n",
      "   NP        VP\n",
      "    |         |\n",
      "  Det         VBP\n",
      "    |         |\n",
      "  the        are\n",
      "    |         |\n",
      "  exports    VP\n",
      "    |         |\n",
      "    NP       PP\n",
      "    |      /  |  \\\n",
      " exports  to  NP  |\n",
      "          |   |   |\n",
      "         USA  |  PP\n",
      "              |  |\n",
      "         Switzerland\n",
      "```\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Consider using a parser with the following (partial) grammar:\n",
      "S -> NP VP \n",
      "VP -> V\n",
      "NP -> Det N\n",
      "VP -> VP PP\n",
      "NP -> N\n",
      "VP -> VBP VBG PP\n",
      "NP -> NP PP\n",
      "PP -> P NP\n",
      "and (also partial) lexicon:\n",
      "2012 N\n",
      "from P\n",
      "Switzerland N\n",
      "in P\n",
      "USA N \n",
      "increasing VBG\n",
      "are VBP \n",
      "the Det\n",
      "exports N \n",
      "to P\n",
      "exports V\n",
      "Using the CYK algorithm, parse the following sentence with the above lexicon/grammar:\n",
      "the exports from the USA to Switzerland are increasing in 2012\n",
      "Provide both the complete, fully filled, data structure used by the algorithm, as well as the result of\n",
      "the parsing in the form of a/the parse tree(s).\n",
      "To parse the sentence \"the exports from the USA to Switzerland are increasing in 2012\" using the CYK algorithm with the given grammar and lexicon, we need to create a chart and fill it according to the algorithm.\n",
      "\n",
      "Here is the completed chart:\n",
      "\n",
      "|    | 1       | 2    | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 |\n",
      "|----|---------|------|---|---|---|---|---|---|---|----|----|\n",
      "| 1  | Det     | N    | P | N | P | N | V |    |    |    |    |\n",
      "| 2  |         |      |   |   |   |   |   |    |    |    |    |\n",
      "| 3  |         |      |   |   |   |   |   |    |    |    |    |\n",
      "| 4  |         |      |   |   |   |   |   |    |    |    |    |\n",
      "| 5  |         |      |   |   |   |   |   |    |    |    |    |\n",
      "| 6  |         |      |   |   |   |   |   |    |    |    |    |\n",
      "| 7  |         |      |   |   |   |   |   |    |    |    |    |\n",
      "| 8  |         |      |   |   |   |   |   |    |    |    |    |\n",
      "| 9  |         |      |   |   |   |   |   |    |    |    |    |\n",
      "| 10 |         |      |   |   |   |   |   |    |    |    |    |\n",
      "| 11 |         |      |   |   |   |   |   |    |    |    |    |\n",
      "\n",
      "Now, let's fill in the chart based on the grammar rules and lexicon:\n",
      "\n",
      "1. Det -> the\n",
      "2. N -> exports\n",
      "3. P -> from\n",
      "4. N -> USA\n",
      "5. P -> to\n",
      "6. N -> Switzerland\n",
      "7. V -> are\n",
      "8. VBG -> increasing\n",
      "9. P -> in\n",
      "10. N -> 2012\n",
      "\n",
      "Now, we can fill in the corresponding cells in the chart:\n",
      "\n",
      "|    | 1       | 2    | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 |\n",
      "|----|---------|------|---|---|---|---|---|---|---|----|----|\n",
      "| 1  | Det     | N    | P | N | P | N | V |    |    |    |    |\n",
      "| 2  |         |      | NP |    |    |    |    |    |    |    |    |\n",
      "| 3  |         |      |    |    |    |    |    |    |    |    |    |\n",
      "| 4  |         |      |    | NP |    |    |    |    |\n",
      "--------------------------------Question 60--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : Considering the set of triangles previously calculated, estimate the fraction of triangles of configurations  {+,+,+}\n",
      " ,  {−,−,−}\n",
      " ,  {+,+,−}\n",
      " , and  {+,−,−}\n",
      " . What fraction of triangles are \"balanced\" according to structural balance theory?\n",
      "[SOLUTION] : \n",
      "To estimate the fraction of triangles of configurations {+,+,+}, {−,−,−}, {+,+,−}, and {+,−,−}, we need to calculate the number of triangles of each configuration and divide it by the total number of triangles.\n",
      "\n",
      "Let's denote the total number of triangles as T. Then, we calculate the number of triangles for each configuration:\n",
      "- {+,+,+}: Let's denote the number of positive edges as P and the total number of edges as E. The number of triangles with all positive edges is P choose 3 (P3) since we need to choose 3 positive edges out of P total edges.\n",
      "- {−,−,−}: Similarly, the number of triangles with all negative edges is (E-P) choose 3 ((E-P)3).\n",
      "- {+,+,−}: The number of triangles with two positive edges and one negative edge is P choose 2 * (E-P) (P2 * (E-P)).\n",
      "- {+,−,−}: The number of triangles with one positive edge and two negative edges is P * (E-P) choose 2 (P * (E-P)2).\n",
      "\n",
      "Once we have calculated the number of triangles for each configuration, we can calculate the fractions by dividing by the total number of triangles T.\n",
      "\n",
      "As for the fraction of triangles that are \"balanced\" according to structural balance theory, we need to consider the configurations where there are no cycles of odd length. In this case, the configurations {+,+,+} and {−,−,−} are balanced, while {+,+,−} and {+,−,−} are unbalanced. So the fraction of balanced triangles would be the sum of the fractions of triangles of configurations {+,+,+} and {−,−,−}.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Considering the set of triangles previously calculated, estimate the fraction of triangles of configurations  {+,+,+}\n",
      " ,  {−,−,−}\n",
      " ,  {+,+,−}\n",
      " , and  {+,−,−}\n",
      " . What fraction of triangles are \"balanced\" according to structural balance theory?\n",
      "To estimate the fraction of each type of triangle in the set, we can first count the total number of triangles and then count how many fall into each category. Let's consider the following configurations:\n",
      "\n",
      "1. {+, +, +} - This configuration represents a balanced triangle where all three relationships are positive.\n",
      "\n",
      "2. {−, −, −} - This configuration also represents a balanced triangle where all three relationships are negative.\n",
      "\n",
      "3. {+, +, −} - This configuration represents an unbalanced triangle where two relationships are positive and one is negative.\n",
      "\n",
      "4. {+, −, −} - This configuration also represents an unbalanced triangle where one relationship is positive and two are negative.\n",
      "\n",
      "To calculate the fraction of each type of triangle, we need to count the number of triangles in each category and then divide by the total number of triangles. Let's say we have:\n",
      "- Total number of triangles = N\n",
      "- Number of {+, +, +} triangles = A\n",
      "- Number of {−, −, −} triangles = B\n",
      "- Number of {+, +, −} triangles = C\n",
      "- Number of {+, −, −} triangles = D\n",
      "\n",
      "The fraction of each type of triangle would be:\n",
      "- Fraction of {+, +, +} triangles = A / N\n",
      "- Fraction of {−, −, −} triangles = B / N\n",
      "- Fraction of {+, +, −} triangles = C / N\n",
      "- Fraction of {+, −, −} triangles = D / N\n",
      "\n",
      "To determine the fraction of \"balanced\" triangles according to structural balance theory, we would add the fractions of {+, +, +} and {−, −, −} triangles, as these are the configurations that are considered balanced. This fraction would be (A + B) / N.\n",
      "--------------------------------Question 61--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Tick the \\textbf{false} statement : \n",
      "[ ] As a defender of a machine learning model you should be more worried about black-box effective attacks than white-box effective attacks.\n",
      "[ ] Privacy problems in machine learning stem solely from the need for data to train models.\n",
      "[ ] Poisoning attacks can be used to increase vulnerability to adversarial examples.\n",
      "[SOLUTION] : The false statement is : Privacy problems in machine learning stem solely from the need for data to train models. Data collection for training is one of many privacy attack vectors in machine learning. There exist attacks on models and outputs; and naturally exposing data for test is a risk in itself. The first statement is true, an adversary performing a black-box attack needs much less resources and capabilities than a white-box adversary. This is much more dangerous, as the adversary only needs the ability to interact with the model. The last statement is also true because by providing poisoning inputs, the adversary gets to shape the boundaries of the model. Thus, she can carve this boundary to facilitate classification errors. In fact, you can understand a backdoor attack as a particular instance of an adversarial example.\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : To which expression is the following for-loop translated? for x <- xs if x > 5; y <- ys yield x + y\n",
      "[ ] xs.flatMap(x => ys.map(y => x + y)).withFilter(x => x > 5)\n",
      "[ ] xs.withFilter(x => x > 5).map(x => ys.flatMap(y => x + y))\n",
      "[ ] xs.withFilter(x => x > 5).flatMap(x => ys.map(y => x + y))\n",
      "[ ] xs.map(x => ys.flatMap(y => x + y)).withFilter(x => x > 5)\n",
      "[SOLUTION] : \n",
      "xs.withFilter(x => x > 5).flatMap(x => ys.map(y => x + y))\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "To which expression is the following for-loop translated? for x <- xs if x > 5; y <- ys yield x + y\n",
      "[ ] xs.flatMap(x => ys.map(y => x + y)).withFilter(x => x > 5)\n",
      "[ ] xs.withFilter(x => x > 5).map(x => ys.flatMap(y => x + y))\n",
      "[ ] xs.withFilter(x => x > 5).flatMap(x => ys.map(y => x + y))\n",
      "[ ] xs.map(x => ys.flatMap(y => x + y)).withFilter(x => x > 5)\n",
      "To translate the given for-loop expression `for x <- xs if x > 5; y <- ys yield x + y` into an equivalent expression using higher-order functions, we need to break it down step by step:\n",
      "\n",
      "1. Filter the elements in `xs` where `x > 5`.\n",
      "2. For each filtered element `x`, generate a new sequence by combining it with each element in `ys` using the operation `x + y`.\n",
      "\n",
      "Based on this breakdown, the correct translation of the for-loop expression would be:\n",
      "[ ] xs.withFilter(x => x > 5).flatMap(x => ys.map(y => x + y))\n",
      "\n",
      "This expression first filters the elements in `xs` where `x > 5` using `withFilter`, and then for each filtered element `x`, it generates a new sequence by combining it with each element in `ys` using `flatMap`.\n",
      "--------------------------------Question 62--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Considering a sequence of n tokens, the computational complexity of the masked attention mechanism in BERT language models is: (select the smallest correct complexity)\n",
      "[ ] O(n^3)\n",
      "[ ] O(nlog(n))\n",
      "[ ] O(n)\n",
      "[ ] O(n^(1/2))\n",
      "[ ] O(n^2)\n",
      "[SOLUTION] : Masked attention is quadratic in the sequence length n because it computes the attention between all pairs of tokens, therefore O(n^2).\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : 10 itemsets out of 100 contain item A, of which 5 also contain B. The rule B -> A has:\n",
      "[ ] unknown support and 50% confidence\n",
      "[ ] unknown support and unknown confidence\n",
      "[ ] 5% support and 50% confidence\n",
      "[ ] 5% support and unknown confidence\n",
      "[SOLUTION] : \n",
      "5% support and 50% confidence. \n",
      "\n",
      "Support is the proportion of transactions that contain both A and B, which is 5%. Confidence is the proportion of transactions containing B that also contain A, which is 50%.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "10 itemsets out of 100 contain item A, of which 5 also contain B. The rule B -> A has:\n",
      "[ ] unknown support and 50% confidence\n",
      "[ ] unknown support and unknown confidence\n",
      "[ ] 5% support and 50% confidence\n",
      "[ ] 5% support and unknown confidence\n",
      "To determine the support and confidence of the rule B -> A, we need to first calculate the support and confidence values.\n",
      "\n",
      "Given:\n",
      "- 10 itemsets out of 100 contain item A\n",
      "- 5 out of these 10 itemsets also contain item B\n",
      "\n",
      "Support is the proportion of transactions that contain both items A and B:\n",
      "Support(B -> A) = P(A and B) = Number of itemsets containing both A and B / Total number of itemsets\n",
      "Support(B -> A) = 5 / 100 = 0.05 or 5%\n",
      "\n",
      "Confidence is the likelihood of item A being bought when item B is bought:\n",
      "Confidence(B -> A) = P(A|B) = P(A and B) / P(B)\n",
      "Confidence(B -> A) = Support(B -> A) / Support(B) = 5% / (Number of itemsets containing B / Total number of itemsets)\n",
      "Confidence(B -> A) = 5% / (10 / 100) = 5% / 10% = 50%\n",
      "\n",
      "Therefore, the rule B -> A has 5% support and 50% confidence. \n",
      "\n",
      "So, the correct answer is: [ ] 5% support and 50% confidence.\n",
      "--------------------------------Question 63--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : A rigid and homogeneous horizontal rod of mass M, of length L, of negligible thickness e, i.e. e << L, is rotating in a horizontal plane around the vertical axis $C e_3$ at angular velocity $\\Omega=\\dot{\\psioldsymbol{e}3$. The moment of inertia of the rod with respect to the vertical principal axis that contains its centre of mass G is $I{G,3}=\frac1{12}ML^{2}$. Let C be the point of contact between the extremity of the rod and the rotation axis, and P the point at the other extremity. The unit vector $e_1$ is oriented along the rod and the vector $e_2$ is orthogonal to $e_1$. The unit vectors $e_1$, $e_2$ and $e_3$, attached to the rod at point C, are the principal axis frame of the rod. We consider that there is no friction and we do not take explicitly into account the influence of the gravitational field. Give the expression of the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis of rotation $C e_3$ in terms of the scalar quantities M and L.\n",
      "[SOLUTION] : Applying the Huygens-Steiner theorem, we determine the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis $C e_3$ taking into account the fact that d = L/2 is the distance separating points G and C and that $I_{G,3}=\frac1{12}ML^{2}$,\n",
      "ight)^2=\frac{1}{12}ML^2+\frac{1}{4}ML^2=\frac{1}{3}ML^2$\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : We consider a ball of mass $m$ sliding without friction in a ring of radius $R$. The ring itself is rotating around the vertical axis passing through its centre $O$ with a constant angular speed $\\boldsymbol{\\omega}$ with respect to the frame of reference of the laboratory. We suppose that the ball can be considered as a material point.\n",
      "\n",
      "Determine the equilibrium positions $0\\leq\\theta_1<\\theta_2\\leq\\frac{\\pi}{2}$ of the ball with respect to the ring and the minimal angular speed $\\omega_{\\,\\text{min}}$ for which the equilibrium position $\\theta_2$ exists.\n",
      "\n",
      "\n",
      "[SOLUTION] : \n",
      "Since the ball is sliding without friction, the only forces acting on it are the gravitational force and the centrifugal force due to the rotation of the ring.\n",
      "\n",
      "The gravitational force acting on the ball is $m\\boldsymbol{g}$, where $\\boldsymbol{g}$ is the acceleration due to gravity directed vertically downward.\n",
      "\n",
      "The centrifugal force acting on the ball is $mR\\omega^2$, directed radially outward.\n",
      "\n",
      "At equilibrium, the net force acting on the ball must be zero. This gives us the equation:\n",
      "\n",
      "$$m\\boldsymbol{g} + mR\\omega^2 = m\\boldsymbol{a}$$\n",
      "\n",
      "where $\\boldsymbol{a}$ is the acceleration of the ball along the ring.\n",
      "\n",
      "Since the ball is at equilibrium, the acceleration $\\boldsymbol{a}$ is zero. Therefore, we have:\n",
      "\n",
      "$$m\\boldsymbol{g} + mR\\omega^2 = 0$$\n",
      "\n",
      "Solving for $\\omega$:\n",
      "\n",
      "$$\\omega^2 = \\frac{g}{R}$$\n",
      "\n",
      "Taking the square root of both sides, we get:\n",
      "\n",
      "$$\\omega = \\sqrt{\\frac{g}{R}}$$\n",
      "\n",
      "This is the minimum angular speed $\\omega_{\\,\\text{min}}$ for which the equilibrium position $\\theta_2$ exists.\n",
      "\n",
      "The equilibrium positions $\\theta_1$ and $\\theta_2$ of the ball with respect to the ring can be found by considering the forces along the radial direction. At positions $\\theta_1$ and $\\theta_2$, the centrifugal force and the gravitational force balance each other out, leading to:\n",
      "\n",
      "At $\\theta_1$:\n",
      "\n",
      "$$m\\boldsymbol{g}\\cos(\\theta_1) + mR\\omega^2 = 0$$\n",
      "\n",
      "At $\\theta_2$:\n",
      "\n",
      "$$m\\boldsymbol{g}\\cos(\\theta_2) + mR\\omega^2 = 0$$\n",
      "\n",
      "Solving these equations for $\\theta_1$ and $\\theta_2$ will give the equilibrium positions of the ball with respect to the ring.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "We consider a ball of mass $m$ sliding without friction in a ring of radius $R$. The ring itself is rotating around the vertical axis passing through its centre $O$ with a constant angular speed $\\boldsymbol{\\omega}$ with respect to the frame of reference of the laboratory. We suppose that the ball can be considered as a material point.\n",
      "\n",
      "Determine the equilibrium positions $0\\leq\\theta_1<\\theta_2\\leq\\frac{\\pi}{2}$ of the ball with respect to the ring and the minimal angular speed $\\omega_{\\,\\text{min}}$ for which the equilibrium position $\\theta_2$ exists.\n",
      "\n",
      "\n",
      "To find the equilibrium positions $\\theta_1$ and $\\theta_2$, we can start by considering the forces acting on the ball in the rotating frame of reference. In this frame, we have two forces acting on the ball: the gravitational force and the centrifugal force due to the rotation of the ring.\n",
      "\n",
      "1. **Gravitational Force**: The gravitational force acting on the ball is directed downward and has a magnitude of $mg$, where $g$ is the acceleration due to gravity.\n",
      "\n",
      "2. **Centrifugal Force**: The centrifugal force experienced by the ball in the rotating frame is directed outward and has a magnitude of $m R \\omega^2$, where $\\omega$ is the angular speed of the ring.\n",
      "\n",
      "For the ball to be in equilibrium, the net force acting on it in the rotating frame must be directed towards the center of the ring. This means that the centrifugal force must balance the gravitational force. Therefore, we have:\n",
      "\n",
      "\\[\n",
      "m R \\omega^2 = mg\n",
      "\\]\n",
      "\n",
      "From this equation, we can solve for the minimum angular speed $\\omega_{\\,\\text{min}}$ required for the equilibrium position $\\theta_2$ to exist.\n",
      "\n",
      "Next, we need to determine the equilibrium positions $\\theta_1$ and $\\theta_2$ of the ball with respect to the ring. To do this, we can consider the forces acting on the ball in the radial direction when it is at these equilibrium positions.\n",
      "\n",
      "At position $\\theta_1$, the centrifugal force and the gravitational force act in opposite directions. At position $\\theta_2$, the centrifugal force and the gravitational force act in the same direction.\n",
      "\n",
      "By analyzing the forces at these equilibrium positions, we can find the values of $\\theta_1$ and $\\theta_2$.\n",
      "\n",
      "Let's start by finding the minimum angular speed $\\omega_{\\,\\text{min}}$.\n",
      "--------------------------------Question 64--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : Tick the \\textbf{false} statement : \n",
      "[ ] As a defender of a machine learning model you should be more worried about black-box effective attacks than white-box effective attacks.\n",
      "[ ] Privacy problems in machine learning stem solely from the need for data to train models.\n",
      "[ ] Poisoning attacks can be used to increase vulnerability to adversarial examples.\n",
      "[SOLUTION] : The false statement is : Privacy problems in machine learning stem solely from the need for data to train models. Data collection for training is one of many privacy attack vectors in machine learning. There exist attacks on models and outputs; and naturally exposing data for test is a risk in itself. The first statement is true, an adversary performing a black-box attack needs much less resources and capabilities than a white-box adversary. This is much more dangerous, as the adversary only needs the ability to interact with the model. The last statement is also true because by providing poisoning inputs, the adversary gets to shape the boundaries of the model. Thus, she can carve this boundary to facilitate classification errors. In fact, you can understand a backdoor attack as a particular instance of an adversarial example.\n",
      "[QUESTION] : TransE is known to have difficulties in representing symmetric relationships r. Which of the following statements is correct for a symmetric relationship and provides insight for this problem?\n",
      "[ ] For all e1 , e2: \\( f(e_1, r, e_2) = f(e_2, r, e_1)  \\)\n",
      "[ ] For all e1 , e2: \\( f(e_1, r, e_2) = -f(e_2, r, e_1) \\)\n",
      "[ ] \\( \\Sigma_{ e_1, e_2} f(e_1, r, e_2) + f(e_2, r, e_1) \\) is minimized if the embedding vector of r is large\n",
      "[ ] \\( \\Sigma_{ e_1, e_2} f(e_1, r, e_2) + f(e_2, r, e_1) \\) is minimized if the embedding vectors of e1and e2 are close to each other\n",
      "[SOLUTION] : \n",
      "The correct statement is: For all e1 , e2: \\( f(e_1, r, e_2) = f(e_2, r, e_1) \\). This statement indicates that for a symmetric relationship, the embedding of entities e1 and e2 with respect to the relationship r should be the same regardless of the order in which they are considered. This property is important for capturing symmetric relationships accurately in knowledge graph embeddings.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "TransE is known to have difficulties in representing symmetric relationships r. Which of the following statements is correct for a symmetric relationship and provides insight for this problem?\n",
      "[ ] For all e1 , e2: \\( f(e_1, r, e_2) = f(e_2, r, e_1)  \\)\n",
      "[ ] For all e1 , e2: \\( f(e_1, r, e_2) = -f(e_2, r, e_1) \\)\n",
      "[ ] \\( \\Sigma_{ e_1, e_2} f(e_1, r, e_2) + f(e_2, r, e_1) \\) is minimized if the embedding vector of r is large\n",
      "[ ] \\( \\Sigma_{ e_1, e_2} f(e_1, r, e_2) + f(e_2, r, e_1) \\) is minimized if the embedding vectors of e1and e2 are close to each other\n",
      "The correct statement for a symmetric relationship and its implications for TransE is:\n",
      "\n",
      "[ ] For all e1 , e2: \\( f(e_1, r, e_2) = f(e_2, r, e_1) \\)\n",
      "\n",
      "For a symmetric relationship, the embeddings should be the same regardless of the order of the entities. In other words, the score function should return the same value for \\( f(e_1, r, e_2) \\) and \\( f(e_2, r, e_1) \\). This property is not directly captured by TransE's scoring function, leading to difficulties in representing symmetric relationships effectively.\n",
      "--------------------------------Question 65--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : (Privacy) Fine-grained accountability and auditability make it difficult to implement systems with strong privacy protection.\n",
      "[ ] True\n",
      "[ ] False\n",
      "[SOLUTION] : This is True. Accountability and auditability mainly rely on logging actions. These logs typically record all actions in the system, becoming an extra source of information that can be used to infer private information about users.\n",
      "[QUESTION] : (Gradient Descent) When training a Deep Neural Network, it is better to use classical gradient descent rather than stochastic gradient descent with mini-batches to optimize the parameters of the network.\n",
      "[ ] True\n",
      "[ ] False\n",
      "[SOLUTION] : False. Deep Learning requires large datasets, and going through all of the data to compute a full gradient is unnecessarily expensive, compared to many cheaper SGD steps. In addition, noisy updates for several reasons seem to perform better in the non-convex landscapes stemming from deep learning training.\n",
      "[QUESTION] : (Privacy) To provide users with anonymity when accessing a web all accesses from one user must be unlinkable.\n",
      "[ ] True\n",
      "[ ] False\n",
      "[SOLUTION] : This is True. If accesses by a user are linkable, even if we do not know the identity, these accesses become a pseudonym. We cannot anymore say that it is truly anonymous. Thus, in general, unlinkability is needed for anonymity.\n",
      "[QUESTION] : (Nearest Neighbor) The training error of the 1-nearest neighbor classifier is zero.\n",
      "[ ] True\n",
      "[ ] False\n",
      "[SOLUTION] : \n",
      "False. The training error of the 1-nearest neighbor classifier will not necessarily be zero, as it simply assigns the label of the nearest training data point to the query point. If there are multiple instances of the same data point with different labels in the training set, the classifier may still make errors on those instances.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "(Nearest Neighbor) The training error of the 1-nearest neighbor classifier is zero.\n",
      "[ ] True\n",
      "[ ] False\n",
      "True.\n",
      "\n",
      "Explanation: In a 1-nearest neighbor classifier, the training error is typically zero because the classifier simply memorizes the training data and assigns the label of the nearest neighbor in the training set to any new data point. This means that the classifier will always predict the correct label for the data points in the training set, resulting in a training error of zero.\n",
      "--------------------------------Question 66--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : A rigid and homogeneous horizontal rod of mass M, of length L, of negligible thickness e, i.e. e << L, is rotating in a horizontal plane around the vertical axis $C e_3$ at angular velocity $\\Omega=\\dot{\\psioldsymbol{e}3$. The moment of inertia of the rod with respect to the vertical principal axis that contains its centre of mass G is $I{G,3}=\frac1{12}ML^{2}$. Let C be the point of contact between the extremity of the rod and the rotation axis, and P the point at the other extremity. The unit vector $e_1$ is oriented along the rod and the vector $e_2$ is orthogonal to $e_1$. The unit vectors $e_1$, $e_2$ and $e_3$, attached to the rod at point C, are the principal axis frame of the rod. We consider that there is no friction and we do not take explicitly into account the influence of the gravitational field. Give the expression of the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis of rotation $C e_3$ in terms of the scalar quantities M and L.\n",
      "[SOLUTION] : Applying the Huygens-Steiner theorem, we determine the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis $C e_3$ taking into account the fact that d = L/2 is the distance separating points G and C and that $I_{G,3}=\frac1{12}ML^{2}$,\n",
      "ight)^2=\frac{1}{12}ML^2+\frac{1}{4}ML^2=\frac{1}{3}ML^2$\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : A car drives over a very bumpy road (see diagram). We model the car as a material point of mass $m$, riding at constant horizontal speed $v_x$. The material point is attached to a spring with spring constant $k$ and rest length $l_0$. At the other end of the spring is a massless wheel, with negligible radius, that's following the curves of the bumpy road.\n",
      "\n",
      "\n",
      "The spring remains upright at all times; we'll ignore how it does so, and assume that it has no influence on the motion of the material point.\n",
      "The parameters of the problem are such that the wheel never lifts from the road and that the car never hits the wheel. \n",
      "The road's profile follows a sinusoidal shape. The bumps have height $H$ and length $L$.\n",
      "Express the vertical position of the wheel $h(t)$ as a function of time.\n",
      "\n",
      "[SOLUTION] : \n",
      "Let's consider the equilibrium position of the system when the spring is at rest, meaning that the spring force balances the gravitational force acting on the mass $m$. At this point, the spring is compressed by a distance $l_0$ due to the weight of the mass $m$.\n",
      "\n",
      "When the car drives over a bump, the spring will compress or extend depending on the height of the bump. Let's denote the vertical displacement of the wheel from the equilibrium position as $h(t)$.\n",
      "\n",
      "At any given time $t$, the total force acting on the mass $m$ is the sum of the gravitational force, the spring force, and the normal force from the road. The normal force will vary as the wheel goes over the bumps, but it will always be perpendicular to the road surface.\n",
      "\n",
      "The equation of motion for the mass $m$ in the vertical direction can be written as:\n",
      "\n",
      "$m\\ddot{h} = -mg + k(l_0 + h) - N$\n",
      "\n",
      "Where $N$ is the normal force from the road surface. Since the wheel never lifts off the road, the normal force will always be present to counteract the gravitational force.\n",
      "\n",
      "To simplify the problem, we can assume that the normal force is always equal to the gravitational force, i.e., $N = mg$.\n",
      "\n",
      "Therefore, the equation of motion becomes:\n",
      "\n",
      "$m\\ddot{h} = -mg + k(l_0 + h) - mg$\n",
      "\n",
      "Solving this differential equation will give us the vertical position of the wheel $h(t)$ as a function of time. The solution will be a sinusoidal function that oscillates around the equilibrium position $h = 0$.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "A car drives over a very bumpy road (see diagram). We model the car as a material point of mass $m$, riding at constant horizontal speed $v_x$. The material point is attached to a spring with spring constant $k$ and rest length $l_0$. At the other end of the spring is a massless wheel, with negligible radius, that's following the curves of the bumpy road.\n",
      "\n",
      "\n",
      "The spring remains upright at all times; we'll ignore how it does so, and assume that it has no influence on the motion of the material point.\n",
      "The parameters of the problem are such that the wheel never lifts from the road and that the car never hits the wheel. \n",
      "The road's profile follows a sinusoidal shape. The bumps have height $H$ and length $L$.\n",
      "Express the vertical position of the wheel $h(t)$ as a function of time.\n",
      "\n",
      "Let's analyze the situation step by step:\n",
      "\n",
      "1. The equilibrium position of the wheel is at a height $h_0 = -l_0$ (below the material point at rest position). This is because the spring has a rest length of $l_0$.\n",
      "\n",
      "2. As the car moves over the bumps, the spring will be compressed or extended, leading to a change in the vertical position of the wheel.\n",
      "\n",
      "3. Let's define the amplitude of the sinusoidal road profile as $A = H/2$, where $H$ is the height of the bumps. The equation for the road profile is then $h_{\\text{road}}(x) = A\\sin(2\\pi x/L)$, where $x$ is the horizontal position of the car.\n",
      "\n",
      "4. The vertical position of the wheel, $h(t)$, can be written as $h(t) = h_{\\text{road}}(x) + h_{\\text{spring}}(t)$, where $h_{\\text{spring}}(t)$ is the vertical displacement of the spring due to the motion of the car.\n",
      "\n",
      "5. The vertical displacement of the spring, $h_{\\text{spring}}(t)$, is related to the compression or extension of the spring. This can be calculated using Hooke's Law: $F = kx$, where $F$ is the force exerted by the spring, $k$ is the spring constant, and $x$ is the displacement from the equilibrium position.\n",
      "\n",
      "6. The total force acting on the material point is the sum of the gravitational force and the spring force: $mg = k(h_{\\text{spring}} - l_0)$, where $m$ is the mass of the material point, $g$ is the acceleration due to gravity, and $l_0$ is the rest length of the spring.\n",
      "\n",
      "7. Solving the above equation for $h_{\\text{spring}}$, we get $h_{\\text{spring}}(t) = \\frac{mg}{k} + l_0$.\n",
      "\n",
      "8. Substituting $h_{\\text{spring}}(t)$ into the expression for $h(t)$, we get:\n",
      "$$\n",
      "h(t) = A\\sin\\left(\\frac{2\\pi v_xt}{L}\\right) + \\frac{mg}{k} + l_0\n",
      "$$\n",
      "\n",
      "Therefore, the vertical position of the wheel as a function of time is given by:\n",
      "$$\n",
      "h(t) = A\\sin\\left(\\frac{2\\pi v_xt}{L}\\right) + \\frac{mg}{k} + l_0\n",
      "$$\n",
      "--------------------------------Question 67--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : Two disks A and B of radius R, aligned, can rotate around a vertical axis $z$ inside a container filled with a fluid of viscosity $\\eta$. The distances between A and B and between A and the bottom of the container are equal to $d$. The disk B rotates at constant angular velocity $\\omega_0~\\vec{e}_z$.\n",
      "At $t=0$ the angular velocity of A is $\\omega=0$.\n",
      "\n",
      "What is the temporal dependency of $\\omega$?\n",
      "\n",
      "[SOLUTION] : \n",
      "The torque acting on disk A is due to the viscous force exerted by the fluid. This torque can be expressed as $\\tau = -\\eta \\cdot A \\cdot \\omega$, where $A$ is the area of the disk and $\\omega$ is the angular velocity of disk A. The negative sign indicates that the torque opposes the motion.\n",
      "\n",
      "The moment of inertia of disk A is $I = \\frac{1}{2}mR^2$, where $m$ is the mass of the disk and $R$ is the radius.\n",
      "\n",
      "Applying Newton's second law for rotation, $\\tau = I \\cdot \\frac{d\\omega}{dt}$, we can write $-\\eta \\cdot A \\cdot \\omega = \\frac{1}{2}mR^2 \\cdot \\frac{d\\omega}{dt}$.\n",
      "\n",
      "Solving this differential equation, we get $\\omega(t) = \\omega_0 \\cdot e^{-\\frac{2\\eta At}{mR^2}}$.\n",
      "\n",
      "Therefore, the temporal dependency of $\\omega$ is exponential decay.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Two disks A and B of radius R, aligned, can rotate around a vertical axis $z$ inside a container filled with a fluid of viscosity $\\eta$. The distances between A and B and between A and the bottom of the container are equal to $d$. The disk B rotates at constant angular velocity $\\omega_0~\\vec{e}_z$.\n",
      "At $t=0$ the angular velocity of A is $\\omega=0$.\n",
      "\n",
      "What is the temporal dependency of $\\omega$?\n",
      "\n",
      "To determine the temporal dependency of the angular velocity $\\omega$ of disk A, we can analyze the torque acting on disk A. The torque on disk A is due to the fluid viscosity and the interaction with disk B.\n",
      "\n",
      "The torque on disk A can be written as:\n",
      "\n",
      "$$\\tau = I \\frac{d\\omega}{dt}$$\n",
      "\n",
      "where $I$ is the moment of inertia of disk A about the axis of rotation. Since disk A is rotating around a vertical axis, the moment of inertia can be calculated as $I = \\frac{1}{2}mR^2$, where $m$ is the mass of disk A.\n",
      "\n",
      "The torque is given by the sum of the torques due to the fluid viscosity and the interaction with disk B:\n",
      "\n",
      "$$\\tau = \\tau_{\\text{viscosity}} + \\tau_{\\text{interaction}}$$\n",
      "\n",
      "The torque due to fluid viscosity can be calculated using the formula for viscous drag on a rotating disk:\n",
      "\n",
      "$$\\tau_{\\text{viscosity}} = -\\eta \\omega R^2$$\n",
      "\n",
      "The torque due to the interaction with disk B can be calculated using the formula for torque due to a force acting at a distance $d$ from the axis of rotation:\n",
      "\n",
      "$$\\tau_{\\text{interaction}} = F \\cdot d = m \\cdot g \\cdot R \\cdot d$$\n",
      "\n",
      "where $F$ is the force due to the gravitational interaction with disk B, $m$ is the mass of disk A, $g$ is the acceleration due to gravity, and $R$ is the radius of disk A.\n",
      "\n",
      "Substituting these expressions into the torque equation, we get:\n",
      "\n",
      "$$I \\frac{d\\omega}{dt} = -\\eta \\omega R^2 + m \\cdot g \\cdot R \\cdot d$$\n",
      "\n",
      "Substitute the moment of inertia $I = \\frac{1}{2}mR^2$:\n",
      "\n",
      "$$\\frac{1}{2}mR^2 \\frac{d\\omega}{dt} = -\\eta \\omega R^2 + m \\cdot g \\cdot R \\cdot d$$\n",
      "\n",
      "Solve for $\\frac{d\\omega}{dt}$:\n",
      "\n",
      "$$\\frac{d\\omega}{dt} = -\\frac{2\\eta \\omega R}{m} + 2g \\cdot d$$\n",
      "\n",
      "This is the differential equation for the temporal dependency of the angular velocity $\\omega$ of disk A. It describes how the angular velocity changes over time due to the interaction with the fluid viscosity and disk B. Solving this differential equation will give the temporal evolution of $\\omega$.\n",
      "--------------------------------Question 68--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : A missile is launched with an initial velocity $\\boldsymbol{v_0}$ from point $O$. At the same time, a material point is launched with no initial velocity from point $P$. \n",
      "\n",
      "Show that if the missile is initially launched along the line of fire $\\boldsymbol{OP}$, then the missile will inevitably hit the material point.\n",
      "\n",
      "[SOLUTION] : \n",
      "Let $\\boldsymbol{r_1}(t)$ and $\\boldsymbol{r_2}(t)$ be the positions of the missile and the material point at time $t$, respectively. Since the missile is initially launched along the line of fire $\\boldsymbol{OP}$, we have $\\boldsymbol{r_1}(0) = \\boldsymbol{v_0}t$ and $\\boldsymbol{r_2}(0) = \\boldsymbol{0}$. \n",
      "\n",
      "The distance between the missile and the material point at time $t$ is given by $||\\boldsymbol{r_1}(t) - \\boldsymbol{r_2}(t)||$. Since the missile is initially launched along the line of fire $\\boldsymbol{OP}$, the vector connecting the missile to the material point at time $t$ lies along the line $\\boldsymbol{OP}$. \n",
      "\n",
      "Therefore, the missile will inevitably hit the material point when $||\\boldsymbol{r_1}(t) - \\boldsymbol{r_2}(t)|| = 0$. This implies that the missile and the material point will collide at some time $t$ along the line of fire $\\boldsymbol{OP}$.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "A missile is launched with an initial velocity $\\boldsymbol{v_0}$ from point $O$. At the same time, a material point is launched with no initial velocity from point $P$. \n",
      "\n",
      "Show that if the missile is initially launched along the line of fire $\\boldsymbol{OP}$, then the missile will inevitably hit the material point.\n",
      "\n",
      "To show that the missile will inevitably hit the material point when it is initially launched along the line of fire $OP$, we can consider the motion of the missile and the material point separately.\n",
      "\n",
      "Let's denote the position of the missile at time $t$ as $\\boldsymbol{r}_m(t)$ and the position of the material point as $\\boldsymbol{r}_p(t)$.\n",
      "\n",
      "Given that the missile is initially launched along the line of fire $OP$, we can express the initial position of the missile as:\n",
      "$$\\boldsymbol{r}_m(0) = \\boldsymbol{v}_0t$$\n",
      "\n",
      "Since the material point is launched with no initial velocity from point $P$, we have:\n",
      "$$\\boldsymbol{r}_p(0) = \\boldsymbol{0}$$\n",
      "\n",
      "Now, let's consider the motion of the missile. The acceleration of the missile is denoted as $\\boldsymbol{a}_m$. Since the missile is under the influence of gravity, we have $\\boldsymbol{a}_m = \\boldsymbol{g}$, where $\\boldsymbol{g}$ is the acceleration due to gravity.\n",
      "\n",
      "The position of the missile at any time $t$ can be expressed as:\n",
      "$$\\boldsymbol{r}_m(t) = \\boldsymbol{v}_0t + \\frac{1}{2}\\boldsymbol{g}t^2$$\n",
      "\n",
      "Next, let's consider the motion of the material point. Since it is launched with no initial velocity, the acceleration of the material point, $\\boldsymbol{a}_p$, is also equal to $\\boldsymbol{g}$.\n",
      "\n",
      "The position of the material point at any time $t$ can be expressed as:\n",
      "$$\\boldsymbol{r}_p(t) = \\frac{1}{2}\\boldsymbol{g}t^2$$\n",
      "\n",
      "Now, we want to show that the missile will hit the material point. This means that there exists a time $T$ such that $\\boldsymbol{r}_m(T) = \\boldsymbol{r}_p(T)$.\n",
      "\n",
      "Substitute the expressions for $\\boldsymbol{r}_m(t)$ and $\\boldsymbol{r}_p(t)$ into the condition $\\boldsymbol{r}_m(T) = \\boldsymbol{r}_p(T)$:\n",
      "$$\\boldsymbol{v}_0T + \\frac{1}{2}\\boldsymbol{g}T^2 = \\frac{1}{2}\\boldsymbol{g}T^2$$\n",
      "\n",
      "Simplify the equation:\n",
      "$$\\boldsymbol{v}_0T = \\boldsymbol{0}$$\n",
      "\n",
      "Since $\\boldsymbol{v}_0 \\neq \\boldsymbol{0}$, this equation implies that $T = 0$, which means the missile and the material point will coincide at time $T = 0$. This confirms that the missile will hit the material point when it is initially launched along the line of fire $OP$.\n",
      "--------------------------------Question 69--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : (Adversarial Training) Adversarial training typically results in a decreased (standard) accuracy on a test set drawn from the same distribution as the training and validation sets.\n",
      "[ ] True\n",
      "[ ] False\n",
      "[SOLUTION] : True. Robustness often comes at the cost of standard accuracy as non-robust features can be useful and generalize to the test set.\n",
      "[QUESTION] : (Feature expansion) Unnecessary polynomial expansion of input features can lead to underfitting.\n",
      "[ ] True\n",
      "[ ] False\n",
      "[SOLUTION] : False. It can lead to overfitting.\n",
      "[QUESTION] : (EM Algorithm) The Expectation-Maximization (EM) algorithm is guaranteed to converge to the global maximum likelihood solution for fitting GMMs.\n",
      "[ ] True\n",
      "[ ] False\n",
      "[SOLUTION] : False. The EM algorithm for GMMs may converge to a local maximum likelihood solution, not necessarily the global maximum likelihood solution.\n",
      "[QUESTION] : Let  $$G=egin{pmatrix} 1 &1 &1 &0 &1 &0\\ 0 &1 &1 &1 &0 &0\\ 0 &1 &1 &0 &0 &0\\ 0 &1 &1 &1 &0 &1 \\end{pmatrix}$$ be the generator matrix of a $(6,4)$ linear code $\\mathcal C$ over $\\mathbb F_2$. True or false: $d_{min}=2$.\n",
      "[ ] False\n",
      "[ ] True\n",
      "[SOLUTION] : \n",
      "False. The minimum distance $d_{min}$ of a linear code is the minimum Hamming weight of a non-zero codeword. In this case, the minimum Hamming weight of the non-zero codewords in $\\mathcal C$ is 3, not 2.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Let  $$G=egin{pmatrix} 1 &1 &1 &0 &1 &0\\ 0 &1 &1 &1 &0 &0\\ 0 &1 &1 &0 &0 &0\\ 0 &1 &1 &1 &0 &1 \\end{pmatrix}$$ be the generator matrix of a $(6,4)$ linear code $\\mathcal C$ over $\\mathbb F_2$. True or false: $d_{min}=2$.\n",
      "[ ] False\n",
      "[ ] True\n",
      "To find the minimum distance of the code, we need to consider the weight of all possible non-zero codewords in the code. Since this is a $(6,4)$ linear code, all non-zero codewords must have a weight of at least 2.\n",
      "\n",
      "Let's consider the possible non-zero codewords of weight 2:\n",
      "\n",
      "1. The first column of the generator matrix is a non-zero codeword of weight 1.\n",
      "2. The second column of the generator matrix is a non-zero codeword of weight 1.\n",
      "3. The third column of the generator matrix is a non-zero codeword of weight 1.\n",
      "4. The fourth column of the generator matrix is a non-zero codeword of weight 1.\n",
      "\n",
      "Therefore, the minimum distance of the code $\\mathcal C$ is at least 2, which means $d_{min} \\geq 2$. So, the statement $d_{min}=2$ is true.\n",
      "\n",
      "Therefore, the correct answer is:\n",
      "\n",
      "[ ] True\n",
      "--------------------------------Question 70--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Considering a sequence of n tokens, the computational complexity of the masked attention mechanism in BERT language models is: (select the smallest correct complexity)\n",
      "[ ] O(n^3)\n",
      "[ ] O(nlog(n))\n",
      "[ ] O(n)\n",
      "[ ] O(n^(1/2))\n",
      "[ ] O(n^2)\n",
      "[SOLUTION] : Masked attention is quadratic in the sequence length n because it computes the attention between all pairs of tokens, therefore O(n^2).\n",
      "[QUESTION] : Let $H:\\{0,1\\}^* \\rightarrow \\{0,1\\}^n$ be a hash function and $x_1,x_2\\in\\{0,1\\}^{2n}$ two random different messages. In cryptography, we usually assume that the probability of collision, i.e. $\\Pr[H(x_1)=H(x_2)]$, is close to \\ldots\n",
      "[ ] $2^{-\\frac{n}{2}}$.\n",
      "[ ] $2^{-n}$.\n",
      "[ ] $2^{-2n}$.\n",
      "[ ] $0$.\n",
      "[SOLUTION] : \n",
      "$2^{-n}$. In cryptography, we aim for hash functions to have a very low collision probability, ideally close to $2^{-n}$ where n is the length of the output hash.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Let $H:\\{0,1\\}^* \\rightarrow \\{0,1\\}^n$ be a hash function and $x_1,x_2\\in\\{0,1\\}^{2n}$ two random different messages. In cryptography, we usually assume that the probability of collision, i.e. $\\Pr[H(x_1)=H(x_2)]$, is close to \\ldots\n",
      "[ ] $2^{-\\frac{n}{2}}$.\n",
      "[ ] $2^{-n}$.\n",
      "[ ] $2^{-2n}$.\n",
      "[ ] $0$.\n",
      "In cryptography, a good hash function is designed such that the probability of collision is very low. The probability of collision for a random hash function is close to $2^{-n}$, where $n$ is the length of the hash output in bits.\n",
      "\n",
      "Therefore, the correct answer is:\n",
      "[ ] $2^{-n}$.\n",
      "--------------------------------Question 71--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : We consider the earth as a compact set of concentric spheres.\n",
      "\n",
      "a) Use a geometric argument to show that the field vanishes inside a spherical shell. Thus, for a given point, only the spherical shell for which the point is in the exterior contributes to the field at that point.\n",
      "\n",
      "[SOLUTION] : \n",
      "a) Inside a spherical shell, the gravitational field generated by the mass distribution outside the shell can be considered as the superposition of the fields generated by each infinitesimally thin spherical shell of mass. For any point inside the spherical shell, the gravitational field generated by all the individual infinitesimal mass elements cancels out due to symmetry. This is because for every infinitesimal mass element on one side of the point, there is an equal and opposite mass element on the other side, resulting in equal and opposite gravitational forces that cancel each other out. Therefore, the net gravitational field inside a spherical shell is zero. This implies that for a given point, only the spherical shell for which the point is in the exterior contributes to the gravitational field at that point.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "We consider the earth as a compact set of concentric spheres.\n",
      "\n",
      "a) Use a geometric argument to show that the field vanishes inside a spherical shell. Thus, for a given point, only the spherical shell for which the point is in the exterior contributes to the field at that point.\n",
      "\n",
      "To show that the electric field vanishes inside a spherical shell, we can use the principle of superposition. \n",
      "\n",
      "Consider a point inside the spherical shell. The electric field at this point is the vector sum of the electric fields due to each individual sphere making up the shell. Since the electric field due to a point charge or a spherical shell of charge is spherically symmetric, the electric fields due to all the spheres will cancel each other out inside the shell.\n",
      "\n",
      "This cancellation occurs because for every point inside the shell, there exists another point on the opposite side of the shell that generates an electric field in the opposite direction. The superposition of these fields results in a net electric field of zero inside the shell.\n",
      "\n",
      "Therefore, only the spherical shell for which the point is in the exterior contributes to the field at that point, as the contribution from the interior spheres cancels out.\n",
      "--------------------------------Question 72--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Considering a sequence of n tokens, the computational complexity of the masked attention mechanism in BERT language models is: (select the smallest correct complexity)\n",
      "[ ] O(n^3)\n",
      "[ ] O(nlog(n))\n",
      "[ ] O(n)\n",
      "[ ] O(n^(1/2))\n",
      "[ ] O(n^2)\n",
      "[SOLUTION] : Masked attention is quadratic in the sequence length n because it computes the attention between all pairs of tokens, therefore O(n^2).\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Your friend Charlie was training a neural net, and observed something very curious. During training, the same network, with the same exact weights, doesn't always give the same prediction for a given example. What can cause this behavior?\n",
      "[ ] Residual layers (skip-connections)\n",
      "[ ] Convolutional layers\n",
      "[ ] Batch normalization\n",
      "[ ] SGD with momentum\n",
      "[ ] Adam\n",
      "[ ] Dropout\n",
      "[ ] L1 regularization\n",
      "[ ] L2 regularization\n",
      "[ ] This is not possible, Charlie made a mistake\n",
      "[SOLUTION] : \n",
      "Batch normalization can cause this behavior. Batch normalization introduces randomness during training due to the fact that it normalizes the activations of each mini-batch using the mean and variance of that mini-batch. This can lead to different predictions for the same example when the network is evaluated multiple times during training.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Your friend Charlie was training a neural net, and observed something very curious. During training, the same network, with the same exact weights, doesn't always give the same prediction for a given example. What can cause this behavior?\n",
      "[ ] Residual layers (skip-connections)\n",
      "[ ] Convolutional layers\n",
      "[ ] Batch normalization\n",
      "[ ] SGD with momentum\n",
      "[ ] Adam\n",
      "[ ] Dropout\n",
      "[ ] L1 regularization\n",
      "[ ] L2 regularization\n",
      "[ ] This is not possible, Charlie made a mistake\n",
      "The behavior where the same network with the same exact weights doesn't always give the same prediction for a given example can be attributed to the following factors:\n",
      "\n",
      "- **Dropout**: Dropout is a regularization technique commonly used in neural networks to prevent overfitting. During training, random units are dropped out (i.e., set to zero) with a probability p. This can lead to different predictions for the same example since different units are dropped out in each forward pass.\n",
      "\n",
      "- **Batch normalization**: Batch normalization is a technique used to normalize the inputs of each layer to speed up training and improve generalization. During training, the mean and variance of the batch are used to normalize the inputs. Since the batch statistics differ in each iteration, the predictions can vary even with the same weights.\n",
      "\n",
      "- **SGD with momentum**: Stochastic Gradient Descent (SGD) with momentum is an optimization algorithm commonly used to train neural networks. The inclusion of momentum helps accelerate convergence and dampen oscillations. The momentum term introduces a moving average of past gradients, which can cause variations in predictions for the same example.\n",
      "\n",
      "- **Adam**: Adam is another popular optimization algorithm that combines the benefits of both Adagrad and RMSprop. It uses adaptive learning rates and momentum terms to optimize the training process. The adaptive nature of Adam can lead to different predictions for the same example due to the variations in learning rates.\n",
      "\n",
      "Therefore, the correct options that could cause the observed behavior are:\n",
      "- [ ] Dropout\n",
      "- [ ] Batch normalization\n",
      "- [ ] SGD with momentum\n",
      "- [ ] Adam\n",
      "--------------------------------Question 73--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Which of these plaintexts can be the result of the decryption of \\texttt{SERGEV} using a simple subsitution cipher?\n",
      "[ ] \\texttt{VERNAM}\n",
      "[ ] \\texttt{ENIGMA}\n",
      "[ ] \\texttt{TURING}\n",
      "[ ] \\texttt{CAESAR}\n",
      "[SOLUTION] : \n",
      "\\texttt{TURING}\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Which of these plaintexts can be the result of the decryption of \\texttt{SERGEV} using a simple subsitution cipher?\n",
      "[ ] \\texttt{VERNAM}\n",
      "[ ] \\texttt{ENIGMA}\n",
      "[ ] \\texttt{TURING}\n",
      "[ ] \\texttt{CAESAR}\n",
      "To decrypt the ciphertext \\texttt{SERGEV} using a simple substitution cipher, we need to map the letters back to their original positions in the alphabet based on the key used for encryption.\n",
      "\n",
      "Let's analyze each option:\n",
      "\n",
      "1. \\texttt{VERNAM}: The letters do not match the pattern of the ciphertext, so it is unlikely to be the correct decryption.\n",
      "\n",
      "2. \\texttt{ENIGMA}: The letters do not match the pattern of the ciphertext, so it is unlikely to be the correct decryption.\n",
      "\n",
      "3. \\texttt{TURING}: The letters do not match the pattern of the ciphertext, so it is unlikely to be the correct decryption.\n",
      "\n",
      "4. \\texttt{CAESAR}: The letters \\texttt{SERGEV} could be rearranged to form the word \\texttt{CAESAR} if a specific Caesar shift was used for encryption. Therefore, \\texttt{CAESAR} is the plaintext that could be the result of decrypting \\texttt{SERGEV} with a simple substitution cipher.\n",
      "\n",
      "Therefore, the correct answer is:\n",
      "[ ] \\texttt{VERNAM}\n",
      "[ ] \\texttt{ENIGMA}\n",
      "[ ] \\texttt{TURING}\n",
      "[X] \\texttt{CAESAR}\n",
      "--------------------------------Question 74--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : A spider of mass $m$ is suspended by its thread to a tree. The thread has elastic constant $k$ and rest length $L$ and the tree is assumed to stand still.  Gravity acts on the spider which oscillates vertically around its equilibrium position.\n",
      "Write the spider's equation of motion\n",
      "[SOLUTION] : \n",
      "The forces acting on the spider are the gravitational force $mg$ and the elastic force from the thread. The elastic force is given by Hooke's Law: $F_{\\text{elastic}} = -k(y-L)$, where $y$ is the displacement of the spider from the equilibrium position.\n",
      "\n",
      "Using Newton's second law, we have:\n",
      "$$\n",
      "m\\frac{d^2y}{dt^2} = -mg - k(y-L)\n",
      "$$\n",
      "\n",
      "Simplifying, we get the equation of motion for the spider:\n",
      "$$\n",
      "m\\frac{d^2y}{dt^2} + ky = mg + kL\n",
      "$$\n",
      "\n",
      "This is a second-order linear differential equation, which can be solved to find the motion of the spider.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "A spider of mass $m$ is suspended by its thread to a tree. The thread has elastic constant $k$ and rest length $L$ and the tree is assumed to stand still.  Gravity acts on the spider which oscillates vertically around its equilibrium position.\n",
      "Write the spider's equation of motion\n",
      "To write the equation of motion for the spider, we can consider the forces acting on it. The two main forces are the gravitational force and the force due to the tension in the thread.\n",
      "\n",
      "Let's denote the displacement of the spider from its equilibrium position as $x$. The restoring force due to the tension in the thread is given by Hooke's Law, $F_{\\text{spring}} = -kx$, where $k$ is the elastic constant of the thread.\n",
      "\n",
      "The gravitational force acting on the spider is $F_{\\text{gravity}} = mg$, where $m$ is the mass of the spider and $g$ is the acceleration due to gravity.\n",
      "\n",
      "The net force acting on the spider is the sum of the gravitational force and the restoring force:\n",
      "\n",
      "$$\n",
      "\\sum F = F_{\\text{gravity}} + F_{\\text{spring}} = mg - kx\n",
      "$$\n",
      "\n",
      "According to Newton's second law, the net force is equal to the mass of the spider times its acceleration:\n",
      "\n",
      "$$\n",
      "m \\ddot{x} = mg - kx\n",
      "$$\n",
      "\n",
      "where $\\ddot{x}$ represents the second derivative of the displacement $x$ with respect to time, which is the acceleration of the spider.\n",
      "\n",
      "Therefore, the equation of motion for the spider is:\n",
      "\n",
      "$$\n",
      "m \\ddot{x} + kx = mg\n",
      "$$\n",
      "--------------------------------Question 75--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : Assume you are working on a text editor written in Java. Your colleague is interested in optimizing a wrapper around \"String.substring()\" used to let users copy and paste parts of the text and decides to write some benchmarks to measure the current performance of the feature. How would you suggest that he proceeds?\n",
      "[SOLUTION] : \n",
      "I would suggest that your colleague follows these steps to benchmark the performance of the \"String.substring()\" wrapper:\n",
      "\n",
      "1. Identify the specific use cases for the \"String.substring()\" wrapper in the text editor where users copy and paste parts of the text.\n",
      "\n",
      "2. Create a set of test cases that represent typical scenarios where the \"String.substring()\" wrapper is used, including different input sizes and edge cases.\n",
      "\n",
      "3. Implement a benchmarking framework in Java, such as JMH (Java Microbenchmark Harness), to accurately measure the performance of the \"String.substring()\" wrapper in different scenarios.\n",
      "\n",
      "4. Run the benchmark tests multiple times to ensure consistency and accuracy of the results.\n",
      "\n",
      "5. Analyze the benchmark results to identify any performance bottlenecks or areas for optimization in the \"String.substring()\" wrapper code.\n",
      "\n",
      "6. Make improvements to the code based on the benchmark results and re-run the tests to measure the impact of the optimizations.\n",
      "\n",
      "7. Document the benchmarking process, results, and any optimizations made to the \"String.substring()\" wrapper for future reference and comparison.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Assume you are working on a text editor written in Java. Your colleague is interested in optimizing a wrapper around \"String.substring()\" used to let users copy and paste parts of the text and decides to write some benchmarks to measure the current performance of the feature. How would you suggest that he proceeds?\n",
      "Here are some steps your colleague can follow to benchmark the performance of the \"String.substring()\" wrapper in the text editor:\n",
      "\n",
      "1. **Identify the Scope of Benchmarking**: Define the specific use cases and scenarios where the \"String.substring()\" wrapper is used in the text editor. This could include copying and pasting small sections of text, large sections of text, text with different lengths, etc.\n",
      "\n",
      "2. **Select Benchmarking Tools**: Choose a benchmarking tool or library that can accurately measure the performance of the \"String.substring()\" wrapper. Popular Java benchmarking tools include JMH (Java Microbenchmarking Harness), Apache JMeter, and Caliper.\n",
      "\n",
      "3. **Create Benchmark Tests**: Write benchmark tests that simulate the typical use cases of the \"String.substring()\" wrapper in the text editor. Make sure to vary the input parameters such as text length, starting index, and ending index to cover different scenarios.\n",
      "\n",
      "4. **Run the Benchmark Tests**: Execute the benchmark tests multiple times to ensure consistent results. It's important to run the tests on a stable environment with minimal interference from other processes.\n",
      "\n",
      "5. **Collect and Analyze Results**: Record the performance metrics such as execution time, memory usage, and CPU utilization for each benchmark test. Analyze the results to identify any performance bottlenecks or areas for optimization.\n",
      "\n",
      "6. **Optimize and Retest**: Based on the benchmark results, make any necessary optimizations to the \"String.substring()\" wrapper implementation. After making changes, re-run the benchmark tests to measure the impact of the optimizations on performance.\n",
      "\n",
      "7. **Iterate and Fine-Tune**: Continue to iterate on the benchmarking process by refining the test scenarios, adjusting parameters, and retesting the performance of the \"String.substring()\" wrapper. This iterative approach will help in identifying the most effective optimizations.\n",
      "\n",
      "By following these steps, your colleague can effectively benchmark the performance of the \"String.substring()\" wrapper in the text editor and make informed decisions on how to optimize its implementation.\n",
      "--------------------------------Question 76--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : A rigid and homogeneous horizontal rod of mass M, of length L, of negligible thickness e, i.e. e << L, is rotating in a horizontal plane around the vertical axis $C e_3$ at angular velocity $\\Omega=\\dot{\\psioldsymbol{e}3$. The moment of inertia of the rod with respect to the vertical principal axis that contains its centre of mass G is $I{G,3}=\frac1{12}ML^{2}$. Let C be the point of contact between the extremity of the rod and the rotation axis, and P the point at the other extremity. The unit vector $e_1$ is oriented along the rod and the vector $e_2$ is orthogonal to $e_1$. The unit vectors $e_1$, $e_2$ and $e_3$, attached to the rod at point C, are the principal axis frame of the rod. We consider that there is no friction and we do not take explicitly into account the influence of the gravitational field. Give the expression of the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis of rotation $C e_3$ in terms of the scalar quantities M and L.\n",
      "[SOLUTION] : Applying the Huygens-Steiner theorem, we determine the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis $C e_3$ taking into account the fact that d = L/2 is the distance separating points G and C and that $I_{G,3}=\frac1{12}ML^{2}$,\n",
      "ight)^2=\frac{1}{12}ML^2+\frac{1}{4}ML^2=\frac{1}{3}ML^2$\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : A charged body with $Q=-1~\\mu C$ is dropped from a height $h=1~m$ above the Earth surface. A plate charged with $10^{19}$ electrons is placed exactly below it on the surface.\n",
      "By using the concept of potential energy, evaluate the mass $M$ of the body in order to let it float at height $h$ \\textit{(remember that the gravitational potential energy at distance $z$ close to the Earth surface can be approximated as $U=Mgz$, with $g=9.81~m/s^2$)}.\n",
      "[SOLUTION] : \n",
      "The potential energy of the charged body can be calculated as the sum of its gravitational potential energy and its electrical potential energy. \n",
      "\n",
      "The gravitational potential energy at height h above the Earth surface is given by $U_{\\text{grav}} = Mgh$, where M is the mass of the body and g is the acceleration due to gravity.\n",
      "\n",
      "The electrical potential energy of the charged body is given by $U_{\\text{elec}} = \\frac{kQq}{r}$, where k is the Coulomb constant, Q is the charge of the body, q is the charge of the plate (10^19 electrons), and r is the distance between the body and the plate.\n",
      "\n",
      "Since the body is floating at height h, the total potential energy is zero. Therefore, we have:\n",
      "\n",
      "$U_{\\text{grav}} + U_{\\text{elec}} = 0$\n",
      "\n",
      "$Mgh + \\frac{kQq}{r} = 0$\n",
      "\n",
      "Substitute the values of Q, h, q, k, and g into the equation and solve for M to find the mass of the body required for it to float at height h.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "A charged body with $Q=-1~\\mu C$ is dropped from a height $h=1~m$ above the Earth surface. A plate charged with $10^{19}$ electrons is placed exactly below it on the surface.\n",
      "By using the concept of potential energy, evaluate the mass $M$ of the body in order to let it float at height $h$ \\textit{(remember that the gravitational potential energy at distance $z$ close to the Earth surface can be approximated as $U=Mgz$, with $g=9.81~m/s^2$)}.\n",
      "To find the mass $M$ of the body in order to let it float at a height $h$, we need to consider the equilibrium condition where the electric force repelling the body upwards is equal in magnitude to the gravitational force pulling it downward.\n",
      "\n",
      "Let's analyze the forces acting on the charged body at height $h$ above the Earth's surface:\n",
      "- The electric force repelling the body upwards is due to the interaction between the body and the plate placed on the Earth's surface. This force can be calculated using Coulomb's law: $F_{\\text{elec}} = k \\frac{|Q_1| |Q_2|}{r^2}$, where $k$ is the electrostatic constant ($8.988 \\times 10^9 ~ N m^2/C^2$), $Q_1$ and $Q_2$ are the charges of the two bodies, and $r$ is the distance between them.\n",
      "- The gravitational force pulling the body downwards is given by $F_{\\text{grav}} = M g$, where $M$ is the mass of the body and $g$ is the acceleration due to gravity.\n",
      "\n",
      "At equilibrium, these two forces are equal in magnitude: $F_{\\text{elec}} = F_{\\text{grav}}$. Therefore, we can write:\n",
      "\n",
      "$k \\frac{|Q_1| |Q_2|}{r^2} = M g$\n",
      "\n",
      "Substitute the given values: $Q_1 = -1 \\times 10^{-6} ~C$, $Q_2 = -10^{19} ~e$, $r = R_{\\text{Earth}} = 6.37 \\times 10^6 ~m$, and $g = 9.81 ~m/s^2$. Also, convert the charge of the plate to Coulombs ($-10^{19} ~e \\approx -1.602 \\times 10^{-14} ~C$) and solve for $M$.\n",
      "\n",
      "$k \\frac{|-1 \\times 10^{-6}| |-1.602 \\times 10^{-14}|}{(6.37 \\times 10^6)^2} = M \\times 9.81$\n",
      "\n",
      "$M = \\frac{k \\times |-1 \\times 10^{-6} \\times -1.602 \\times 10^{-14}|}{9.81 \\times (6.37 \\times 10^6)^2}$\n",
      "\n",
      "Calculate the value of $M$ using the given values and the constants.\n",
      "--------------------------------Question 77--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : Why does Intel Itanium contain more general-purpose registers (128) than most RISC instruction sets (usually 32)?\n",
      "[SOLUTION] : \n",
      "The Intel Itanium architecture was designed to support a wide range of complex instructions and to handle very large amounts of data. Having more general-purpose registers allows for better performance and optimization of these complex instructions. RISC architectures, on the other hand, focus on simplicity and efficiency by using a smaller number of registers and simpler instructions to achieve high performance.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Why does Intel Itanium contain more general-purpose registers (128) than most RISC instruction sets (usually 32)?\n",
      "The reason Intel Itanium contains more general-purpose registers (128) compared to most RISC instruction sets (usually 32) can be attributed to the design philosophy and goals of the Itanium architecture.\n",
      "\n",
      "1. **EPIC Architecture**: Intel Itanium uses the Explicitly Parallel Instruction Computing (EPIC) architecture. EPIC architectures are designed to expose more parallelism at the hardware level, allowing for multiple instructions to be executed in parallel. To fully exploit this parallelism, a larger number of registers are needed to store intermediate values and reduce the need to access memory frequently.\n",
      "\n",
      "2. **Compiler Optimization**: EPIC architectures rely heavily on compiler optimization to schedule and execute instructions in parallel. By providing a larger number of registers, the compiler has more flexibility in assigning and managing register usage efficiently. This can lead to improved performance by reducing the need to spill registers to memory and enabling more aggressive optimization techniques.\n",
      "\n",
      "3. **Performance and Scalability**: The large number of registers in Itanium allows for better performance and scalability in handling complex and demanding workloads. By providing a vast register file, Itanium can support a wide range of applications and computational tasks, making it suitable for high-performance computing and enterprise-level workloads.\n",
      "\n",
      "4. **Legacy Compatibility**: Itanium was designed to be a versatile architecture that could support a wide range of existing software and applications. By providing a large number of general-purpose registers, Itanium can accommodate the register-intensive programming styles commonly found in legacy codebases without sacrificing performance.\n",
      "\n",
      "In contrast, traditional RISC architectures typically focus on simplicity, reduced instruction set complexity, and efficient pipelining. They often rely on register-windowing techniques or register renaming to mitigate the impact of having a smaller number of registers. This design choice helps keep the hardware implementation simpler and more power-efficient, which can be advantageous for embedded systems or low-power devices.\n",
      "\n",
      "Overall, the decision to include a large number of general-purpose registers in Intel Itanium was driven by the architecture's emphasis on parallelism, performance optimization through compiler techniques, scalability, and legacy compatibility.\n",
      "--------------------------------Question 78--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : Which of the following is TRUE for Recommender Systems (RS)?\n",
      "[ ] The complexity of the Content-based RS depends on the number of users\n",
      "[ ] Item-based RS need not only the ratings but also the item features\n",
      "[ ] Matrix Factorization is typically robust to the cold-start problem.\n",
      "[ ] Matrix Factorization can predict a score for any user-item combination in the dataset.\n",
      "[SOLUTION] : \n",
      "Matrix Factorization can predict a score for any user-item combination in the dataset. Matrix Factorization is a popular technique used in Recommender Systems that is capable of predicting ratings for user-item combinations even if those combinations have not been observed in the training data. This helps address the cold-start problem where new users or items have limited historical data.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Which of the following is TRUE for Recommender Systems (RS)?\n",
      "[ ] The complexity of the Content-based RS depends on the number of users\n",
      "[ ] Item-based RS need not only the ratings but also the item features\n",
      "[ ] Matrix Factorization is typically robust to the cold-start problem.\n",
      "[ ] Matrix Factorization can predict a score for any user-item combination in the dataset.\n",
      "Let's analyze each statement:\n",
      "\n",
      "1. [ ] The complexity of the Content-based RS depends on the number of users.\n",
      "   - This statement is generally not true. The complexity of a content-based RS typically depends more on the number of items in the dataset and the features associated with those items. The number of users may influence the computational complexity to some extent, but it is not a primary factor.\n",
      "\n",
      "2. [ ] Item-based RS need not only the ratings but also the item features.\n",
      "   - This statement is true. In item-based recommendation systems, both ratings and item features play a crucial role in determining the similarity between items and making recommendations.\n",
      "\n",
      "3. [ ] Matrix Factorization is typically robust to the cold-start problem.\n",
      "   - This statement is not true. Matrix factorization techniques are known to struggle with the cold-start problem, where there is a lack of historical data for new users or items. Cold-start problems can lead to challenges in making accurate recommendations using matrix factorization.\n",
      "\n",
      "4. [ ] Matrix Factorization can predict a score for any user-item combination in the dataset.\n",
      "   - This statement is true. Matrix factorization models can predict scores for user-item combinations based on the learned latent factors from the matrix decomposition.\n",
      "\n",
      "Therefore, the correct statements are:\n",
      "- [ ] Item-based RS need not only the ratings but also the item features.\n",
      "- [ ] Matrix Factorization can predict a score for any user-item combination in the dataset.\n",
      "--------------------------------Question 79--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : A ball of mass $m$ is hanging (vertically) on a spring of elastic constant $k$ and of natural length $l_0$. The suspension point of the spring is attached to the ceiling at height $H$.\n",
      "\n",
      "Determine the equilibrium position of the ball.\n",
      "\n",
      "[SOLUTION] : \n",
      "At equilibrium, the forces acting on the ball are the gravitational force and the spring force. The gravitational force is given by $F_{\\text{gravity}} = mg$, where $g$ is the acceleration due to gravity. The spring force is given by Hooke's Law, $F_{\\text{spring}} = k(y-l_0)$, where $y$ is the displacement of the ball from its natural length $l_0$.\n",
      "\n",
      "At equilibrium, these forces balance each other out, so we have $mg = k(y-l_0)$. Solving for $y$, we get $y = \\frac{mg}{k} + l_0$.\n",
      "\n",
      "Since the ball is hanging vertically, at equilibrium the total length of the spring is equal to the height $H$ from the ceiling. Therefore, the equilibrium position of the ball is $H = y + l_0$, which gives us $H = \\frac{mg}{k} + 2l_0$.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "A ball of mass $m$ is hanging (vertically) on a spring of elastic constant $k$ and of natural length $l_0$. The suspension point of the spring is attached to the ceiling at height $H$.\n",
      "\n",
      "Determine the equilibrium position of the ball.\n",
      "\n",
      "To determine the equilibrium position of the ball, we need to consider the forces acting on it at that position.\n",
      "\n",
      "At equilibrium, the forces acting on the ball are its weight $mg$ acting downwards and the spring force acting upwards. The spring force is given by Hooke's Law, which states that the force exerted by a spring is proportional to the displacement from its equilibrium position. \n",
      "\n",
      "Let $x$ be the displacement of the ball from its equilibrium position, then the spring force can be written as $-kx$, where the negative sign indicates that the force is acting in the opposite direction of the displacement.\n",
      "\n",
      "At equilibrium, these two forces balance each other:\n",
      "\n",
      "$mg = kx$\n",
      "\n",
      "Solving for $x$, we find:\n",
      "\n",
      "$x = \\frac{mg}{k}$\n",
      "\n",
      "Therefore, the equilibrium position of the ball is at a distance $\\frac{mg}{k}$ below the suspension point of the spring.\n",
      "--------------------------------Question 80--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : A rigid and homogeneous horizontal rod of mass M, of length L, of negligible thickness e, i.e. e << L, is rotating in a horizontal plane around the vertical axis $C e_3$ at angular velocity $\\Omega=\\dot{\\psioldsymbol{e}3$. The moment of inertia of the rod with respect to the vertical principal axis that contains its centre of mass G is $I{G,3}=\frac1{12}ML^{2}$. Let C be the point of contact between the extremity of the rod and the rotation axis, and P the point at the other extremity. The unit vector $e_1$ is oriented along the rod and the vector $e_2$ is orthogonal to $e_1$. The unit vectors $e_1$, $e_2$ and $e_3$, attached to the rod at point C, are the principal axis frame of the rod. We consider that there is no friction and we do not take explicitly into account the influence of the gravitational field. Give the expression of the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis of rotation $C e_3$ in terms of the scalar quantities M and L.\n",
      "[SOLUTION] : Applying the Huygens-Steiner theorem, we determine the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis $C e_3$ taking into account the fact that d = L/2 is the distance separating points G and C and that $I_{G,3}=\frac1{12}ML^{2}$,\n",
      "ight)^2=\frac{1}{12}ML^2+\frac{1}{4}ML^2=\frac{1}{3}ML^2$\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : An expression is referentially transparent if it always returns the same value, no matter\n",
      "the global state of the program. A referentially transparent expression can be replaced by its value without\n",
      "changing the result of the program.\n",
      "Say we have a value representing a class of students and their GPAs. Given the following defintions:\n",
      "1 case class Student(gpa: Double)\n",
      "2\n",
      "3 def count(c: List[Student], student: Student): Double =\n",
      "4 c.filter(s => s == student).size\n",
      "5\n",
      "6 val students = List(\n",
      "7 Student(1.0), Student(2.0), Student(3.0),\n",
      "8 Student(4.0), Student(5.0), Student(6.0)\n",
      "9 )\n",
      "And the expression e:\n",
      "1 count(students, Student(6.0))\n",
      "Is the expression e referentially transparent?\n",
      "[SOLUTION] : \n",
      "No, the expression e is not referentially transparent. This is because the result of the expression depends on the global state of the program, specifically the list \"students\" that is defined outside of the function. If the list \"students\" were to change, the result of the expression e would also change.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "An expression is referentially transparent if it always returns the same value, no matter\n",
      "the global state of the program. A referentially transparent expression can be replaced by its value without\n",
      "changing the result of the program.\n",
      "Say we have a value representing a class of students and their GPAs. Given the following defintions:\n",
      "1 case class Student(gpa: Double)\n",
      "2\n",
      "3 def count(c: List[Student], student: Student): Double =\n",
      "4 c.filter(s => s == student).size\n",
      "5\n",
      "6 val students = List(\n",
      "7 Student(1.0), Student(2.0), Student(3.0),\n",
      "8 Student(4.0), Student(5.0), Student(6.0)\n",
      "9 )\n",
      "And the expression e:\n",
      "1 count(students, Student(6.0))\n",
      "Is the expression e referentially transparent?\n",
      "Let's analyze the expression e: count(students, Student(6.0))\n",
      "\n",
      "In this expression:\n",
      "- The input parameters are the list of students and a specific student object with a GPA of 6.0.\n",
      "- The count function filters the list of students to find the students that are equal to the student object with a GPA of 6.0 and then returns the size of the filtered list.\n",
      "\n",
      "Now, let's consider whether the expression e is referentially transparent:\n",
      "- The expression e will always return the size of the filtered list of students with a GPA of 6.0, regardless of the global state of the program as long as the input list 'students' remains unchanged.\n",
      "- The function count does not have any side effects and solely depends on its input parameters.\n",
      "\n",
      "Therefore, the expression e: count(students, Student(6.0)) is referentially transparent because it consistently returns the same value given the same input parameters, and it can be replaced by its resulting value without affecting the program's behavior.\n",
      "--------------------------------Question 81--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Considering a sequence of n tokens, the computational complexity of the masked attention mechanism in BERT language models is: (select the smallest correct complexity)\n",
      "[ ] O(n^3)\n",
      "[ ] O(nlog(n))\n",
      "[ ] O(n)\n",
      "[ ] O(n^(1/2))\n",
      "[ ] O(n^2)\n",
      "[SOLUTION] : Masked attention is quadratic in the sequence length n because it computes the attention between all pairs of tokens, therefore O(n^2).\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : What is WRONG regarding the Transformer model?\n",
      "[ ] It uses a self-attention mechanism to compute representations of the input and output.\n",
      "[ ] Its computation cannot be parallelized compared to LSTMs and other sequential models.\n",
      "[ ] Its complexity is quadratic to the input size.\n",
      "[ ] It captures the semantic context of the input.\n",
      "[SOLUTION] : \n",
      "Its computation cannot be parallelized compared to LSTMs and other sequential models. This statement is incorrect, as the Transformer model is highly parallelizable due to its attention mechanism, allowing for more efficient training on modern hardware.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "What is WRONG regarding the Transformer model?\n",
      "[ ] It uses a self-attention mechanism to compute representations of the input and output.\n",
      "[ ] Its computation cannot be parallelized compared to LSTMs and other sequential models.\n",
      "[ ] Its complexity is quadratic to the input size.\n",
      "[ ] It captures the semantic context of the input.\n",
      "The incorrect statement regarding the Transformer model is:\n",
      "\n",
      "[ ] Its computation cannot be parallelized compared to LSTMs and other sequential models.\n",
      "\n",
      "In fact, the Transformer model can be parallelized much more efficiently compared to traditional sequential models like LSTMs due to its attention mechanism and architecture, which allows for faster training and inference on parallel computing hardware.\n",
      "--------------------------------Question 82--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Tick the \\textbf{false} statement : \n",
      "[ ] As a defender of a machine learning model you should be more worried about black-box effective attacks than white-box effective attacks.\n",
      "[ ] Privacy problems in machine learning stem solely from the need for data to train models.\n",
      "[ ] Poisoning attacks can be used to increase vulnerability to adversarial examples.\n",
      "[SOLUTION] : The false statement is : Privacy problems in machine learning stem solely from the need for data to train models. Data collection for training is one of many privacy attack vectors in machine learning. There exist attacks on models and outputs; and naturally exposing data for test is a risk in itself. The first statement is true, an adversary performing a black-box attack needs much less resources and capabilities than a white-box adversary. This is much more dangerous, as the adversary only needs the ability to interact with the model. The last statement is also true because by providing poisoning inputs, the adversary gets to shape the boundaries of the model. Thus, she can carve this boundary to facilitate classification errors. In fact, you can understand a backdoor attack as a particular instance of an adversarial example.\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : A simple substitution cipher can be broken \\dots\n",
      "[ ] by analysing the probability occurence of the language.\n",
      "[ ] only by using a quantum computer.\n",
      "[ ] by using the ENIGMA machine.\n",
      "[ ] by using public-key cryptogaphy.\n",
      "[SOLUTION] : \n",
      "The correct answer is: by analysing the probability occurrence of the language. Substitution ciphers can be broken by analyzing the frequency of letters in the encrypted text and comparing it to the frequency of letters in the language being used. This method is known as frequency analysis.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "A simple substitution cipher can be broken \\dots\n",
      "[ ] by analysing the probability occurence of the language.\n",
      "[ ] only by using a quantum computer.\n",
      "[ ] by using the ENIGMA machine.\n",
      "[ ] by using public-key cryptogaphy.\n",
      "[ ] by analysing the probability occurence of the language.\n",
      "--------------------------------Question 83--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : A rigid and homogeneous horizontal rod of mass M, of length L, of negligible thickness e, i.e. e << L, is rotating in a horizontal plane around the vertical axis $C e_3$ at angular velocity $\\Omega=\\dot{\\psioldsymbol{e}3$. The moment of inertia of the rod with respect to the vertical principal axis that contains its centre of mass G is $I{G,3}=\frac1{12}ML^{2}$. Let C be the point of contact between the extremity of the rod and the rotation axis, and P the point at the other extremity. The unit vector $e_1$ is oriented along the rod and the vector $e_2$ is orthogonal to $e_1$. The unit vectors $e_1$, $e_2$ and $e_3$, attached to the rod at point C, are the principal axis frame of the rod. We consider that there is no friction and we do not take explicitly into account the influence of the gravitational field. Give the expression of the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis of rotation $C e_3$ in terms of the scalar quantities M and L.\n",
      "[SOLUTION] : Applying the Huygens-Steiner theorem, we determine the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis $C e_3$ taking into account the fact that d = L/2 is the distance separating points G and C and that $I_{G,3}=\frac1{12}ML^{2}$,\n",
      "ight)^2=\frac{1}{12}ML^2+\frac{1}{4}ML^2=\frac{1}{3}ML^2$\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] :  Design and analyze a  polynomial-time algorithm for the following problem: \\begin{center} \\begin{boxedminipage}[t]{0.83\\textwidth} \\begin{description} \\item[Input:] a vertex set $V$. \\item[Output:]  vertex subsets $S_1, S_2, \\ldots, S_\\ell \\subseteq V$ with the following property:\\\\[2mm] For every set of edges $E\\subseteq {V \\choose 2}$, there is an $i\\in \\{1,2, \\ldots, \\ell\\}$ such that \\begin{align*} |\\{e\\in E: |e\\cap S_i| = 1\\}| \\geq |E|/2\\,, \\end{align*} i.e., $S_i$ cuts at least half the edges in $G = (V,E)$. \\end{description} \\end{boxedminipage} \\end{center} We remark that, since your algorithm should run in time polynomial in $n=|V|$, it can output at most polynomially (in $n$) many vertex sets. We also emphasize that the algorithm does \\textbf{not} take the edge set $E$ as input. {\\em (In this problem you are asked to (i) design the algorithm, (ii) show that it runs in time polynomial in $n$, and (iii) prove that the output satisfies the property given in the problem statement. Recall that you are allowed to refer to material covered in the lecture notes.)}\n",
      "[SOLUTION] : \n",
      "(i) To design the algorithm, we can use a randomized approach. \n",
      "\n",
      "1. Randomly select a vertex subset $S_1 \\subseteq V$.\n",
      "2. For each edge $e \\in E$, check if $|e \\cap S_1| = 1$. If so, add $e$ to a list $L$.\n",
      "3. Repeat steps 1 and 2 for a certain number of iterations to obtain subsets $S_2, S_3, ..., S_\\ell$.\n",
      "4. Output the subsets $S_1, S_2, ..., S_\\ell$.\n",
      "\n",
      "(ii) This algorithm runs in polynomial time since the main loop iterates a polynomial number of times, and for each iteration, we perform polynomial operations.\n",
      "\n",
      "(iii) To prove that the output satisfies the property given in the problem statement, consider any set of edges $E \\subseteq {V \\choose 2}$. By the Pigeonhole Principle, at least one of the subsets $S_i$ will cut at least half of the edges in $E$. This is because if we randomly select vertices for $S_i$ multiple times, eventually we will cover all possible edge configurations in $E$ with at least one of the subsets $S_i$.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      " Design and analyze a  polynomial-time algorithm for the following problem: \\begin{center} \\begin{boxedminipage}[t]{0.83\\textwidth} \\begin{description} \\item[Input:] a vertex set $V$. \\item[Output:]  vertex subsets $S_1, S_2, \\ldots, S_\\ell \\subseteq V$ with the following property:\\\\[2mm] For every set of edges $E\\subseteq {V \\choose 2}$, there is an $i\\in \\{1,2, \\ldots, \\ell\\}$ such that \\begin{align*} |\\{e\\in E: |e\\cap S_i| = 1\\}| \\geq |E|/2\\,, \\end{align*} i.e., $S_i$ cuts at least half the edges in $G = (V,E)$. \\end{description} \\end{boxedminipage} \\end{center} We remark that, since your algorithm should run in time polynomial in $n=|V|$, it can output at most polynomially (in $n$) many vertex sets. We also emphasize that the algorithm does \\textbf{not} take the edge set $E$ as input. {\\em (In this problem you are asked to (i) design the algorithm, (ii) show that it runs in time polynomial in $n$, and (iii) prove that the output satisfies the property given in the problem statement. Recall that you are allowed to refer to material covered in the lecture notes.)}\n",
      "To design an algorithm for this problem, we can proceed as follows:\n",
      "\n",
      "**Algorithm:**\n",
      "1. Let $V_1 = V$ be the initial vertex set.\n",
      "2. Initialize an empty list of subsets $S_1, S_2, \\ldots, S_\\ell$.\n",
      "3. While $V_i$ is not empty, do the following:\n",
      "   a. Pick a vertex $v$ uniformly at random from $V_i$.\n",
      "   b. Let $S_i = \\{v\\}$.\n",
      "   c. Remove $v$ and its neighbors from $V_i$.\n",
      "   d. Increment $i$.\n",
      "4. Output the list of subsets $S_1, S_2, \\ldots, S_\\ell$.\n",
      "\n",
      "**Analysis:**\n",
      "- Step 1 takes $O(1)$ time.\n",
      "- In each iteration of the while loop, we pick a vertex $v$ and remove $v$ and its neighbors. This can be done in $O(|V_i|)$ time.\n",
      "- The while loop runs for at most $|V|$ iterations since we remove at least one vertex in each iteration.\n",
      "- Thus, the algorithm runs in $O(|V|^2)$ time, which is polynomial in $n$.\n",
      "\n",
      "**Proof of Property:**\n",
      "Let $E$ be any set of edges in ${V \\choose 2}$. Since we pick a vertex and remove its neighbors in each iteration, there exists at least one $S_i$ that contains an endpoint of each edge in $E$.\n",
      "Thus, for any set of edges $E$, there is at least one $S_i$ that cuts at least half the edges in $E$.\n",
      "Therefore, the output of the algorithm satisfies the required property.\n",
      "--------------------------------Question 84--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Tick the \\textbf{false} statement : \n",
      "[ ] As a defender of a machine learning model you should be more worried about black-box effective attacks than white-box effective attacks.\n",
      "[ ] Privacy problems in machine learning stem solely from the need for data to train models.\n",
      "[ ] Poisoning attacks can be used to increase vulnerability to adversarial examples.\n",
      "[SOLUTION] : The false statement is : Privacy problems in machine learning stem solely from the need for data to train models. Data collection for training is one of many privacy attack vectors in machine learning. There exist attacks on models and outputs; and naturally exposing data for test is a risk in itself. The first statement is true, an adversary performing a black-box attack needs much less resources and capabilities than a white-box adversary. This is much more dangerous, as the adversary only needs the ability to interact with the model. The last statement is also true because by providing poisoning inputs, the adversary gets to shape the boundaries of the model. Thus, she can carve this boundary to facilitate classification errors. In fact, you can understand a backdoor attack as a particular instance of an adversarial example.\n",
      "[QUESTION] : Tick the false assertion. Bluetooth ... \n",
      "[ ] uses a stream cipher for encryption.\n",
      "[ ] has secure integrity protection for secure communication.\n",
      "[ ] has devices which use the same secret key with any other device.uses the SAFER+ block cipher in a one-way mode.\n",
      "[SOLUTION] : The false assertion is : has secure integrity protection for secure communication. Bluetooth is indeed a secure protocol which relies on the E0 stream cipher for privacy. In Bluetooth, the encryption process involves the Long Term Key (LTK), which is a secret key shared and stored by both connected devices. Bluetooth implements confidentiality, authentication and key derivation with custom algorithms based on a SAFER+ block cipher\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : In classification, which of the following is true regarding class imbalance?\n",
      "[ ] Classes should have the same distribution in the validation set and in the full dataset.\n",
      "[ ] Oversampling the larger class can reduce the impact of the skewed distribution.\n",
      "[ ] Oversampling rare classes in the testing set can reduce the impact of skewed distribution.\n",
      "[ ] The leave-one-out methodology produces the same class distribution in the training and the testing set.\n",
      "[SOLUTION] : \n",
      "Oversampling the larger class can reduce the impact of the skewed distribution. Class imbalance refers to when one class has significantly more instances than another class. Oversampling the larger class can help balance out the distribution and improve the model's performance. The other statements are false. Classes do not need to have the same distribution in the validation set and the full dataset. Oversampling rare classes in the testing set can introduce bias and is not recommended. The leave-one-out methodology does not guarantee the same class distribution in the training and testing set.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "In classification, which of the following is true regarding class imbalance?\n",
      "[ ] Classes should have the same distribution in the validation set and in the full dataset.\n",
      "[ ] Oversampling the larger class can reduce the impact of the skewed distribution.\n",
      "[ ] Oversampling rare classes in the testing set can reduce the impact of skewed distribution.\n",
      "[ ] The leave-one-out methodology produces the same class distribution in the training and the testing set.\n",
      "The correct statement regarding class imbalance in classification is:\n",
      "\n",
      "[ ] Oversampling the larger class can reduce the impact of the skewed distribution.\n",
      "\n",
      "Explanation:\n",
      "- Class imbalance occurs when one class has significantly more instances than another class in the dataset.\n",
      "- In the case of class imbalance, oversampling the larger class can help balance out the distribution and reduce the impact of the skewed distribution.\n",
      "- It is important to balance the class distribution to prevent the model from being biased towards the majority class.\n",
      "--------------------------------Question 85--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : We learnt in the lecture that terms are typically stored in an inverted list. Now, in the inverted list, instead of only storing document identifiers of the documents in which the term appears, assume we also store an *offset* of the appearance of a term in a document. An $offset$ of a term $l_k$ given a document is defined as the number of words between the start of the document and $l_k$. Thus our inverted list is now:  $l_k= \\langle f_k: \\{d_{i_1} \\rightarrow [o_1,\\ldots,o_{n_{i_1}}]\\},  \\{d_{i_2} \\rightarrow [o_1,\\ldots,o_{n_{i_2}}]\\}, \\ldots,  \\{d_{i_k} \\rightarrow [o_1,\\ldots,o_{n_{i_k}}]\\} \\rangle$  This means that in document $d_{i_1}$ term $l_k$ appears $n_{i_1}$ times and at offset $[o_1,\\ldots,o_{n_{i_1}}]$, where $[o_1,\\ldots,o_{n_{i_1}}]$ are sorted in ascending order, these type of indices are also known as term-offset indices. An example of a term-offset index is as follows:  **Obama** = $⟨4 : {1 → [3]},{2 → [6]},{3 → [2,17]},{4 → [1]}⟩$  **Governor** = $⟨2 : {4 → [3]}, {7 → [14]}⟩$  **Election** = $⟨4 : {1 → [1]},{2 → [1,21]},{3 → [3]},{5 → [16,22,51]}⟩$  Which is to say that the term **Governor** appear in 2 documents. In document 4 at offset 3, in document 7 at offset 14. Now let us consider the *SLOP/x* operator in text retrieval. This operator has the syntax: *QueryTerm1 SLOP/x QueryTerm2* finds occurrences of *QueryTerm1* within $x$ (but not necessarily in that order) words of *QueryTerm2*, where $x$ is a positive integer argument ($x \\geq 1$). Thus $x = 1$ demands that *QueryTerm1* be adjacent to *QueryTerm2*.  Consider the general procedure for \"merging\" two term-offset inverted lists for a given document, to determine where the document satisfies a *SLOP/x* clause (since in general there will be many offsets at which each term occurs in a document). Let $L$ denote the total number of occurrences of the two terms in the document. Assume we have a pointer to the list of occurrences of each term and can move the pointer along this list. As we do so we check whether we have a hit for $SLOP/x$ (i.e. the $SLOP/x$ clause is satisfied). Each move of either pointer counts as a step. Based on this assumption is there a general \"merging\" procedure to determine whether the document satisfies a $SLOP/x$ clause, for which the following is true? Justify your answer.      1. The merge can be accomplished in a number of steps linear in $L$ regardless of $x$, and we can ensure that each pointer moves only to the right (i.e. forward).     2. The merge can be accomplished in a number of steps linear in $L$, but a pointer may be forced to move to the left (i.e. backwards).     3. The merge can require $x \\times L$ steps in some cases.\n",
      "[SOLUTION] : \n",
      "The correct answer is 2. The merge can be accomplished in a number of steps linear in L, but a pointer may be forced to move to the left (i.e. backwards).\n",
      "\n",
      "In order to determine whether a document satisfies a SLOP/x clause, we need to consider all possible combinations of offsets for the two terms within the document. This may require moving the pointers of the term-offset inverted lists in both directions to find valid combinations that satisfy the SLOP/x condition.\n",
      "\n",
      "Since the SLOP/x operator allows for the terms to appear within x words of each other in any order, it is possible that we need to backtrack and recheck certain offsets if a valid combination is not found initially. This means that in some cases, a pointer may be forced to move to the left (backwards) in order to find a satisfying combination.\n",
      "\n",
      "Therefore, the merge can be accomplished in a number of steps linear in L, but it may require moving the pointers in both directions to find all valid combinations that satisfy the SLOP/x clause.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "We learnt in the lecture that terms are typically stored in an inverted list. Now, in the inverted list, instead of only storing document identifiers of the documents in which the term appears, assume we also store an *offset* of the appearance of a term in a document. An $offset$ of a term $l_k$ given a document is defined as the number of words between the start of the document and $l_k$. Thus our inverted list is now:  $l_k= \\langle f_k: \\{d_{i_1} \\rightarrow [o_1,\\ldots,o_{n_{i_1}}]\\},  \\{d_{i_2} \\rightarrow [o_1,\\ldots,o_{n_{i_2}}]\\}, \\ldots,  \\{d_{i_k} \\rightarrow [o_1,\\ldots,o_{n_{i_k}}]\\} \\rangle$  This means that in document $d_{i_1}$ term $l_k$ appears $n_{i_1}$ times and at offset $[o_1,\\ldots,o_{n_{i_1}}]$, where $[o_1,\\ldots,o_{n_{i_1}}]$ are sorted in ascending order, these type of indices are also known as term-offset indices. An example of a term-offset index is as follows:  **Obama** = $⟨4 : {1 → [3]},{2 → [6]},{3 → [2,17]},{4 → [1]}⟩$  **Governor** = $⟨2 : {4 → [3]}, {7 → [14]}⟩$  **Election** = $⟨4 : {1 → [1]},{2 → [1,21]},{3 → [3]},{5 → [16,22,51]}⟩$  Which is to say that the term **Governor** appear in 2 documents. In document 4 at offset 3, in document 7 at offset 14. Now let us consider the *SLOP/x* operator in text retrieval. This operator has the syntax: *QueryTerm1 SLOP/x QueryTerm2* finds occurrences of *QueryTerm1* within $x$ (but not necessarily in that order) words of *QueryTerm2*, where $x$ is a positive integer argument ($x \\geq 1$). Thus $x = 1$ demands that *QueryTerm1* be adjacent to *QueryTerm2*.  Consider the general procedure for \"merging\" two term-offset inverted lists for a given document, to determine where the document satisfies a *SLOP/x* clause (since in general there will be many offsets at which each term occurs in a document). Let $L$ denote the total number of occurrences of the two terms in the document. Assume we have a pointer to the list of occurrences of each term and can move the pointer along this list. As we do so we check whether we have a hit for $SLOP/x$ (i.e. the $SLOP/x$ clause is satisfied). Each move of either pointer counts as a step. Based on this assumption is there a general \"merging\" procedure to determine whether the document satisfies a $SLOP/x$ clause, for which the following is true? Justify your answer.      1. The merge can be accomplished in a number of steps linear in $L$ regardless of $x$, and we can ensure that each pointer moves only to the right (i.e. forward).     2. The merge can be accomplished in a number of steps linear in $L$, but a pointer may be forced to move to the left (i.e. backwards).     3. The merge can require $x \\times L$ steps in some cases.\n",
      "To determine whether a document satisfies a SLOP/x clause for two terms with term-offset inverted lists, we need to find occurrences of QueryTerm1 within x words of QueryTerm2. Given the term-offset inverted lists, we can merge the lists of occurrences for each term in a document using a pointer-based approach.\n",
      "\n",
      "Let's analyze the options provided:\n",
      "\n",
      "1. **The merge can be accomplished in a number of steps linear in L regardless of x, and we can ensure that each pointer moves only to the right (i.e. forward).**\n",
      "\n",
      "This option implies that we can merge the term-offset inverted lists in a linear number of steps in terms of the total number of occurrences (L), and each pointer moves only to the right. This approach is feasible because we are essentially comparing the positions of the terms in the document and checking if the SLOP/x clause is satisfied. By iterating through the occurrences of each term in the document and comparing positions, we can achieve this linear time complexity. So, this option is valid.\n",
      "\n",
      "2. **The merge can be accomplished in a number of steps linear in L, but a pointer may be forced to move to the left (i.e. backwards).**\n",
      "\n",
      "For a SLOP/x operator, we are interested in finding occurrences within a specific range of x words, irrespective of the direction. However, moving the pointer backward in a term-offset inverted list may not always be necessary for checking the SLOP/x clause. Since we are interested in a fixed range x, we can achieve this by moving the pointers forward only, making this option less likely.\n",
      "\n",
      "3. **The merge can require x * L steps in some cases.**\n",
      "\n",
      "If we consider this option, it would imply that for each occurrence of QueryTerm1, we would need to potentially iterate through x occurrences of QueryTerm2 to check the SLOP/x condition. This approach could lead to x * L steps in the worst-case scenario where we have to check all possible combinations within the specified range. However, a more efficient way would be to merge the inverted lists linearly and track the relative positions of the terms to satisfy the SLOP/x condition, making this option less likely.\n",
      "\n",
      "Therefore, based on the analysis, the most suitable option is:\n",
      "\n",
      "**1. The merge can be accomplished in a number of steps linear in L regardless of x, and we can ensure that each pointer moves only to the right (i.e. forward).**\n",
      "--------------------------------Question 86--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Tick the \\textbf{false} statement : \n",
      "[ ] As a defender of a machine learning model you should be more worried about black-box effective attacks than white-box effective attacks.\n",
      "[ ] Privacy problems in machine learning stem solely from the need for data to train models.\n",
      "[ ] Poisoning attacks can be used to increase vulnerability to adversarial examples.\n",
      "[SOLUTION] : The false statement is : Privacy problems in machine learning stem solely from the need for data to train models. Data collection for training is one of many privacy attack vectors in machine learning. There exist attacks on models and outputs; and naturally exposing data for test is a risk in itself. The first statement is true, an adversary performing a black-box attack needs much less resources and capabilities than a white-box adversary. This is much more dangerous, as the adversary only needs the ability to interact with the model. The last statement is also true because by providing poisoning inputs, the adversary gets to shape the boundaries of the model. Thus, she can carve this boundary to facilitate classification errors. In fact, you can understand a backdoor attack as a particular instance of an adversarial example.\n",
      "ight)^2 + x^2 \\). Select the correct statement:\n",
      "ight)  \\) but not \\(\\Omega\\left(3 x \\left(\\log_2(x) \n",
      "[ ] None of the other statements are correct\n",
      "ight)  \\))\\) is \\(\\Theta \\left(3 x \\left(\\log_2(x) \n",
      "ight)  \\) but not \\(O\\left(3 x \\left(\\log_2(x) x) \n",
      "[SOLUTION] : \n",
      "The correct statement is: \\(f(x)\\) is \\(\\Theta \\left(3 x \\left(\\log_2(x) \\right)^2 \\right)\\). This is because \\(f(x)\\) is both upper bounded by \\(3 x \\left(\\log_2(x) \\right)^2\\) and lower bounded by \\(3 x \\left(\\log_2(x) \\right)^2\\), indicating that it grows at the same rate.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "ight)^2 + x^2 \\). Select the correct statement:\n",
      "ight)  \\) but not \\(\\Omega\\left(3 x \\left(\\log_2(x) \n",
      "[ ] None of the other statements are correct\n",
      "ight)  \\))\\) is \\(\\Theta \\left(3 x \\left(\\log_2(x) \n",
      "ight)  \\) but not \\(O\\left(3 x \\left(\\log_2(x) x) \n",
      "To determine whether \\(f(x)\\) is \\(O\\), \\(\\Omega\\), or \\(\\Theta\\) of \\(3x(\\log_2(x))^2\\), we need to compare their growth rates.\n",
      "\n",
      "First, let's simplify \\(3x(\\log_2(x))^2\\) and \\(x^2\\):\n",
      "\\[ 3x(\\log_2(x))^2 = 3x(\\log(x)/\\log(2))^2 = 3x(\\log(x))^2/\\log^2(2) = 3x(\\log(x))^2/\\log(2)^2 \\]\n",
      "\n",
      "Now, let's compare the growth rates of \\(f(x)\\) and \\(3x(\\log(x))^2/\\log(2)^2\\) as \\(x\\) approaches infinity.\n",
      "\n",
      "1. As \\(x\\) approaches infinity, the dominant term in \\(f(x)\\) is \\(3x(\\log(x))^2\\) because the logarithmic term grows slower than the quadratic term.\n",
      "2. We can see that \\(f(x)\\) grows faster than \\(3x(\\log(x))^2\\), which means \\(f(x)\\) is \\(\\Omega(3x(\\log(x))^2)\\).\n",
      "\n",
      "Therefore, the correct statement is:\n",
      "[ ] \\(f(x)\\) is \\(\\Omega\\left(3 x \\left(\\log_2(x)\\right)^2\\right)\\) but not \\(O\\left(3 x \\left(\\log_2(x)\\right)^2\\right)\\)\n",
      "--------------------------------Question 87--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : A rigid and homogeneous horizontal rod of mass M, of length L, of negligible thickness e, i.e. e << L, is rotating in a horizontal plane around the vertical axis $C e_3$ at angular velocity $\\Omega=\\dot{\\psioldsymbol{e}3$. The moment of inertia of the rod with respect to the vertical principal axis that contains its centre of mass G is $I{G,3}=\frac1{12}ML^{2}$. Let C be the point of contact between the extremity of the rod and the rotation axis, and P the point at the other extremity. The unit vector $e_1$ is oriented along the rod and the vector $e_2$ is orthogonal to $e_1$. The unit vectors $e_1$, $e_2$ and $e_3$, attached to the rod at point C, are the principal axis frame of the rod. We consider that there is no friction and we do not take explicitly into account the influence of the gravitational field. Give the expression of the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis of rotation $C e_3$ in terms of the scalar quantities M and L.\n",
      "[SOLUTION] : Applying the Huygens-Steiner theorem, we determine the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis $C e_3$ taking into account the fact that d = L/2 is the distance separating points G and C and that $I_{G,3}=\frac1{12}ML^{2}$,\n",
      "ight)^2=\frac{1}{12}ML^2+\frac{1}{4}ML^2=\frac{1}{3}ML^2$\n",
      "[QUESTION] : Consider an IR engine, which uses an indexing mechanism implementing the following 3 consecutive filters:\n",
      "\n",
      "a morpho-syntactic filter that restricts indexing term candidates to only nouns, and reduces them to their root forms;\n",
      "a frequencial filter parameterized with \\(f_\\text{min}=0.06\\) (resp. \\(f_\\text{max}=0.20\\)) as lower (resp. upper) cut-off value, expressed as relative frequencies;\n",
      "a stop word filter using the following stop list: {a, in, mouse, the}.\n",
      "\n",
      "and the following document \\(d\\):\n",
      "\n",
      "Cats are the worst enemies of rodents. After all, a cat is a cat: as soon as it can, it rushes into the bushes with only one target in mind: mice, mice and mice! Naturally, the cats of houses are less frightening, as for them croquette loaded dressers have replaced prey hiding bushes. Cat's life in the house is easy!...\n",
      "\n",
      "What is the multi-set resulting from the indexing of document \\(d\\) by the above described IR engine?\n",
      "Format your answer as an alphabetically ordered list of the form: \"lemma1(tf1), lemma2(tf2), ...\", where tfi is the term frequency of indexing term i.\n",
      "For instance: dog(2), frog(3), zebra(1)\n",
      "[SOLUTION] : \n",
      "After applying the 3 consecutive filters to the document \\(d\\), the resulting multi-set from the indexing by the IR engine is:\n",
      "\n",
      "cat(2), enemy(1), house(2), life(1), prey(1), target(1)\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Consider an IR engine, which uses an indexing mechanism implementing the following 3 consecutive filters:\n",
      "\n",
      "a morpho-syntactic filter that restricts indexing term candidates to only nouns, and reduces them to their root forms;\n",
      "a frequencial filter parameterized with \\(f_\\text{min}=0.06\\) (resp. \\(f_\\text{max}=0.20\\)) as lower (resp. upper) cut-off value, expressed as relative frequencies;\n",
      "a stop word filter using the following stop list: {a, in, mouse, the}.\n",
      "\n",
      "and the following document \\(d\\):\n",
      "\n",
      "Cats are the worst enemies of rodents. After all, a cat is a cat: as soon as it can, it rushes into the bushes with only one target in mind: mice, mice and mice! Naturally, the cats of houses are less frightening, as for them croquette loaded dressers have replaced prey hiding bushes. Cat's life in the house is easy!...\n",
      "\n",
      "What is the multi-set resulting from the indexing of document \\(d\\) by the above described IR engine?\n",
      "Format your answer as an alphabetically ordered list of the form: \"lemma1(tf1), lemma2(tf2), ...\", where tfi is the term frequency of indexing term i.\n",
      "For instance: dog(2), frog(3), zebra(1)\n",
      "To find the multi-set resulting from the indexing of the document \\(d\\) by the described IR engine, we need to apply the three consecutive filters to the terms in the document. Let's go step by step:\n",
      "\n",
      "1. Apply the morpho-syntactic filter:\n",
      "- Only nouns are retained and reduced to their root forms:\n",
      "  - Cats -> cat\n",
      "  - enemies -> enemy\n",
      "  - rodents -> rodent\n",
      "  - cat -> cat\n",
      "  - target -> target\n",
      "  - mice -> mouse\n",
      "  - cats -> cat\n",
      "  - houses -> house\n",
      "  - croquette -> croquette\n",
      "  - dressers -> dresser\n",
      "  - prey -> prey\n",
      "  - bushes -> bush\n",
      "  - cat's -> cat\n",
      "  - house -> house\n",
      "\n",
      "2. Apply the frequencial filter:\n",
      "- Calculate the term frequencies for each lemma:\n",
      "  - cat(3), enemy(1), rodent(1), target(1), mouse(1), house(2), croquette(1), dresser(1), prey(1), bush(1)\n",
      "\n",
      "3. Apply the stop word filter:\n",
      "- Remove the terms in the stop list: {a, in, mouse, the}\n",
      "- Remaining terms: cat(3), enemy(1), rodent(1), target(1), house(2), croquette(1), dresser(1), prey(1), bush(1)\n",
      "\n",
      "Therefore, the multi-set resulting from the indexing of document \\(d\\) by the IR engine is:\n",
      "cat(3), croquette(1), dresser(1), enemy(1), house(2), prey(1), rodent(1), target(1)\n",
      "--------------------------------Question 88--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : A rigid and homogeneous horizontal rod of mass M, of length L, of negligible thickness e, i.e. e << L, is rotating in a horizontal plane around the vertical axis $C e_3$ at angular velocity $\\Omega=\\dot{\\psioldsymbol{e}3$. The moment of inertia of the rod with respect to the vertical principal axis that contains its centre of mass G is $I{G,3}=\frac1{12}ML^{2}$. Let C be the point of contact between the extremity of the rod and the rotation axis, and P the point at the other extremity. The unit vector $e_1$ is oriented along the rod and the vector $e_2$ is orthogonal to $e_1$. The unit vectors $e_1$, $e_2$ and $e_3$, attached to the rod at point C, are the principal axis frame of the rod. We consider that there is no friction and we do not take explicitly into account the influence of the gravitational field. Give the expression of the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis of rotation $C e_3$ in terms of the scalar quantities M and L.\n",
      "[SOLUTION] : Applying the Huygens-Steiner theorem, we determine the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis $C e_3$ taking into account the fact that d = L/2 is the distance separating points G and C and that $I_{G,3}=\frac1{12}ML^{2}$,\n",
      "ight)^2=\frac{1}{12}ML^2+\frac{1}{4}ML^2=\frac{1}{3}ML^2$\n",
      "[QUESTION] : For each column of the lattice used in the Viterbi algorithm applied to that input sequence (\"process time control\"), how many nodes (= lines) does it have?Provide your answer as a coma separated list of integers.For instance, if the lattice has 5 columns, you could for instance here write:4,3,2,4,2\n",
      "[SOLUTION] : \n",
      "The number of nodes in each column of the lattice decreases as we move towards the end of the input sequence. Therefore, the number of nodes in each column would be: 6, 5, 4, 3, 2, 1, 1, 1.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "For each column of the lattice used in the Viterbi algorithm applied to that input sequence (\"process time control\"), how many nodes (= lines) does it have?Provide your answer as a coma separated list of integers.For instance, if the lattice has 5 columns, you could for instance here write:4,3,2,4,2\n",
      "To determine the number of nodes in each column of the lattice for the Viterbi algorithm applied to the input sequence \"process time control,\" we need to consider the number of possible states at each time step.\n",
      "\n",
      "The input sequence has 18 characters, so there are 18 time steps in the Viterbi algorithm. Each time step corresponds to a column in the lattice.\n",
      "\n",
      "Now, let's analyze the number of nodes in each column:\n",
      "\n",
      "1. For the first column (corresponding to the first character \"p\"), there are 4 possible states: P, R, S, T. Hence, 4 nodes.\n",
      "2. For the second column (corresponding to the first two characters \"pr\"), there are 3 possible states: O, T, R. Hence, 3 nodes.\n",
      "3. For the third column (corresponding to the first three characters \"pro\"), there are 2 possible states: C, E. Hence, 2 nodes.\n",
      "4. For the fourth column (corresponding to the first four characters \"proc\"), there are 4 possible states: E, S, T, O. Hence, 4 nodes.\n",
      "5. For the fifth column (corresponding to the first five characters \"proce\"), there are 2 possible states: S, D. Hence, 2 nodes.\n",
      "6. For the sixth column (corresponding to the first six characters \"proces\"), there are 4 possible states: S, S, T, O. Hence, 4 nodes.\n",
      "7. For the seventh column (corresponding to the first seven characters \"process\"), there are 3 possible states: T, T, O. Hence, 3 nodes.\n",
      "8. For the eighth column (corresponding to the first eight characters \"process \"), there are 4 possible states: T, I, M, E. Hence, 4 nodes.\n",
      "9. For the ninth column (corresponding to the first nine characters \"process t\"), there are 3 possible states: I, M, E. Hence, 3 nodes.\n",
      "10. For the tenth column (corresponding to the first ten characters \"process ti\"), there are 3 possible states: M, E, C. Hence, 3 nodes.\n",
      "11. For the eleventh column (corresponding to the first eleven characters \"process tim\"), there are 2 possible states: E, E. Hence, 2 nodes.\n",
      "12. For the twelfth column (corresponding to the first twelve characters \"process time\"), there are 3 possible states: A, M, E. Hence, 3 nodes.\n",
      "13. For the thirteenth column (corresponding to the first thirteen characters \"process time \"), there are 3 possible states: M, C, O. Hence, 3 nodes.\n",
      "14. For the fourteenth column (corresponding to the first fourteen characters \"process time c\"), there are 3 possible states: O, O, R. Hence, 3 nodes.\n",
      "15. For the fifteenth column (corresponding to the first fifteen characters \"process time co\"), there are 3 possible states: N, N, T. Hence, 3 nodes.\n",
      "16. For the sixteenth column (corresponding to the first sixteen characters \"process time con\"), there are 2 possible states: T, S. Hence, 2 nodes.\n",
      "17. For the seventeenth column (corresponding to the first seventeen characters \"process time cont\"), there are 2 possible states: R, I. Hence, 2 nodes.\n",
      "18. For the eighteenth column (corresponding to the entire sequence \"process time control\"), there are 3 possible states: R, O, L. Hence, 3 nodes.\n",
      "\n",
      "Therefore, the number of nodes in each column of the lattice, from left to right, is: 4, 3, 2, 4, 2, 4, 3, 4, 3, 3, 2, 3, 3, 3, 3, 2, 2, 3.\n",
      "--------------------------------Question 89--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Tick the \\textbf{false} statement : \n",
      "[ ] As a defender of a machine learning model you should be more worried about black-box effective attacks than white-box effective attacks.\n",
      "[ ] Privacy problems in machine learning stem solely from the need for data to train models.\n",
      "[ ] Poisoning attacks can be used to increase vulnerability to adversarial examples.\n",
      "[SOLUTION] : The false statement is : Privacy problems in machine learning stem solely from the need for data to train models. Data collection for training is one of many privacy attack vectors in machine learning. There exist attacks on models and outputs; and naturally exposing data for test is a risk in itself. The first statement is true, an adversary performing a black-box attack needs much less resources and capabilities than a white-box adversary. This is much more dangerous, as the adversary only needs the ability to interact with the model. The last statement is also true because by providing poisoning inputs, the adversary gets to shape the boundaries of the model. Thus, she can carve this boundary to facilitate classification errors. In fact, you can understand a backdoor attack as a particular instance of an adversarial example.\n",
      "[QUESTION] : What is the mean squared error of $f$ for a sample, where $\\textbf{x}$ is an input, $y$ a target and $f(\\textbf{x},W)$ the mapping function  ? \n",
      "(One answer)\n",
      "[ ]  $||y - f(\\textbf{x},W)||^2 $ \n",
      "[ ]  $||y - f(\\textbf{x},W)|| $\n",
      "[ ]  $-\\log(P(y=i | \\textbf{x})) = -\\log(\\frac{e^{\\textbf{f}_i(\\textbf{x},W)}}{\\sum_j e^{\\textbf{f}_j(\\textbf{x},W)}})$ \n",
      "[ ]  $P(y=i |\\textbf{x}) = \\frac{e^{\\textbf{f}_i(\\textbf{x},W)}}{\\sum_j e^{\\textbf{f}_j(\\textbf{x},W)}}$ \n",
      "[SOLUTION] : \n",
      "The mean squared error (MSE) of $f$ for a sample is given by $||y - f(\\textbf{x},W)||^2 $.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "What is the mean squared error of $f$ for a sample, where $\\textbf{x}$ is an input, $y$ a target and $f(\\textbf{x},W)$ the mapping function  ? \n",
      "(One answer)\n",
      "[ ]  $||y - f(\\textbf{x},W)||^2 $ \n",
      "[ ]  $||y - f(\\textbf{x},W)|| $\n",
      "[ ]  $-\\log(P(y=i | \\textbf{x})) = -\\log(\\frac{e^{\\textbf{f}_i(\\textbf{x},W)}}{\\sum_j e^{\\textbf{f}_j(\\textbf{x},W)}})$ \n",
      "[ ]  $P(y=i |\\textbf{x}) = \\frac{e^{\\textbf{f}_i(\\textbf{x},W)}}{\\sum_j e^{\\textbf{f}_j(\\textbf{x},W)}}$ \n",
      "$||y - f(\\textbf{x},W)||^2 $\n",
      "--------------------------------Question 90--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : Given a joint data distribution $\\mathcal D$ on $\\mathcal X \times \\{-1,1\\}$ and $n$ independent and identically distributed observations from $\\mathcal D$, the goal of the classification task is to learn a classifier $f:\\mathcal X \to \\{-1,1\\}$ with minimum true risk $\\mathcal L(f) = \\mathbb E_{(X,Y)\\sim \\mathcal D} oldsymbol{\\mathbb{1}}_{f(X)\n",
      "eq Y}]$ where oldsymbol{\\mathbb{1}}_{C} =egin{cases}\n",
      "            1 \\; \text{ if } C  \text{ is true} \\\n",
      "            0 \\quad \text{otherwise} \n",
      "            \\end{cases}$. %\n",
      "            We denote by $\\mathcal D_{X}$ the marginal law (probability distribution) of $X$, and $\\mathcal D_{Y|X}$ the conditional law of $Y$ given $X$.\n",
      "            Give the two reasons seen in the course which explain that minimizing the true risk with the $0-1$ loss over the set of classifiers $f:\\mathcal X \to \\{-1,1\\}$ is problematic.\n",
      "[SOLUTION] : \n",
      "The two reasons seen in the course which explain that minimizing the true risk with the 0-1 loss over the set of classifiers $f:\\mathcal X \\to \\{-1,1\\}$ is problematic are:\n",
      "\n",
      "1. The 0-1 loss function is discontinuous: The 0-1 loss function assigns a penalty of 1 for misclassifications and 0 for correct classifications. This makes the optimization problem non-convex and discontinuous, leading to computational challenges in finding the optimal classifier.\n",
      "\n",
      "2. The true risk is not differentiable: The true risk $\\mathcal L(f)$ with the 0-1 loss function is not differentiable, making it difficult to apply traditional optimization algorithms that rely on gradients for convergence. This lack of differentiability can lead to optimization difficulties and suboptimal solutions when trying to minimize the true risk.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Given a joint data distribution $\\mathcal D$ on $\\mathcal X \times \\{-1,1\\}$ and $n$ independent and identically distributed observations from $\\mathcal D$, the goal of the classification task is to learn a classifier $f:\\mathcal X \to \\{-1,1\\}$ with minimum true risk $\\mathcal L(f) = \\mathbb E_{(X,Y)\\sim \\mathcal D} oldsymbol{\\mathbb{1}}_{f(X)\n",
      "eq Y}]$ where oldsymbol{\\mathbb{1}}_{C} =egin{cases}\n",
      "            1 \\; \text{ if } C  \text{ is true} \\\n",
      "            0 \\quad \text{otherwise} \n",
      "            \\end{cases}$. %\n",
      "            We denote by $\\mathcal D_{X}$ the marginal law (probability distribution) of $X$, and $\\mathcal D_{Y|X}$ the conditional law of $Y$ given $X$.\n",
      "            Give the two reasons seen in the course which explain that minimizing the true risk with the $0-1$ loss over the set of classifiers $f:\\mathcal X \to \\{-1,1\\}$ is problematic.\n",
      "The two main reasons why minimizing the true risk with the $0-1$ loss over the set of classifiers $f:\\mathcal X \\rightarrow \\{-1,1\\}$ is problematic are:\n",
      "\n",
      "1. **Non-Convex Optimization**: The $0-1$ loss function is non-convex and discontinuous, making it difficult to optimize directly. This leads to optimization problems that are hard to solve efficiently, and in many cases, the optimization algorithms get stuck in local minima. This makes it challenging to find the global minimum of the true risk when using the $0-1$ loss.\n",
      "\n",
      "2. **Non-Differentiability**: The $0-1$ loss function is non-differentiable almost everywhere, which poses challenges for gradient-based optimization methods commonly used in machine learning. This non-differentiability makes it hard to apply gradient descent algorithms to find the optimal classifier directly. This can lead to optimization issues, slow convergence, and difficulties in finding a good solution for the classification problem.\n",
      "\n",
      "Due to these reasons, it is often more practical to use surrogate loss functions that are differentiable and convex, such as the logistic loss or hinge loss, instead of the $0-1$ loss when training classifiers in practice. These surrogate loss functions provide smoother optimization landscapes and enable more efficient optimization algorithms to be applied, leading to better performance in practice.\n",
      "--------------------------------Question 91--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : Can we devise a broadcast algorithm that does not ensure the causal delivery property but only (in) its non-uniform variant:\n",
      "No correct process pi delivers a message m2 unless pi has already delivered every message m1 such that m1 → m2?\n",
      "[SOLUTION] : \n",
      "Yes, it is possible to devise a broadcast algorithm that only ensures non-uniform causal delivery. One way to achieve this is by implementing a total ordering on messages based on their causal dependencies. Each process would deliver messages in the order determined by this total ordering, ensuring that a process only delivers a message m2 after delivering all messages m1 such that m1 → m2. This way, the non-uniform causal delivery property is maintained without enforcing strict causal delivery.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Can we devise a broadcast algorithm that does not ensure the causal delivery property but only (in) its non-uniform variant:\n",
      "No correct process pi delivers a message m2 unless pi has already delivered every message m1 such that m1 → m2?\n",
      "Yes, we can devise a broadcast algorithm that does not ensure the causal delivery property but only its non-uniform variant. One such algorithm is the basic flooding algorithm.\n",
      "\n",
      "In a basic flooding algorithm, when a process receives a message, it forwards that message to all other processes it knows about. This ensures that all processes eventually receive the message, but it does not guarantee causal delivery. In this algorithm, a process may deliver a message without having previously delivered all messages that causally precede it.\n",
      "\n",
      "To implement the non-uniform variant of the causal delivery property, we can modify the basic flooding algorithm by adding a mechanism to track the causal relationships between messages. When a process receives a message, it also receives the causal history of that message (i.e., the list of messages that causally precede it). Before delivering a message, a process can check if it has already delivered all messages in the causal history of the received message. If not, the process can wait until it has delivered those messages before delivering the new message.\n",
      "\n",
      "This modification ensures that no correct process delivers a message unless it has already delivered every message that causally precedes it. However, it does not guarantee that messages are delivered in the order they were sent, as in the strict causal delivery property.\n",
      "--------------------------------Question 92--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Tick the \\textbf{false} statement : \n",
      "[ ] As a defender of a machine learning model you should be more worried about black-box effective attacks than white-box effective attacks.\n",
      "[ ] Privacy problems in machine learning stem solely from the need for data to train models.\n",
      "[ ] Poisoning attacks can be used to increase vulnerability to adversarial examples.\n",
      "[SOLUTION] : The false statement is : Privacy problems in machine learning stem solely from the need for data to train models. Data collection for training is one of many privacy attack vectors in machine learning. There exist attacks on models and outputs; and naturally exposing data for test is a risk in itself. The first statement is true, an adversary performing a black-box attack needs much less resources and capabilities than a white-box adversary. This is much more dangerous, as the adversary only needs the ability to interact with the model. The last statement is also true because by providing poisoning inputs, the adversary gets to shape the boundaries of the model. Thus, she can carve this boundary to facilitate classification errors. In fact, you can understand a backdoor attack as a particular instance of an adversarial example.\n",
      "[QUESTION] : We are using Gradient Descent to find the 1-dimensional global minimum $w^$ by optimizing the loss function L(w) at iteration t. L(w) is strictly convex, so it has a unique minimum. If $w^t > w^$, what is true about the gradient of the loss function, ∇L(wt), and the next iteration of the parameter $w_{t+1}$?\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}<w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}>w^t$\n",
      "[ ] $\n",
      "abla\\mathcal{L}(w^t)<0\\mathrm{and}w^{t+1}>w^t$\n",
      "[SOLUTION] : $\n",
      "abla\\mathcal{L}(w^t)>0\\mathrm{and}w^{t+1}<w^t$. Take, for example, the MSE loss function. $w^t > w^*$, it means that the current parameter is greater than the optimum and at this point the gradient is positive. In a Gradient Descent optimization step $w^{t+1}=w^t-\\gamma\n",
      "abla\\mathcal{L}(w^t)$, the parameter moves closer to the optimum and therefore decreases.\n",
      "[QUESTION] : Given matrix $A\\in\\mathbb{R}^{d\times d}$ with eigenvectors $(1,2,1)^\top$ and $(1,1,0)^\top$, both with eigenvalue 4, and trace(A) = 2. What is the determinant of A?\n",
      "[ ] det(A) = -16\n",
      "[ ] det(A) = 128\n",
      "[ ] det(A) = 16\n",
      "[ ] The determinant of a matrix cannot be determined, since the dimension of A is unknown. \n",
      "[ ] det(A) = -128\n",
      "[ ] det(A) = -96\n",
      "[SOLUTION] : Since the eigenvectors of A is in $R^3$, the total number of eigenvalues is 3. Using trace(A) = $\\lambda_1 + \\lambda_2 + \\lambda_3$, we can determine the eigenvalues are (4, 4, -6). Thus, det(A) = 4 x 4 x (-6) = -96.\n",
      "[QUESTION] : Tick the \\textbf{false} assertion. In Linear Cryptanalysis, the corresponding mask circuit of \\ldots\n",
      "[ ] \\ldots a XOR gate ($X\\oplus Y = Z$) is $a\\cdot Z=(a\\cdot X)\\oplus (a\\cdot Y)$\n",
      "[ ] \\ldots a XOR to constant gate ($Y=X\\oplus K$) is $a\\cdot Y = (a\\cdot X)\\oplus (a\\cdot K)$\n",
      "[ ] \\ldots a linear circuit ($Y=M\\times X$) is $a\\cdot Y = (M\\times a)\\cdot X$\n",
      "[ ] \\ldots a duplicate gate ($X=Y=Z$) is $(a\\oplus b)\\cdot X=(a\\cdot Y)\\oplus (b\\cdot Z)$\n",
      "[SOLUTION] : \n",
      "The false assertion is: \"... a duplicate gate ($X=Y=Z$) is $(a\\oplus b)\\cdot X=(a\\cdot Y)\\oplus (b\\cdot Z)$\". The correct corresponding mask circuit for a duplicate gate should be $(a\\oplus b)\\cdot X=(a\\cdot X)\\oplus (b\\cdot X)$.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Tick the \\textbf{false} assertion. In Linear Cryptanalysis, the corresponding mask circuit of \\ldots\n",
      "[ ] \\ldots a XOR gate ($X\\oplus Y = Z$) is $a\\cdot Z=(a\\cdot X)\\oplus (a\\cdot Y)$\n",
      "[ ] \\ldots a XOR to constant gate ($Y=X\\oplus K$) is $a\\cdot Y = (a\\cdot X)\\oplus (a\\cdot K)$\n",
      "[ ] \\ldots a linear circuit ($Y=M\\times X$) is $a\\cdot Y = (M\\times a)\\cdot X$\n",
      "[ ] \\ldots a duplicate gate ($X=Y=Z$) is $(a\\oplus b)\\cdot X=(a\\cdot Y)\\oplus (b\\cdot Z)$\n",
      "Let's analyze each assertion:\n",
      "\n",
      "1. The corresponding mask circuit of an XOR gate is $a\\cdot Z=(a\\cdot X)\\oplus (a\\cdot Y)$. This assertion is true because in Linear Cryptanalysis, XOR gates are represented using linear equations.\n",
      "2. The corresponding mask circuit of an XOR to constant gate is $a\\cdot Y = (a\\cdot X)\\oplus (a\\cdot K)$. This assertion is false. The correct expression for an XOR to constant gate is $a\\cdot Y = (a\\cdot X)\\oplus K$.\n",
      "3. The corresponding mask circuit of a linear circuit ($Y=M\\times X$) is $a\\cdot Y = (M\\times a)\\cdot X$. This assertion is true. In Linear Cryptanalysis, linear circuits are represented by linear equations.\n",
      "4. The corresponding mask circuit of a duplicate gate is $(a\\oplus b)\\cdot X=(a\\cdot Y)\\oplus (b\\cdot Z)$. This assertion is false. The correct expression for a duplicate gate is $X=Y=Z$, which means that the input is duplicated to multiple outputs.\n",
      "\n",
      "Therefore, the false assertion is:\n",
      "\n",
      "[ ] ... a XOR to constant gate ($Y=X\\oplus K$) is $a\\cdot Y = (a\\cdot X)\\oplus (a\\cdot K)$\n",
      "--------------------------------Question 93--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : A rigid and homogeneous horizontal rod of mass M, of length L, of negligible thickness e, i.e. e << L, is rotating in a horizontal plane around the vertical axis $C e_3$ at angular velocity $\\Omega=\\dot{\\psioldsymbol{e}3$. The moment of inertia of the rod with respect to the vertical principal axis that contains its centre of mass G is $I{G,3}=\frac1{12}ML^{2}$. Let C be the point of contact between the extremity of the rod and the rotation axis, and P the point at the other extremity. The unit vector $e_1$ is oriented along the rod and the vector $e_2$ is orthogonal to $e_1$. The unit vectors $e_1$, $e_2$ and $e_3$, attached to the rod at point C, are the principal axis frame of the rod. We consider that there is no friction and we do not take explicitly into account the influence of the gravitational field. Give the expression of the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis of rotation $C e_3$ in terms of the scalar quantities M and L.\n",
      "[SOLUTION] : Applying the Huygens-Steiner theorem, we determine the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis $C e_3$ taking into account the fact that d = L/2 is the distance separating points G and C and that $I_{G,3}=\frac1{12}ML^{2}$,\n",
      "ight)^2=\frac{1}{12}ML^2+\frac{1}{4}ML^2=\frac{1}{3}ML^2$\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : What is the communication complexity of the FloodSet algorithm in number of bits?\n",
      "[SOLUTION] : \n",
      "The communication complexity of the FloodSet algorithm in terms of bits can be calculated as follows:\n",
      "\n",
      "In the FloodSet algorithm, each node communicates its current set of neighbors to its neighbors in each round of communication. Since each node can have at most n-1 neighbors in a network with n nodes (excluding itself), the maximum number of bits needed to represent the set of neighbors of a node is log2(n-1) bits.\n",
      "\n",
      "Therefore, in each round of communication, each node needs to communicate log2(n-1) bits to each of its neighbors. Since there are n nodes in the network, the total communication complexity of the FloodSet algorithm in terms of bits is n * log2(n-1) bits.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "What is the communication complexity of the FloodSet algorithm in number of bits?\n",
      "The FloodSet algorithm is a distributed algorithm used for set agreement in a network of processes. In the worst case scenario, where all processes need to communicate their set to all other processes in the network, the communication complexity of FloodSet can be quite high.\n",
      "\n",
      "Let's break down the communication complexity of FloodSet in terms of the number of bits exchanged between processes:\n",
      "\n",
      "1. Initialization phase: Each process needs to broadcast its initial set to all other processes in the network. This requires each process to send the size of its set (log2(N) bits, where N is the number of processes) and the elements in the set. If we assume each element in the set is represented using log2(M) bits (where M is the maximum number of elements in the set), then the total number of bits exchanged in the initialization phase is approximately N * (log2(N) + M * log2(M)).\n",
      "\n",
      "2. Flooding phase: In each round of the flooding phase, each process broadcasts its set to all other processes that have not received it yet. This requires each process to send the size of its set and the elements in the set. The number of bits exchanged in each round is approximately N * (log2(N) + M * log2(M)).\n",
      "\n",
      "3. Termination phase: Once all processes have received the sets of all other processes, the algorithm terminates. This phase may involve some additional communication to ensure that all processes have reached a consensus.\n",
      "\n",
      "Overall, the total communication complexity of the FloodSet algorithm can be quite high, especially in the worst case scenario where all processes need to exchange their sets with all other processes. The exact number of bits exchanged will depend on the number of processes, the size of the sets, and the specific implementation of the algorithm.\n",
      "--------------------------------Question 94--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Tick the false assertion. Bluetooth ... \n",
      "[ ] uses a stream cipher for encryption.\n",
      "[ ] has secure integrity protection for secure communication.\n",
      "[ ] has devices which use the same secret key with any other device.uses the SAFER+ block cipher in a one-way mode.\n",
      "[SOLUTION] : The false assertion is : has secure integrity protection for secure communication. Bluetooth is indeed a secure protocol which relies on the E0 stream cipher for privacy. In Bluetooth, the encryption process involves the Long Term Key (LTK), which is a secret key shared and stored by both connected devices. Bluetooth implements confidentiality, authentication and key derivation with custom algorithms based on a SAFER+ block cipher\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Tick the \\textbf{false} statement : \n",
      "[ ] As a defender of a machine learning model you should be more worried about black-box effective attacks than white-box effective attacks.\n",
      "[ ] Privacy problems in machine learning stem solely from the need for data to train models.\n",
      "[ ] Poisoning attacks can be used to increase vulnerability to adversarial examples.\n",
      "[SOLUTION] : The false statement is : Privacy problems in machine learning stem solely from the need for data to train models. Data collection for training is one of many privacy attack vectors in machine learning. There exist attacks on models and outputs; and naturally exposing data for test is a risk in itself. The first statement is true, an adversary performing a black-box attack needs much less resources and capabilities than a white-box adversary. This is much more dangerous, as the adversary only needs the ability to interact with the model. The last statement is also true because by providing poisoning inputs, the adversary gets to shape the boundaries of the model. Thus, she can carve this boundary to facilitate classification errors. In fact, you can understand a backdoor attack as a particular instance of an adversarial example.\n",
      "[QUESTION] : In order to achieve a collision resistance equivalent to a $128$ bit key search, the size of the digest must be at least $\\ldots$\n",
      "[ ] $128$ bits.\n",
      "[ ] $2^{256}$ bits.\n",
      "[ ] $256$ bits.\n",
      "[ ] $2^{128}$ bits.\n",
      "[SOLUTION] : \n",
      "In order to achieve a collision resistance equivalent to a $128$ bit key search, the size of the digest must be at least $256$ bits.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "In order to achieve a collision resistance equivalent to a $128$ bit key search, the size of the digest must be at least $\\ldots$\n",
      "[ ] $128$ bits.\n",
      "[ ] $2^{256}$ bits.\n",
      "[ ] $256$ bits.\n",
      "[ ] $2^{128}$ bits.\n",
      "To achieve a collision resistance equivalent to a $128$ bit key search, we need a digest size of at least $2^{128}$ bits. This is because the digest size should ideally be double the desired security level to ensure a high level of collision resistance. Therefore, the correct option is:\n",
      "\n",
      "[ ] $2^{128}$ bits.\n",
      "--------------------------------Question 95--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : Make some rough estimations (in terms of powers of $10$) according to your ``feeling'' (test for a job interview as ``management consultant''...):\n",
      "\n",
      "How many pencils would you need to draw a straight line along the Earth's equator ?\n",
      "\n",
      "[SOLUTION] : \n",
      "The Earth's equator is approximately $40,075$ kilometers long. Let's assume a typical pencil can draw a line of about $1$ meter. \n",
      "\n",
      "So, to draw the Earth's equator with pencils, we would need approximately $40,075,000$ pencils.\n",
      "\n",
      "This can be estimated as $10^7$ pencils. \n",
      "\n",
      "Of course, this is a rough estimation and the actual number may vary.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Make some rough estimations (in terms of powers of $10$) according to your ``feeling'' (test for a job interview as ``management consultant''...):\n",
      "\n",
      "How many pencils would you need to draw a straight line along the Earth's equator ?\n",
      "\n",
      "Let's break down the problem step by step:\n",
      "\n",
      "1. The Earth's equator is approximately $40,075$ kilometers long.\n",
      "2. Let's estimate the length of a pencil to be about $0.1$ meters (or $10$ centimeters).\n",
      "3. To draw a straight line along the Earth's equator, you would need to continuously draw a line with the pencil.\n",
      "4. Assuming there is no breakage or sharpening needed, you would need to align the pencils end to end along the equator.\n",
      "5. The number of pencils needed can be estimated by dividing the length of the equator by the length of one pencil.\n",
      "\n",
      "So, the rough estimation would be:\n",
      "\n",
      "$\\frac{40,075,000 \\text{ meters}}{0.1 \\text{ meters}} = 400,750,000$ pencils\n",
      "\n",
      "Therefore, you would need approximately $10^8$ (or $100$ million) pencils to draw a straight line along the Earth's equator.\n",
      "--------------------------------Question 96--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : Tick the false assertion. Bluetooth ... \n",
      "[ ] uses a stream cipher for encryption.\n",
      "[ ] has secure integrity protection for secure communication.\n",
      "[ ] has devices which use the same secret key with any other device.uses the SAFER+ block cipher in a one-way mode.\n",
      "[SOLUTION] : The false assertion is : has secure integrity protection for secure communication. Bluetooth is indeed a secure protocol which relies on the E0 stream cipher for privacy. In Bluetooth, the encryption process involves the Long Term Key (LTK), which is a secret key shared and stored by both connected devices. Bluetooth implements confidentiality, authentication and key derivation with custom algorithms based on a SAFER+ block cipher\n",
      "[QUESTION] : Considering a sequence of n tokens, the computational complexity of the masked attention mechanism in BERT language models is: (select the smallest correct complexity)\n",
      "[ ] O(n^3)\n",
      "[ ] O(nlog(n))\n",
      "[ ] O(n)\n",
      "[ ] O(n^(1/2))\n",
      "[ ] O(n^2)\n",
      "[SOLUTION] : Masked attention is quadratic in the sequence length n because it computes the attention between all pairs of tokens, therefore O(n^2).\n",
      "[QUESTION] : Which of the following statements is true about the logistic regression model?\n",
      "[ ] Logistic regression gives a max-margin classifier\n",
      "[ ] By minimizing negative log-likelihood, we can obtain a closed-form solution for logistic regression\n",
      "[ ] In logistic regression, we calculate the weights $\\hatoldsymbol{\theta}}=(\\mathbf{X}^\top\\mathbf{X})^{-1}\\mathbf{X}^\top\\mathbf{y},\text{ and then fit responses as }\\hat{\\mathbf{y}}=\\sigma(\\mathbf{X}\\hatoldsymbol{\theta}})$\n",
      "[ ] If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge\n",
      "[SOLUTION] : If we run Gradient Descent to solve a logistic regression task on linearly separable data, the weights will not converge. There is no closed-form solution when minimizing negative log-likelihood for logistic regression. We cannot solve for $\\hat\theta$ analytically in logistic regression like in linear regression. Optimization techniques like GD or Newton methods are required. Logistic regression finds any solution that separates two classes. To solve logistic regression, we maximize log likelihood, i.e. $\\max_oldsymbol{\theta}}\\log\\prod_{oldsymbol{=}1}^N\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})^{y_n}[oldsymbol{-}\\sigma(\\mathbf{x}_n^\tooldsymbol{\theta})]^{oldsymbol{-}y_n}$. For linearly separable case, by increasing $\\|\theta\\|$, one could always increase the likelihood. The weights can thus go to infinity.\n",
      "[QUESTION] : Tick the \\emph{false} answer. In a group, the operation\\dots\n",
      "[ ] is commutative\n",
      "[ ] is associative.\n",
      "[ ] has a neutral element.\n",
      "[ ] associates an inverse to each value.\n",
      "[SOLUTION] : \n",
      "The false answer is: is commutative. In a group, the operation is not necessarily commutative, meaning the order in which the operation is performed matters.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Tick the \\emph{false} answer. In a group, the operation\\dots\n",
      "[ ] is commutative\n",
      "[ ] is associative.\n",
      "[ ] has a neutral element.\n",
      "[ ] associates an inverse to each value.\n",
      "The false answer is: [ ] is commutative\n",
      "--------------------------------Question 97--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : A rigid and homogeneous horizontal rod of mass M, of length L, of negligible thickness e, i.e. e << L, is rotating in a horizontal plane around the vertical axis $C e_3$ at angular velocity $\\Omega=\\dot{\\psioldsymbol{e}3$. The moment of inertia of the rod with respect to the vertical principal axis that contains its centre of mass G is $I{G,3}=\frac1{12}ML^{2}$. Let C be the point of contact between the extremity of the rod and the rotation axis, and P the point at the other extremity. The unit vector $e_1$ is oriented along the rod and the vector $e_2$ is orthogonal to $e_1$. The unit vectors $e_1$, $e_2$ and $e_3$, attached to the rod at point C, are the principal axis frame of the rod. We consider that there is no friction and we do not take explicitly into account the influence of the gravitational field. Give the expression of the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis of rotation $C e_3$ in terms of the scalar quantities M and L.\n",
      "[SOLUTION] : Applying the Huygens-Steiner theorem, we determine the moment of inertia $I_{C,3}$ of the rod with respect to the vertical axis $C e_3$ taking into account the fact that d = L/2 is the distance separating points G and C and that $I_{G,3}=\frac1{12}ML^{2}$,\n",
      "ight)^2=\frac{1}{12}ML^2+\frac{1}{4}ML^2=\frac{1}{3}ML^2$\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : A particle of mass $m_1$, of initial speed $\\boldsymbol{v}_1 = v_1\\,\\boldsymbol{e}_x$ collides with a particle of mass $m_2$, initially at rest, i.e. $\\boldsymbol{v}_2 = \\boldsymbol{0}$. We consider here the case of an elastic collision between the two particles. We denote $\\boldsymbol{v}'_1 = v'_1\\left(\\cos\\theta_1\\,\\boldsymbol{e}_x + \\sin\\theta_1\\,\\boldsymbol{e}_y\\right)$ and $\\boldsymbol{v}'_2 = v'_2\\left(\\cos\\theta_2\\,\\boldsymbol{e}_x -\\,\\sin\\theta_2\\,\\boldsymbol{e}_y\\right)$ the speeds after the collision.\n",
      "\n",
      "Using the conservation laws, write the equations relating the physical variables $v_1$, $m_1$, $m_2$ with the physical variables $v'_1$, $v'_2$, $\\theta_1$, $\\theta_2$.\n",
      "\n",
      "[SOLUTION] : \n",
      "In an elastic collision, both momentum and kinetic energy are conserved. \n",
      "\n",
      "1. Conservation of momentum:\n",
      "Before the collision:\n",
      "$$m_1 v_1 = m_1 v'_1 \\cos \\theta_1 + m_2 v'_2 \\cos \\theta_2$$\n",
      "2. Conservation of kinetic energy:\n",
      "Before the collision:\n",
      "$$\\frac{1}{2} m_1 v_1^2 = \\frac{1}{2} m_1 v'_1^2 + \\frac{1}{2} m_2 v'_2^2$$\n",
      "\n",
      "These two equations can be used to relate the physical variables $v_1$, $m_1$, $m_2$ with the physical variables $v'_1$, $v'_2$, $\\theta_1$, $\\theta_2$ after the collision.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "A particle of mass $m_1$, of initial speed $\\boldsymbol{v}_1 = v_1\\,\\boldsymbol{e}_x$ collides with a particle of mass $m_2$, initially at rest, i.e. $\\boldsymbol{v}_2 = \\boldsymbol{0}$. We consider here the case of an elastic collision between the two particles. We denote $\\boldsymbol{v}'_1 = v'_1\\left(\\cos\\theta_1\\,\\boldsymbol{e}_x + \\sin\\theta_1\\,\\boldsymbol{e}_y\\right)$ and $\\boldsymbol{v}'_2 = v'_2\\left(\\cos\\theta_2\\,\\boldsymbol{e}_x -\\,\\sin\\theta_2\\,\\boldsymbol{e}_y\\right)$ the speeds after the collision.\n",
      "\n",
      "Using the conservation laws, write the equations relating the physical variables $v_1$, $m_1$, $m_2$ with the physical variables $v'_1$, $v'_2$, $\\theta_1$, $\\theta_2$.\n",
      "\n",
      "To solve this problem, we will use the conservation of momentum and the conservation of kinetic energy.\n",
      "\n",
      "1. Conservation of momentum in the $x$ direction:\n",
      "\\[ m_1v_1 = m_1v'_1\\cos\\theta_1 + m_2v'_2\\cos\\theta_2 \\]\n",
      "\n",
      "2. Conservation of momentum in the $y$ direction:\n",
      "\\[ 0 = m_1v'_1\\sin\\theta_1 - m_2v'_2\\sin\\theta_2 \\]\n",
      "\n",
      "3. Conservation of kinetic energy:\n",
      "\\[ \\frac{1}{2}m_1v_1^2 = \\frac{1}{2}m_1v'_1^2 + \\frac{1}{2}m_2v'_2^2 \\]\n",
      "\n",
      "These three equations relate the physical variables $v_1$, $m_1$, $m_2$ with the physical variables $v'_1$, $v'_2$, $\\theta_1$, $\\theta_2$.\n",
      "--------------------------------Question 98--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : A material point P of mass m subjected to the gravitational field g = - g $\\hat{x_3}$ is constrained to move on the inside surface of a cone. The vertex of the cone is located at the origin O of the Cartesian frame $(Ooldsymbol{\\hat{x}}1oldsymbol{\\hat{x}}2oldsymbol{\\hat{x}}_3)$. The axis of symmetry of the cone is the vertical line containing point O and its opening angle is $\theta$ = const. The spherical frame $(P, e_r, e{\theta}, e{\\phi},)$ attached to the material point P is such that the basis vectors $e_r$ and $e_\theta$ are always contained in a vertical plane and the basis vector $e_\\phi$ is horizontal. We assume that there is no friction force. Determine the three scalar equations of motion along the lines of coordinates tangent to the unit vectors oldsymbol{e}roldsymbol{e}\theta\\mathrm{andoldsymbol{e}_\\phi$ in terms of the scalar quantities m, g, N (norm of the normal reaction force), $r,\\dot{r},\\ddot{r}\theta,\\dot{\\phi},\\ddot{\\phi}$ taking explicitly into account the geometric constraints.\n",
      "[SOLUTION] : The external forces are the weight P and the normal reaction force N. These forces are expressed in spherical coordinates as: oldsymbol{P}=oldsymbol{g}=mg(-\\cos\thetoldsymbol{e}r+\\sin\thetoldsymbol{e}\theta)$ and $N=-oldsymbol{e}\theta$. \n",
      "Taking into account the geometric constraints, i.e. $\theta=\\mathrm{const}$, thus $\\dot{\theta}=0$ and $\\ddot{\theta}=0$, \n",
      "the acceleration is expressed in spherical coordinates as: \n",
      "ightoldsymbol{e}\\phi $\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\theta\n",
      "The vectorial law of motion: $\\suoldsymbol{F}^\\mathrm{ext}oldsymbol{P}oldsymbol{N}=oldsymbol{a}$\n",
      "projected along the unit vectors tangent to the three lines of coordinates yields the three scalar equations :\n",
      "ight)\\end{aligned}$uaoldsymbol{e}\\phi:\\quad0=m\\left(r\\ddot{\\phi}\\sin\theta+2\\dot{r}\\dot{\\phi}\\sin\thetaa\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : Let us consider a hydrogen atom of mass $m = 1.67\\cdot10^{-27}\\,\\text{kg}$ chemically bound to a metallic surface. We model the chemical bound by a spring of constant $k$, of natural length $l_0$ and of vibration frequency $f=10^{13}\\,\\text{s}^{-1}$. \n",
      "Determine the value of the spring constant $k$ of the chemical bound, neglecting the action of the gravitational force.\n",
      "\n",
      "[SOLUTION] : \n",
      "The natural frequency of vibration of a spring-mass system is given by the formula $f = \\frac{1}{2\\pi}\\sqrt{\\frac{k}{m}}$, where $k$ is the spring constant and $m$ is the mass.\n",
      "\n",
      "Given that $f = 10^{13}\\,\\text{s}^{-1}$ and $m = 1.67\\cdot10^{-27}\\,\\text{kg}$, we can rearrange the formula to solve for $k$:\n",
      "\n",
      "$10^{13} = \\frac{1}{2\\pi}\\sqrt{\\frac{k}{1.67\\cdot10^{-27}}}$\n",
      "\n",
      "Squaring both sides and rearranging, we get:\n",
      "\n",
      "$k = (2\\pi)^2 \\times (1.67\\cdot10^{-27}) \\times (10^{13})^2$\n",
      "\n",
      "Calculating the value, we find:\n",
      "\n",
      "$k \\approx 1.05 \\times 10^{-13}\\,\\text{N/m}$\n",
      "\n",
      "Therefore, the value of the spring constant $k$ for the chemical bond is approximately $1.05 \\times 10^{-13}\\,\\text{N/m}$.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "Let us consider a hydrogen atom of mass $m = 1.67\\cdot10^{-27}\\,\\text{kg}$ chemically bound to a metallic surface. We model the chemical bound by a spring of constant $k$, of natural length $l_0$ and of vibration frequency $f=10^{13}\\,\\text{s}^{-1}$. \n",
      "Determine the value of the spring constant $k$ of the chemical bound, neglecting the action of the gravitational force.\n",
      "\n",
      "To determine the value of the spring constant $k$ of the chemical bond, we can use the relationship between the natural frequency of vibration $f$, the mass of the object $m$, and the spring constant $k$.\n",
      "\n",
      "The natural frequency of vibration $f$ of a harmonic oscillator (such as a spring-mass system) is given by:\n",
      "\n",
      "$$ f = \\frac{1}{2\\pi} \\sqrt{\\frac{k}{m}} $$\n",
      "\n",
      "Given that $f = 10^{13}\\,\\text{s}^{-1}$ and $m = 1.67\\cdot10^{-27}\\,\\text{kg}$, we can rearrange the equation to solve for the spring constant $k$:\n",
      "\n",
      "$$ k = (2\\pi f)^2 \\cdot m $$\n",
      "\n",
      "Plugging in the values, we get:\n",
      "\n",
      "$$ k = (2\\pi \\cdot 10^{13}\\,\\text{s}^{-1})^2 \\cdot 1.67\\cdot10^{-27}\\,\\text{kg} $$\n",
      "\n",
      "Calculating this expression will give us the value of the spring constant $k$ for the chemical bound.\n",
      "--------------------------------Question 99--------------------------------\n",
      "-------------------------------------A-------------------------------------\n",
      "\n",
      "[QUESTION] : We consider a binary classification problem for which a predictor is being considered. A validation set which contains 20$%$ of positive examples is used to evaluate the classifier. On this set the recall is at 90$%$ and the false positive rate is of 5$%$. What is the misclassification error? Please detail your reasoning and calculation.\n",
      "[SOLUTION] : Let P, N, FP, FN, TP denote respectively the number of positives, of negatives, of false positives, false negatives and true positives. Let n = N + P be the total number of datapoints in the validation set. By definition, the rate of false positives is rFP = FP/N and the rate of true positives, aka recall, is rTP = TP/P = 1 / FN/P. Let π = P/n. \n",
      " By definition, the misclassification error is: $Rb0-1 = (FP/n) + (FN/n) = (1 - π) * (FP/N) + π * (1 - rTP).$ \n",
      " With the numbers provided: $Rb0-1 = (1 - 0.2) * 0.05 + 0.2 * (1 - 0.9) = 0.8 * 0.05 + 0.2 * 0.1 = 0.06.$ \n",
      " The misclassification error is thus 6%.\n",
      "[QUESTION] : In you opinion, is an anti-virus software a good protection against social engineering attacks carried out over e-mail? Explain why. What would be the best way of protecting against these attacks?\n",
      "[SOLUTION] : An antivirus software might be able to detect some typical characteristics of a social engineering e-mail (e.g. a fake sender address, or some keywords like “please pay”, etc.). Social engineering attacks can have so many different forms that it does not seem possible to create a software that can detect all of them. The best protection is to raise the awareness of the users. This can be done through specific training of the users. This could include running a fake social engineering attack and informing them of the results.\n",
      "[QUESTION] : Why can't you use a message authentication code (e.g. HMAC-SHA2) to sign a contract between a buyer and a seller ?\n",
      "[SOLUTION] : The MAC is based on a symmetric key that both parties need to know. Any party could modify the contract, replace the MAC and pretend it is authentic.\n",
      "[QUESTION] : For students born in April, how many months older are they than the average student in their grade? 5.4898 months\n",
      "For students born in March, how many months younger are they than the average student in their grade? 5.5102 months\n",
      "\n",
      "Discuss: Considering your common sense and the results obtained from the simulation: what advantage do students born in April have over those born in March? How may this affect their odds of becoming professional athletes?\n",
      "[SOLUTION] : \n",
      "Students born in April have a slight advantage over those born in March in terms of age, as they are slightly older on average. This advantage may affect their odds of becoming professional athletes in sports where age and physical maturity play a significant role. Being slightly older may give them a physical advantage over their younger peers, especially in sports where strength and athleticism are important factors. However, it is important to note that factors such as talent, dedication, and training also play a significant role in becoming a professional athlete.\n",
      "-------------------------------------B-------------------------------------\n",
      "Let's think step by step !\n",
      "For students born in April, how many months older are they than the average student in their grade? 5.4898 months\n",
      "For students born in March, how many months younger are they than the average student in their grade? 5.5102 months\n",
      "\n",
      "Discuss: Considering your common sense and the results obtained from the simulation: what advantage do students born in April have over those born in March? How may this affect their odds of becoming professional athletes?\n",
      "Based on the information provided, students born in April are 5.4898 months older than the average student in their grade, while students born in March are 5.5102 months younger than the average student. This slight age difference of around 0.02 months may not seem significant, but it can have a cumulative effect in certain competitive fields, such as sports.\n",
      "\n",
      "In sports, especially at the professional level, age can play a crucial role in skill development, physical maturity, and overall performance. The advantage of being slightly older, even by a few months, could mean that students born in April may have had more time to develop their skills, physical abilities, and maturity compared to those born in March. This could potentially give them a slight edge in sports competitions and selection processes.\n",
      "\n",
      "In terms of becoming professional athletes, this age difference could impact the odds of success for students born in April compared to those born in March. The additional months of development and experience could give April-born students a competitive advantage in terms of physical conditioning, skill development, and overall performance, which may increase their chances of being noticed by scouts, coaches, and teams.\n",
      "\n",
      "While individual talent, hard work, and dedication are also crucial factors in becoming a professional athlete, the age advantage that April-born students have over March-born students could potentially influence their odds of success in the highly competitive world of sports.\n"
     ]
    }
   ],
   "source": [
    "generated_answers = gpt_generation(\n",
    "    questions=questions,\n",
    "    instructions=[\n",
    "        \"\", # Few shot learning\n",
    "        \"Let's think step by step !\" # Zero shot\n",
    "    ],\n",
    "    examples_path = \"data\",\n",
    "    verbose=True,\n",
    "    #subset_questions_indices=known_answers,\n",
    "    nb_few_shot_examples=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'course_id': 15002, 'question_id': 1016, 'question': 'What is a good distance metric to be used when you want to compute the similarity between documents independent of their length?A penalty will be applied for any incorrect answers.', 'question_options': ['Cosine similarity', 'Euclidean distance', 'Manhattan distance', 'Chi-squared distance'], 'A_chat_id': 92662, 'B_chat_id': 92663, 'A': 'Cosine similarity is the correct distance metric to use when you want to compute the similarity between documents independent of their length. This metric measures the cosine of the angle between two vectors, making it insensitive to the magnitude of the vectors and therefore independent of the length of the documents.', 'B': 'The correct answer is:\\n[ ] Cosine similarity\\n\\nCosine similarity is a good distance metric to use when you want to compute the similarity between documents independent of their length. It measures the cosine of the angle between two vectors, which makes it effective for comparing documents based on the orientation of their term vectors rather than their length.'}, {'course_id': 15118, 'question_id': 6900, 'question': 'Consider the motion of a harmonic oscillator. Identify when the  acceleration is naught.\\n\\n', 'question_options': None, 'A_chat_id': 92664, 'B_chat_id': 92665, 'A': 'The acceleration of a harmonic oscillator is zero at the extreme points of its motion, i.e. at the points where the velocity is maximum and the displacement is either maximum or minimum. This occurs when the oscillator reaches its equilibrium position or its maximum displacement in either direction.', 'B': 'In the motion of a harmonic oscillator, the acceleration is zero at the extreme points of the motion, where the velocity is maximum. This is because the acceleration is directly proportional to the displacement from the equilibrium position and acts in the opposite direction to the displacement.\\n\\nAt the extreme points of the motion (when the oscillator reaches the maximum displacement from the equilibrium position), the direction of the acceleration changes, and at that instant, the acceleration is zero. This occurs because the restoring force at the extreme points is zero, and hence there is no acceleration acting on the oscillator.'}, {'course_id': 0, 'question_id': 6147, 'question': 'Which one of these Ciphers is perfectly secure?', 'question_options': ['Hieroglyphs', 'Caesar', 'Vigen\\\\`{e}re', 'Vernam'], 'A_chat_id': 92666, 'B_chat_id': 92667, 'A': 'Vernam cipher is perfectly secure if used correctly with a truly random key that is at least as long as the message being encrypted. This is because the key stream used in Vernam cipher is XORed with the plaintext, making it impossible for cryptanalysis to determine the original message without the key.', 'B': 'The Vernam cipher is considered perfectly secure when implemented correctly. It is also known as the one-time pad, where the key used to encrypt the message is as long as the message itself and is completely random. This makes it theoretically unbreakable if the key is kept secret and only used once.'}, {'course_id': 9, 'question_id': 6850, 'question': 'A vending machine dispensing books of stamps accepts only $1 bills, $2 bills and $5 bills.\\n\\nFind a recurrence relation for the number of ways to deposit $$n$$ dollars in the vending machine, where the order in which the coins and bills are deposited matters.', 'question_options': ['$$a_{n} = a_{n-1} + a_{n-2} + a_{n-5}$$', '$$a_{n+1} = a_{n-1} + a_{n-2} + a_{n-5}$$', '$$a_{n+1} = a_{n-1} + 2a_{n-2} + 5a_{n-5}$$', '$$a_{n} = a_{n-1} + 2a_{n-2} + 5a_{n-5}$$'], 'A_chat_id': 92668, 'B_chat_id': 92669, 'A': '$$a_{n} = a_{n-1} + a_{n-2} + a_{n-5}$$', 'B': 'To find the recurrence relation for the number of ways to deposit $n$ dollars in the vending machine, we need to consider the possible last bill deposited. The last bill could be a $1 bill, a $2 bill, or a $5 bill.\\n\\nIf the last bill deposited is a $1 bill, then there are $a_{n-1}$ ways to deposit the remaining $n-1$ dollars.\\n\\nIf the last bill deposited is a $2 bill, then there are $a_{n-2}$ ways to deposit the remaining $n-2$ dollars.\\n\\nIf the last bill deposited is a $5 bill, then there are $a_{n-5}$ ways to deposit the remaining $n-5$ dollars.\\n\\nTherefore, the correct recurrence relation is:\\n$$a_{n} = a_{n-1} + a_{n-2} + a_{n-5}$$\\n\\nSo, the correct option is:\\n[ ] $$a_{n} = a_{n-1} + a_{n-2} + a_{n-5}$$'}, {'course_id': 15125, 'question_id': 3667, 'question': 'Which of the following graph analysis techniques do you believe would be most appropriate to identify communities on a social graph?', 'question_options': ['Cliques', 'Random Walks', 'Shortest Paths', 'Association rules'], 'A_chat_id': 92671, 'B_chat_id': 92672, 'A': 'The most appropriate graph analysis technique to identify communities on a social graph would be Cliques. Cliques are subsets of vertices in a graph where every vertex is connected to every other vertex in the subset. In the context of social networks, cliques can represent tightly-knit groups or communities of individuals who interact frequently with each other. By identifying cliques in a social graph, we can uncover these community structures within the network.', 'B': 'The most appropriate graph analysis technique to identify communities on a social graph is \"Cliques.\" \\n\\nCliques are groups of nodes within a graph that are densely connected to each other. In a social graph, cliques can represent communities or groups of individuals who are closely connected or have similar interests. By identifying cliques in a social graph, we can uncover these communities and understand the relationships between members within them. \\n\\nRandom walks, shortest paths, and association rules are also valuable techniques for analyzing graphs, but they may not specifically focus on identifying communities within a social graph.'}, {'course_id': 15125, 'question_id': 1431, 'question': 'Vectorize the input with the Vector Space Model', 'question_options': None, 'A_chat_id': 92673, 'B_chat_id': 92674, 'A': 'To vectorize the input with the Vector Space Model, we first need to represent the input text as a set of vectors. This can be done by converting the text into a document-term matrix, where each row represents a document (in this case, a sentence or a phrase) and each column represents a term (word).\\n\\nFor example, considering the input text \"Vectorize the input with the Vector Space Model\", we can represent it as a document-term matrix with the following terms: \"vectorize\", \"input\", \"with\", \"the\", \"space\", \"model\".\\n\\nThe document-term matrix for the input text would look like this:\\n\\n|            | vectorize | input | with | the | space | model |\\n|------------|-----------|-------|------|-----|-------|-------|\\n| Sentence 1 | 1         | 1     | 1    | 1   | 1     | 1     |\\n\\nEach row in the matrix represents a document (sentence) and each column represents a term (word), with the values in the cells indicating the frequency of each term in the corresponding document.\\n\\nThis document-term matrix can then be used as input for various text analysis and machine learning tasks, such as information retrieval, document clustering, and text classification, using techniques like cosine similarity or TF-IDF weighting.', 'B': 'To vectorize the input using the Vector Space Model, we need to follow these steps:\\n\\n1. Tokenization: Break the input text into individual words or tokens.\\n2. Create a vocabulary: Build a list of unique words from the input text.\\n3. Vectorization: Represent the input text as a numerical vector based on the frequency of each word in the vocabulary.\\n\\nLet\\'s illustrate this with an example:\\n\\nInput text: \"The quick brown fox jumps over the lazy dog\"\\n\\nStep 1: Tokenization\\nTokens: [\"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\"]\\n\\nStep 2: Create a vocabulary\\nVocabulary: [\"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"lazy\", \"dog\"]\\n\\nStep 3: Vectorization\\nVector representation:\\n- \"the\": 2 (appears twice in the input text)\\n- \"quick\": 1\\n- \"brown\": 1\\n- \"fox\": 1\\n- \"jumps\": 1\\n- \"over\": 1\\n- \"lazy\": 1\\n- \"dog\": 1\\n\\nThe vector representation of the input text using the Vector Space Model would be [2, 1, 1, 1, 1, 1, 1, 1] based on the frequency of each word in the vocabulary.'}, {'course_id': 15126, 'question_id': 2329, 'question': 'In which type of processors do you expect to find a reorder buffer?', 'question_options': None, 'A_chat_id': 92675, 'B_chat_id': 92676, 'A': 'A reorder buffer is typically found in out-of-order processors.', 'B': 'Reorder buffers are typically found in out-of-order processors. These processors can execute instructions in an order that is different from the order they appear in the program. The reorder buffer helps keep track of the original program order and ensures that instructions are completed and retired in the correct sequence.'}, {'course_id': 15127, 'question_id': 3332, 'question': 'Consider the following matrix-factorization problem. For the observed ratings $r_{u m}$ for a given pair $(u, m)$ of a user $u$ and a movie $m$, one typically tries to estimate the score by $$ f_{u m}=\\\\left\\\\langle\\\\mathbf{v}_{u}, \\\\mathbf{w}_{m}\\\\right\\\\rangle+b_{u}+b_{m} $$ Here $\\\\mathbf{v}_{u}$ and $\\\\mathbf{w}_{m}$ are vectors in $\\\\mathbb{R}^{D}$ and $b_{u}$ and $b_{m}$ are scalars, indicating the bias. How could you address the problem of potentially recommending a new movie without any ratings to users? [As in the previous point, this is also not a math question.]', 'question_options': None, 'A_chat_id': 92677, 'B_chat_id': 92678, 'A': 'One common approach to recommending a new movie to users without any ratings is to use collaborative filtering techniques. Collaborative filtering leverages the ratings of other users to make recommendations. \\n\\nOne way to do this is by using matrix factorization techniques, such as Singular Value Decomposition (SVD) or Alternating Least Squares (ALS), to learn latent factors representing users and movies from the existing ratings data. These learned latent factors can then be used to predict the potential rating a user might give to a new movie.\\n\\nAnother approach is to use content-based filtering, where information about the movie itself (such as genre, actors, director, etc.) is used to make recommendations. This can be combined with collaborative filtering to provide more personalized recommendations.\\n\\nAdditionally, techniques like hybrid recommendation systems that combine collaborative filtering, content-based filtering, and other methods can also be used to recommend new movies to users without any ratings.', 'B': \"One way to address the problem of recommending a new movie without any ratings from users is to use a combination of content-based filtering and collaborative filtering techniques.\\n\\n1. **Content-Based Filtering**: In content-based filtering, movies are recommended to users based on the attributes of the items they have liked in the past. You can recommend a new movie to a user by analyzing the features of the movie (e.g., genre, actors, director, plot keywords) and comparing them with the user's historical preferences. If the movie shares similar characteristics with movies the user has liked before, it may be a good recommendation.\\n\\n2. **Collaborative Filtering**: Collaborative filtering techniques recommend items to users based on the preferences of other users. In the absence of ratings for a new movie, you can leverage collaborative filtering to recommend the new movie to users who have similar preferences to the target user. By analyzing the historical ratings of other users who have rated the new movie, you can identify users with similar taste and recommend the movie to the target user based on their preferences.\\n\\n3. **Hybrid Approaches**: Another approach is to use hybrid recommendation systems that combine content-based and collaborative filtering techniques. By leveraging both content-based features and collaborative filtering algorithms, you can provide more accurate and diverse recommendations to users, even for new items with little to no ratings.\\n\\nBy combining these techniques, you can effectively address the challenge of recommending new movies to users without any ratings, providing personalized and relevant recommendations based on user preferences and item characteristics.\"}, {'course_id': 15103, 'question_id': 1716, 'question': 'Assume your colleague wants to wait until the next minor release to include a major bugfix instead of making a bugfix release. Explain why this is not a good idea.', 'question_options': None, 'A_chat_id': 92679, 'B_chat_id': 92680, 'A': 'Waiting until the next minor release to include a major bugfix is not a good idea because it leaves the bug unfixed and potentially affecting users until the next release, which could be weeks or even months away. This can lead to user frustration, negative reviews, and potential loss of users or customers. Additionally, the longer the bug remains unfixed, the more time-consuming and costly it may become to address it in the future. It is generally best practice to address major bugs as soon as possible through a bugfix release to minimize the impact on users and maintain the overall quality and stability of the software.', 'B': 'Waiting until the next minor release to include a major bugfix instead of making a bugfix release is not a good idea for several reasons:\\n\\n1. Impact on users: By delaying the bugfix until the next minor release, users will have to wait longer for a resolution to the issue. This can result in frustration and dissatisfaction among users who are affected by the bug.\\n\\n2. Severity of the bug: If the bug is considered a major issue that significantly impacts the functionality or security of the software, it should be addressed as soon as possible. Delaying the bugfix can leave the software vulnerable to exploitation or cause further issues down the line.\\n\\n3. Maintenance burden: Allowing major bugs to linger in the software can create additional maintenance burden for the development team. It may lead to more complex bugfixes and testing requirements in the future, increasing the overall workload and potential for introducing new issues.\\n\\n4. Reputation and trust: Failing to address major bugs promptly can damage the reputation of the software and the trust users have in the development team. Users rely on software to work reliably and securely, and delays in addressing critical issues can erode confidence in the product.\\n\\nIn conclusion, it is generally recommended to address major bugs promptly through bugfix releases to minimize the impact on users, maintain the integrity of the software, and uphold the trust of the user base.'}, {'course_id': 15127, 'question_id': 3896, 'question': 'Which of the following is true for Generative Adversarial Networks (GANs) but not Diffusion Models:\\n        ', 'question_options': ['They can generate new data from input noise.', 'They use two different models during training.', 'They use a simple L2 loss function.', 'They gradually remove noise from inputs using a Markov chain.'], 'A_chat_id': 92681, 'B_chat_id': 92682, 'A': '[ ] They can generate new data from input noise. \\n\\nGenerative Adversarial Networks (GANs) can generate new data from input noise, while Diffusion Models do not generate data from noise but instead model the data distribution directly.', 'B': 'The statement that is true for Generative Adversarial Networks (GANs) but not Diffusion Models is:\\n\\n[X] They use two different models during training.\\n\\nExplanation:\\n- GANs consist of two neural networks, a generator and a discriminator, that are trained against each other.\\n- Diffusion Models do not involve two separate models like GANs.'}, {'course_id': 0, 'question_id': 6154, 'question': 'Which of the following is well preserved by 2G?', 'question_options': ['Confidentiality', 'Message Integrity', 'Challenge freshness', 'Authentication of Mobile Station'], 'A_chat_id': 92683, 'B_chat_id': 92684, 'A': '[ ] Challenge freshness\\n\\nChallenge freshness is not well preserved by 2G networks. 2G networks are known to have vulnerabilities in terms of confidentiality, message integrity, and authentication of the mobile station.', 'B': 'The correct answer is:\\n\\n[ ] Confidentiality\\n\\n2G networks primarily focus on providing confidentiality through encryption techniques to protect the communication between the mobile station and the base station. Other security features like message integrity, challenge freshness, and authentication are also important but may not be as well preserved in 2G networks compared to newer generations like 3G or 4G.'}, {'course_id': 4, 'question_id': 6593, 'question': 'Which of the following statements about mitigations are correct?', 'question_options': ['Control-Flow Integrity can efficiently protect the forward edge\\n            but, when using target sets, is limited on the backward edge', 'Code-Pointer Integrity (specifically the implementation\\n            described in the slides) uses a separate stack to protect code\\n            pointers.', 'Shadow stacks can be implemented in software with zero\\n            overhead.', 'Safe stacks protect against corruption of all data on the\\n            stack.'], 'A_chat_id': 92685, 'B_chat_id': 92686, 'A': 'The correct statements about mitigations are:\\n[ ] Control-Flow Integrity can efficiently protect the forward edge but, when using target sets, is limited on the backward edge\\n[ ] Code-Pointer Integrity (specifically the implementation described in the slides) uses a separate stack to protect code pointers.', 'B': \"Let's break down each statement to determine if it is correct:\\n\\n1. [ ] Control-Flow Integrity can efficiently protect the forward edge but, when using target sets, is limited on the backward edge.\\n   - This statement is generally true. Control-Flow Integrity (CFI) focuses on protecting the control flow of a program to prevent attackers from hijacking the program's execution. While it can efficiently protect the forward edge (return addresses), it may have limitations on the backward edge in certain implementations.\\n\\n2. [ ] Code-Pointer Integrity (specifically the implementation described in the slides) uses a separate stack to protect code pointers.\\n   - This statement is false. Code-Pointer Integrity (CPI) typically involves protecting pointers to code functions within the program. While CPI implementations may involve various techniques, such as shadow stacks or metadata checks, using a separate stack specifically for code pointers is not a common approach.\\n\\n3. [ ] Shadow stacks can be implemented in software with zero overhead.\\n   - This statement is false. Shadow stacks are a security mechanism used to store return addresses separately from the main stack to protect against return-oriented programming attacks. While shadow stacks can enhance security, they do incur some overhead in terms of memory and performance, albeit the overhead can be minimized through efficient implementation.\\n\\n4. [ ] Safe stacks protect against corruption of all data on the stack.\\n   - This statement is false. Safe stacks are a security feature designed to protect return addresses on the stack from being overwritten by attackers. They focus on protecting specific data (return addresses) rather than all data on the stack. Other techniques, such as stack canaries, are used to protect against general stack buffer overflows.\\n\\nIn conclusion, the correct statements are:\\n- [x] Control-Flow Integrity can efficiently protect the forward edge but, when using target sets, is limited on the backward edge.\"}, {'course_id': 15005, 'question_id': 8, 'question': 'Suppose we run JOS and set a breakpoint at syscall (in lib/syscall.c). What are the Current Privilege Level (CPL) before invoking the syscall function and after executing the int 0x30 instruction?', 'question_options': ['0 3', '0 0', '3 0', '3 3'], 'A_chat_id': 92688, 'B_chat_id': 92689, 'A': 'Before invoking the syscall function, the Current Privilege Level (CPL) is 0. After executing the int 0x30 instruction, the CPL changes to 3. Therefore, the correct answer is 0 3.', 'B': 'Before invoking the syscall function, the Current Privilege Level (CPL) is 3, as it is the privilege level of user-mode code in x86 systems.\\n\\nWhen the int 0x30 instruction is executed, it triggers a software interrupt to transition from user mode to kernel mode. During this transition, the CPL changes from 3 (user mode) to 0 (kernel mode).\\n\\nTherefore, the correct answer is:\\n[ ] 3 0'}, {'course_id': 15011, 'question_id': 4176, 'question': 'Last year Professor Ueli von Gruy\\\\`{e}res worked hard to to obtain an estimator $\\\\Alg$  to estimate the total cheese consumption of fondue lovers in Switzerland. For a small $\\\\epsilon >0$, his estimator \\\\Alg only  asks $3/\\\\epsilon^2$ random persons and have the following guarantee: if we  let $W$ denote the true answer and let $X$ be the random output of \\\\Alg then \\\\begin{align*} \\\\Pr[|X - W| \\\\geq \\\\epsilon W] \\\\leq 1/3\\\\,. %\\\\qquad \\\\mbox{ where $\\\\epsilon > 0$ is a small constant.} \\\\end{align*} However, Ueli is now stuck because the error probability of $1/3$ is too high.  We are  therefore going to help Ueli by designing a new estimator with a much higher success probability while still only asking relatively few persons. For a fixed small parameter $\\\\delta >0$, your task is to design and analyze an estimator that outputs a random value $Y$ with the following guarantee: \\\\begin{align} \\\\label{eq:guarantee2} \\\\Pr[|Y - W| \\\\geq \\\\epsilon W] \\\\leq \\\\delta\\\\,. %\\\\qquad \\\\mbox{ where $\\\\epsilon > 0$ is a small constant.} \\\\end{align} Your estimator should ask at most $3000\\\\log(1/\\\\delta)/\\\\epsilon^2$ persons about their preferences.  \\\\\\\\ While you should explain why your estimator works and what tools to use to analyze it, \\\\emph{you do not need to do any detailed calculations.} \\\\\\\\ {\\\\em (In this problem you are asked to (i) design an estimator that asks  at most $3000 \\\\log(1/\\\\delta)/\\\\epsilon^2$ persons  and (ii) explain why it satisfies the guarantee~\\\\eqref{eq:guarantee2}. Recall that you are allowed to refer to material covered in the lecture notes.)}', 'question_options': None, 'A_chat_id': 92690, 'B_chat_id': 92691, 'A': \"To design an estimator with a higher success probability, we can use the Chernoff bound. Specifically, we can use Hoeffding's inequality to guarantee the desired probability in Eq. \\\\ref{eq:guarantee2}. \\n\\nBy applying Hoeffding's inequality, we can show that the probability of deviation of the estimator $Y$ from the true answer $W$ by more than $\\\\epsilon W$ decreases exponentially with the number of samples. \\n\\nBy setting the number of samples to be at most $3000\\\\log(1/\\\\delta)/\\\\epsilon^2$, we ensure that the probability of a large deviation is bounded by $\\\\delta$, as required in Eq. \\\\ref{eq:guarantee2}.\\n\\nTherefore, by using the Chernoff bound and selecting an appropriate number of samples, we can design an estimator with a much higher success probability while still only asking a relatively small number of persons.\", 'B': 'To design a new estimator with a higher success probability, we can use the technique of \"repeated sampling\" or \"voting\" to reduce the error probability. Here is the algorithm:\\n\\n1. Sample $k = 1000\\\\log(1/\\\\delta)$ independent sets of $3/\\\\epsilon^2$ persons each. Let the total number of persons sampled be $n = 3000\\\\log(1/\\\\delta)/\\\\epsilon^2$.\\n\\n2. For each set of persons, calculate the estimate of total cheese consumption using the estimator $\\\\Alg$ provided by Professor Ueli von Gruyères.\\n\\n3. Let $Y$ be the average of all the estimates obtained from the $k$ sets.\\n\\nNow, let\\'s analyze why this new estimator satisfies the guarantee \\\\eqref{eq:guarantee2}.\\n\\nLet $W$ be the true total cheese consumption, and let $Y$ be the random output of our estimator. We want to show that \\n\\\\[\\\\Pr[|Y - W| \\\\geq \\\\epsilon W] \\\\leq \\\\delta.\\\\]\\n\\nBy the union bound, we have\\n\\\\begin{align*}\\n\\\\Pr\\\\left[\\\\bigcup_{i=1}^{k} \\\\left\\\\{|X_i - W| \\\\geq \\\\epsilon W\\\\right\\\\}\\\\right] \\n&\\\\leq \\\\sum_{i=1}^{k} \\\\Pr\\\\left[|X_i - W| \\\\geq \\\\epsilon W\\\\right] \\\\\\\\\\n&= k \\\\cdot \\\\Pr\\\\left[|X - W| \\\\geq \\\\epsilon W\\\\right] \\\\\\\\\\n&\\\\leq k \\\\cdot \\\\frac{1}{3},\\n\\\\end{align*}\\nwhere $X_i$ are the estimates obtained from each set and $X$ is the average estimate $Y$.\\n\\nSince $k = 1000\\\\log(1/\\\\delta)$, we can choose $\\\\delta$ such that $k/3 \\\\leq \\\\delta$. Therefore, the error probability of the new estimator is bounded by $\\\\delta$, as required.\\n\\nThis approach leverages the power of averaging multiple estimates to reduce the error probability, while still maintaining a relatively small sample size.'}, {'course_id': 15002, 'question_id': 982, 'question': 'Up to which linguistic processing level can each of the following sentences be considered as correct? The glass broke its leg, I no go rain, The cook put cherry stones in the cake, Cars flow beautifully; syntactic, pragmatic, syntactic, semantic, lexical', 'question_options': None, 'A_chat_id': 92693, 'B_chat_id': 92694, 'A': '- The glass broke its leg: Syntactic level (grammatically correct)\\n- I no go rain: Syntactic level (grammatically incorrect)\\n- The cook put cherry stones in the cake: Semantic level (semantically incorrect)\\n- Cars flow beautifully: Pragmatic level (contextually incorrect)\\n-lexical: N/A', 'B': '1. \"The glass broke its leg\" - Syntactic level: The sentence is syntactically correct as it follows the basic structure of subject-verb-object. However, semantically it is incorrect as glasses do not have legs and cannot break them.\\n\\n2. \"I no go rain\" - Syntactic level: The sentence is syntactically incorrect as it does not follow proper English grammar rules. It should be \"I am not going to rain.\" Pragmatically, it may be understood in a colloquial or dialectal context but it is not standard English.\\n\\n3. \"The cook put cherry stones in the cake\" - Syntactic level: The sentence is syntactically correct as it follows the basic structure of subject-verb-object. However, semantically it is incorrect as cherry stones are not typically put in cakes.\\n\\n4. \"Cars flow beautifully\" - Syntactic level: The sentence is syntactically correct as it follows the basic structure of subject-verb-adverb. Semantically, it is also correct as it can be interpreted figuratively to mean that cars are moving smoothly and gracefully.\\n\\nSo, for the sentences provided:\\n- \"The glass broke its leg\": Syntactic level\\n- \"I no go rain\": Pragmatic level\\n- \"The cook put cherry stones in the cake\": Syntactic level\\n- \"Cars flow beautifully\": Semantic level'}, {'course_id': 0, 'question_id': 6096, 'question': 'Which of the following provides forward secrecy.', 'question_options': ['Transferring keys in plain.', 'Ephemeral Diffie-Hellman.', 'Semi-static Diffie-Hellman.', 'Static Diffie-Hellman.'], 'A_chat_id': 92695, 'B_chat_id': 92696, 'A': 'Ephemeral Diffie-Hellman provides forward secrecy.', 'B': 'Ephemeral Diffie-Hellman provides forward secrecy because it generates new session keys for each communication session, ensuring that even if an attacker obtains the long-term private key, they cannot decrypt past communications. Static Diffie-Hellman and Semi-static Diffie-Hellman do not provide forward secrecy as they use fixed or semi-fixed keys for multiple sessions. Transferring keys in plain also does not provide forward secrecy as the keys are exposed to potential interception.'}, {'course_id': 0, 'question_id': 5879, 'question': 'Let $n$ be an integer. Which of the following is \\\\emph{not} a group in the general case?', 'question_options': ['$(\\\\mathbf{R},+)$', '$(\\\\mathbf{Q}\\\\setminus \\\\{0\\\\},\\\\times)$', '$(\\\\mathbf{Z}_n,+ \\\\pmod{n})$', '$(\\\\mathbf{Z}_n,\\\\times \\\\pmod{n})$'], 'A_chat_id': 92697, 'B_chat_id': 92698, 'A': '$(\\\\mathbf{Q}\\\\setminus \\\\{0\\\\},\\\\times)$ is not a group in the general case. While the set of non-zero rational numbers under multiplication is closed under the operation of multiplication and has an identity element and inverses, it does not satisfy the associative property, which is a necessary condition for a set to be a group.', 'B': \"To determine if a given set equipped with an operation forms a group, we need to check the four group axioms:\\n\\n1. Closure: For all $a, b$ in the set, $a \\\\cdot b$ (or $a + b$) is also in the set.\\n2. Associativity: The operation is associative, i.e., $(a \\\\cdot b) \\\\cdot c = a \\\\cdot (b \\\\cdot c)$ for all $a, b, c$ in the set.\\n3. Identity Element: There exists an identity element $e$ in the set such that for any element $a$ in the set, $a \\\\cdot e = e \\\\cdot a = a$.\\n4. Inverses: For each element $a$ in the set, there exists an inverse $b$ such that $a \\\\cdot b = b \\\\cdot a = e$.\\n\\nLet's analyze each of the given sets:\\n\\n1. $(\\\\mathbf{R},+)$:\\n    - This set forms an abelian group under addition. It satisfies all the group axioms, so it is a group.\\n\\n2. $(\\\\mathbf{Q}\\\\setminus \\\\{0\\\\},\\\\times)$:\\n    - This set forms a group under multiplication. It satisfies all the group axioms, including the existence of inverses for every element, except for 0. Since 0 is not included in the set, the set forms a group.\\n\\n3. $(\\\\mathbf{Z}_n,+ \\\\pmod{n})$:\\n    - This set forms a group under addition modulo $n$. It satisfies all the group axioms, so it is a group.\\n\\n4. $(\\\\mathbf{Z}_n,\\\\times \\\\pmod{n})$:\\n    - This set may not form a group in the general case. To be a group, the set must satisfy the closure, associativity, identity, and inverses properties. In this case, whether this set forms a group depends on the choice of $n$.\\n  \\nTherefore, the set that is \\\\emph{not} a group in the general case is $(\\\\mathbf{Z}_n,\\\\times \\\\pmod{n})$.\"}, {'course_id': 15008, 'question_id': 2746, 'question': 'how can the results from a classifier impact the metric (precision) used? What could be a better suited metric to use with imbalanced data?', 'question_options': None, 'A_chat_id': 92699, 'B_chat_id': 92700, 'A': \"The results from a classifier can impact the precision metric by potentially misleading the evaluation of the model's performance, especially in the case of imbalanced data. Precision is calculated as TP / (TP + FP), where TP is the number of true positives and FP is the number of false positives. In the case of imbalanced data, where one class significantly outnumbers the other, precision may not accurately reflect the classifier's performance. \\n\\nA better suited metric to use with imbalanced data is the F1 score, which is the harmonic mean of precision and recall. The F1 score takes into account both false positives and false negatives, providing a more balanced evaluation of the classifier's performance. It is calculated as 2 * (precision * recall) / (precision + recall), where recall is TP / (TP + FN), with FN being the number of false negatives. \\n\\nUsing the F1 score in addition to precision can provide a more comprehensive evaluation of a classifier's performance, especially in cases of imbalanced data where precision alone may not be sufficient.\", 'B': \"When the results from a classifier are imbalanced, meaning the classes in the dataset are not equally represented, it can impact the precision metric. Precision is calculated as the number of true positive predictions divided by the total number of positive predictions (true positives + false positives). In imbalanced datasets, if one class is much more prevalent than the other, the classifier may have a bias towards predicting the majority class more frequently. This can lead to high precision for the majority class but low precision for the minority class.\\n\\nIn such cases, precision may not be the most suitable metric to evaluate the performance of the classifier. Instead, metrics like recall, F1-score, or area under the precision-recall curve (PR AUC) could be more informative. These metrics take into account both false positives and false negatives, providing a more balanced view of the classifier's performance on imbalanced data.\\n\\nFor imbalanced data, the F1-score is often preferred as it combines precision and recall into a single metric. It is calculated as the harmonic mean of precision and recall, giving equal weight to both metrics. This makes the F1-score a good choice for evaluating classifiers on imbalanced datasets, as it considers both false positives and false negatives.\\n\\nIn summary, when dealing with imbalanced data, it is important to consider metrics like recall, F1-score, or PR AUC in addition to precision to get a comprehensive understanding of the classifier's performance.\"}, {'course_id': 15003, 'question_id': 7345, 'question': 'Design an algorithm that implements consensus using multiple TRB instances.', 'question_options': None, 'A_chat_id': 92701, 'B_chat_id': 92702, 'A': 'One possible algorithm to implement consensus using multiple TRB instances is as follows:\\n\\n1. Initialize each TRB instance with its own unique identifier and a list of values to be proposed.\\n\\n2. Each TRB instance broadcasts its proposed value to all other TRB instances.\\n\\n3. Upon receiving proposed values from all other TRB instances, each TRB instance calculates the median value of the proposed values.\\n\\n4. Each TRB instance broadcasts the calculated median value to all other TRB instances.\\n\\n5. Upon receiving median values from all other TRB instances, each TRB instance checks if the received median values are within an acceptable range of each other. If the median values are within the acceptable range, the TRB instance accepts the median value as the final consensus value. If the median values are not within the acceptable range, the TRB instance repeats the process.\\n\\n6. Repeat steps 2-5 until all TRB instances have reached a final consensus value that is accepted by all instances.\\n\\nThis algorithm ensures that consensus is reached using multiple TRB instances by iteratively proposing values, calculating medians, and accepting a final consensus value that is within an acceptable range of all TRB instances.', 'B': \"To achieve consensus using multiple TRB (Threshold Relay Blockchain) instances, we can use a variation of the traditional Byzantine Fault Tolerant (BFT) algorithm. Here's a high-level outline of the algorithm:\\n\\n1. Setup:\\n   - Initialize a set of TRB instances, each with its own set of validators.\\n   - Define a threshold for the number of instances that need to agree on a decision for it to be considered final.\\n\\n2. Communication:\\n   - Validators in each TRB instance communicate their proposed transactions or blocks with the other instances.\\n\\n3. Agreement Phase:\\n   - Each TRB instance collects proposed transactions or blocks from validators.\\n   - Validators in each instance run a consensus algorithm, such as Practical Byzantine Fault Tolerance (PBFT) or HoneyBadger BFT, to reach agreement on the proposed transactions or blocks.\\n   - Once a TRB instance reaches consensus internally, it broadcasts the decision to other instances.\\n\\n4. Cross-Instance Communication:\\n   - Validators in each instance exchange the decisions reached by their respective instances.\\n   - Validators in each instance verify the decisions received from other instances and check if the threshold for the number of concurring instances is met.\\n\\n5. Final Decision:\\n   - If the threshold for the number of concurring instances is met, the decision is considered final.\\n   - If the threshold is not met, validators may need to repeat the process by proposing new transactions or blocks and going through the agreement phase again.\\n\\nThis algorithm ensures that decisions are only considered final when a sufficient number of TRB instances agree on them. This approach helps to increase the security and reliability of the consensus mechanism by leveraging multiple instances and thresholds.\"}, {'course_id': 15011, 'question_id': 4202, 'question': 'Write the dual of the following linear program: \\\\begin{align*} \\\\text{Maximize}  \\\\quad &6x_1 + 14 x_2 + 13 x_3\\\\\\\\ \\\\text{Subject to} \\\\quad & x_1 + 3x_2 + x_3 \\\\leq 24 \\\\\\\\ & x_1 + 2x_2 + 4 x_3 \\\\leq 60 \\\\\\\\ & x_1, x_2, x_3 \\\\geq 0 \\\\end{align*} Hint: How can you convince your friend that the above linear program has optimum value at most $z$?', 'question_options': None, 'A_chat_id': 92704, 'B_chat_id': 92705, 'A': 'The dual of a linear program is obtained by flipping the direction of the inequalities and swapping the roles of the variables and constraints. \\n\\nThe dual of the given linear program is:\\n\\n\\\\begin{align*}\\n\\\\text{Minimize} \\\\quad & 24y_1 + 60y_2 \\\\\\\\\\n\\\\text{Subject to} \\\\quad & y_1 + y_2 \\\\geq 6 \\\\\\\\\\n& 3y_1 + 2y_2 \\\\geq 14 \\\\\\\\\\n& y_1 + 4y_2 \\\\geq 13 \\\\\\\\\\n& y_1, y_2 \\\\geq 0\\n\\\\end{align*}\\n\\nTo convince a friend that the original linear program has an optimum value at most $z$, we can show that the dual linear program has an optimum value of at most $z$ as well. This is because of the strong duality theorem in linear programming, which states that the optimal value of the primal linear program is equal to the optimal value of the dual linear program.\\n\\nTherefore, by solving the dual linear program and showing that its optimum value is at most $z$, we can indirectly demonstrate that the original linear program also has an optimum value at most $z.', 'B': 'To write the dual of the given linear program, we first rewrite the primal program in standard form by converting the maximization problem to a minimization problem:\\n\\n\\\\begin{align*} \\\\text{Minimize}  \\\\quad &-6x_1 - 14 x_2 - 13 x_3\\\\\\\\ \\\\text{Subject to} \\\\quad & x_1 + 3x_2 + x_3 \\\\leq 24 \\\\\\\\ & x_1 + 2x_2 + 4 x_3 \\\\leq 60 \\\\\\\\ & x_1, x_2, x_3 \\\\geq 0 \\\\end{align*}\\n\\nNext, we introduce the dual variables $y_1$ and $y_2$ corresponding to the constraints in the primal problem. The dual of the given linear program is:\\n\\n\\\\begin{align*} \\\\text{Maximize}  \\\\quad &24y_1 + 60y_2\\\\\\\\ \\\\text{Subject to} \\\\quad & y_1 + y_2 \\\\leq -6 \\\\\\\\ & 3y_1 + 2y_2 \\\\leq -14 \\\\\\\\ & y_1 + 4y_2 \\\\leq -13 \\\\\\\\ & y_1, y_2 \\\\geq 0 \\\\end{align*}\\n\\nTo convince a friend that the primal linear program has an optimum value at most $z$, where $z$ is a given value, we can use the weak duality theorem. The weak duality theorem states that for any feasible primal and dual solutions, the objective value of the dual at those points is always less than or equal to the objective value of the primal at those points.\\n\\nTherefore, if we can find feasible solutions for both the primal and dual programs such that the objective value of the dual at those points is less than or equal to $z$, then we have shown that the primal program has an optimum value at most $z.'}, {'course_id': 15113, 'question_id': 7052, 'question': 'A vehicle is in linear motion. The scalar velocity as a function of time is given by\\n\\n\\\\begin{equation*}\\nv(t) = b_0t^2 -\\\\,a_0t\\\\ ,\\n\\\\end{equation*}\\n\\nwhere $b_0$ and $a_0$ are positive constants. Determine the average velocity $\\\\bar{v}(t)$ at time $t$.\\n', 'question_options': None, 'A_chat_id': 92706, 'B_chat_id': 92707, 'A': 'The average velocity $\\\\bar{v}(t)$ at time $t$ is given by the formula:\\n\\n\\\\begin{equation}\\n\\\\bar{v}(t) = \\\\frac{1}{t} \\\\int_{0}^{t} v(t) dt\\n\\\\end{equation}\\n\\nSubstitute the given velocity function into the formula:\\n\\n\\\\begin{equation}\\n\\\\bar{v}(t) = \\\\frac{1}{t} \\\\int_{0}^{t} (b_0t^2 - a_0t) dt\\n\\\\end{equation}\\n\\nSolving the integral:\\n\\n\\\\begin{equation}\\n\\\\bar{v}(t) = \\\\frac{1}{t} \\\\left[\\\\frac{b_0}{3}t^3 - \\\\frac{a_0}{2}t^2 \\\\right]_{0}^{t}\\n\\\\end{equation}\\n\\n\\\\begin{equation}\\n\\\\bar{v}(t) = \\\\frac{1}{t} \\\\left(\\\\frac{b_0}{3}t^3 - \\\\frac{a_0}{2}t^2 - 0 \\\\right)\\n\\\\end{equation}\\n\\n\\\\begin{equation}\\n\\\\bar{v}(t) = \\\\frac{1}{t} \\\\left(\\\\frac{b_0}{3}t^3 - \\\\frac{a_0}{2}t^2 \\\\right)\\n\\\\end{equation}\\n\\n\\\\begin{equation}\\n\\\\bar{v}(t) = \\\\frac{b_0}{3}t^2 - \\\\frac{a_0}{2}t\\n\\\\end{equation}\\n\\nTherefore, the average velocity $\\\\bar{v}(t)$ at time $t$ is $\\\\frac{b_0}{3}t^2 - \\\\frac{a_0}{2}t$.', 'B': 'To determine the average velocity $\\\\bar{v}(t)$ at time $t$, we need to find the total displacement of the vehicle over a certain time interval and then divide it by the total time taken. \\n\\nThe total displacement $\\\\Delta x$ of the vehicle over a time interval from $t_1$ to $t_2$ can be calculated by integrating the velocity function $v(t)$ over that time interval:\\n\\n\\\\[\\\\Delta x = \\\\int_{t_1}^{t_2} v(t)dt = \\\\int_{t_1}^{t_2} (b_0t^2 - a_0t)dt\\\\]\\n\\nThis gives us the change in position of the vehicle during the time interval from $t_1$ to $t_2$. \\n\\nThe average velocity $\\\\bar{v}(t)$ at time $t$ can then be calculated as:\\n\\n\\\\[\\\\bar{v}(t) = \\\\frac{\\\\Delta x}{\\\\Delta t}\\\\]\\n\\nwhere $\\\\Delta t = t_2 - t_1$ is the time interval over which the displacement occurs.\\n\\nTherefore, to determine the average velocity at time $t$, we need to specify the time interval over which we want to calculate the average velocity.'}, {'course_id': 15002, 'question_id': 1029, 'question': \"You have been publishing a daily column for the Gazette over the last few years and have recently reached a milestone --- your 1000th column! Realizing you'd like to go skiing more often, you decide it might be easier to automate your job by training a story generation system on the columns you've already written. Then, whenever your editor pitches you a title for a column topic, you'll just be able to give the title to your story generation system, produce the text body of the column, and publish it to the website!\\nYour column generation system has become quite successful and you've managed to automate most of your job simply by typing your editor's title pitches into your model to produce your column every day. Two years later, during the COVID--25 pandemic, your editor proposes to use your system to generate an information sheet about the pandemic for anyone looking for information about symptoms, treatments, testing sites, medical professionals, etc. Given the similarity to a previous pandemic many years before, COVID--19, you train your model on all news articles published about COVID--19 between the years of 2019--2022. Then, you generate the information page from your trained model.\\nGive an example of a potential harm that your model could produce from the perspective of human interaction harms.\", 'question_options': None, 'A_chat_id': 92709, 'B_chat_id': 92710, 'A': 'One potential harm that could arise from using a story generation system trained on past columns to generate information about the COVID-19 pandemic is the dissemination of inaccurate or outdated information. As the system is trained on articles from 2019-2022 about COVID-19, it may not be equipped to provide up-to-date information about the COVID-25 pandemic. This could lead to confusion or misinformation among readers who rely on the generated information sheet for accurate and current information. This could potentially harm human interaction by spreading false information and impacting decision-making related to health and safety during the pandemic.', 'B': 'One potential harm that could arise from using an AI-generated information page on COVID-25, trained on news articles about COVID-19, is the dissemination of inaccurate or misleading information. While AI models can be incredibly powerful tools for processing and generating vast amounts of data, they are not immune to biases or errors in the training data.\\n\\nIf the model is not properly vetted or supervised, it could inadvertently generate misinformation or promote certain biases present in the training data. This could lead to harmful consequences such as spreading inaccurate information about COVID-25 symptoms, treatments, or testing sites, potentially causing confusion or even harm to individuals seeking reliable information.\\n\\nAdditionally, relying solely on an AI-generated information page without human oversight or intervention could also lead to a lack of empathy or understanding in the communication of important health information. AI models lack the emotional intelligence and nuanced understanding of human interactions that humans possess, which could result in a cold or impersonal tone in the information presented, potentially alienating or upsetting readers who are seeking guidance and support during a challenging time like a pandemic.\\n\\nTherefore, it is crucial to ensure that AI-generated content, especially when it comes to sensitive topics like healthcare information, is carefully monitored, fact-checked, and supplemented with human oversight to mitigate the risks of disseminating harmful or misleading information and to maintain a human touch in communication.'}, {'course_id': 15011, 'question_id': 4211, 'question': 'Suppose that Alice and Bob have two documents $d_A$ and $d_B$ respectively, and Charlie wants to learn about the difference between them. We represent each document by its word frequency vector as follows. We assume that words in $d_A$ and $d_B$ come from some dictionary of size $n$, and let $x\\\\in \\\\mathbb{R}^n$ be a vector such that for every word $i\\\\in [n]$\\\\footnote{We let $[n]:=\\\\{1,2,\\\\ldots, n\\\\}$.} the entry $x_i$ equals the number of times the $i$-th word in the dictionary occurs in $d_A$. Similarly, let $y\\\\in \\\\mathbb{R}^n$ be a vector such that for every word $i\\\\in [n]$ the entry $y_i$ denotes the number of times the $i$-th word in the dictionary occurs in $d_B$. We assume that the number of words in each document is bounded by a polynomial in $n$. Suppose that there exists $i^*\\\\in [n]$ such that for all $i\\\\in [n]\\\\setminus \\\\{i^*\\\\}$ one has $|x_i-y_i|\\\\leq 2$, and for $i^*$ one has $|x_{i^*}-y_{i^*}|\\\\geq n^{1/2}$.  Show that Alice and Bob can each send a $O(\\\\log^2 n)$-bit message to Charlie, from which Charlie can recover the identity of the special word $i^*$. Your solution must succeed with probability at least $9/10$. You may assume that Alice, Bob and Charlie have a source of shared random bits.', 'question_options': None, 'A_chat_id': 92711, 'B_chat_id': 92712, 'A': 'To solve this problem, Alice and Bob can use the following protocol:\\n\\n1. Alice and Bob agree on a random hash function $h: [n] \\\\rightarrow [2\\\\log n]$ that maps each word index to a binary string of length $2\\\\log n$.\\n\\n2. Alice computes the hash values $h(x_1), h(x_2), \\\\ldots, h(x_n)$ and sends the set of hashed values $\\\\{h(x_i)\\\\}_{i=1}^n$ to Charlie.\\n\\n3. Bob computes the hash values $h(y_1), h(y_2), \\\\ldots, h(y_n)$ and sends the set of hashed values $\\\\{h(y_i)\\\\}_{i=1}^n$ to Charlie.\\n\\n4. Charlie checks if there exists an index $i^*$ such that $|h(x_{i^*}) - h(y_{i^*})| \\\\geq 2\\\\log n$. If such an index exists, Charlie outputs $i^*$. Otherwise, Charlie outputs \"No special word found.\"\\n\\nThis protocol works with high probability because:\\n- If $i = i^*$, then $|h(x_i) - h(y_i)| \\\\geq 2\\\\log n$ with high probability due to the properties of hash functions.\\n- If $i \\\\neq i^*$, then $|h(x_i) - h(y_i)| \\\\leq 2$ with high probability due to the given condition $|x_i - y_i| \\\\leq 2$ for all $i \\\\neq i^*$.\\n\\nTherefore, Alice and Bob can each send a $O(\\\\log^2 n)$-bit message to Charlie, from which Charlie can recover the identity of the special word $i^*$ with probability at least $9/10$.', 'B': \"Let's break down the problem into steps:\\n\\n1. **Construct a Protocol**: We need to come up with a protocol that allows Alice and Bob to send messages to Charlie such that Charlie can identify the special word $i^*$ with high probability.\\n\\n2. **Analyze the Protocol**: We need to analyze the protocol to ensure that it succeeds with probability at least $9/10$.\\n\\n3. **Calculate the Communication Complexity**: We need to determine the number of bits that Alice and Bob need to send to Charlie in this protocol.\\n\\nLet's start by constructing a protocol:\\n\\n1. **Protocol**:\\n    - Alice and Bob agree on a random hash function $h: [n] \\\\rightarrow [k]$ where $k = O(\\\\log n)$.\\n    - Alice computes $h(i)$ for all $i \\\\in [n]$ and sends the tuple $(h(i), x_i)$ to Charlie.\\n    - Bob computes $h(i)$ for all $i \\\\in [n]$ and sends the tuple $(h(i), y_i)$ to Charlie.\\n    - Upon receiving the messages from Alice and Bob, Charlie performs the following steps:\\n        1. For each $j \\\\in [k]$, let $S_j^A$ be the set of words $i$ such that $h(i) = j$ in the message from Alice, and $S_j^B$ be the set of words $i$ such that $h(i) = j$ in the message from Bob.\\n        2. Let $C_j = |S_j^A \\\\cap S_j^B|$ for each $j \\\\in [k]$.\\n        3. Find the index $j^*$ such that $C_{j^*} = \\\\max_{j\\\\in [k]} C_j$.\\n        4. Output $i^* = \\\\text{argmax}_{i\\\\in S_{j^*}^A \\\\cup S_{j^*}^B} |x_i - y_i|$.\\n\\nNow, let's analyze the protocol:\\n\\n2. **Analysis**:\\n    - By the definition of the protocol, if there exists $i^*$ such that $|x_{i^*} - y_{i^*}| \\\\geq n^{1/2}$, then $i^*$ will be in the set $S_{j^*}^A \\\\cup S_{j^*}^B$ with high probability.\\n    - Since $|x_i - y_i| \\\\leq 2$ for all $i \\\\neq i^*$, the maximum difference occurs at $i^*$.\\n    - The protocol succeeds if $i^*$ is correctly identified in $S_{j^*}^A \\\\cup S_{j^*}^B$.\\n    - The probability of error in identifying $i^*$ is at most $1/10$ by Chernoff bound.\\n\\nFinally, let's calculate the communication complexity:\\n\\n3. **Communication Complexity**:\\n    - Alice and Bob each send $O(kn) = O(\\\\log n \\\\cdot n)$ bits to Charlie.\\n    - The total communication complexity is $O(\\\\log n \\\\cdot n)$ bits, which is $O(\\\\log^2 n)$.\\n\\nTherefore, we have successfully constructed a protocol that allows Alice and Bob to send messages to Charlie, from which Charlie can recover the identity of the special word $i^*$ with high probability and a communication complexity of $O(\\\\log^2 n)$ bits.\"}, {'course_id': 0, 'question_id': 5654, 'question': 'Tick the \\\\textbf{false} statement.', 'question_options': ['Cryptographic primitives used in Bluetooth are provably secure.', 'In WEP, authentication is done with the pre-shared keys.', 'The security of Bluetooth 2.0 pairing is based on PIN.', 'Due to memory limitations, dummy devices can share the same key with everyone.'], 'A_chat_id': 92713, 'B_chat_id': 92714, 'A': 'The false statement is: Cryptographic primitives used in Bluetooth are provably secure. While Bluetooth does use cryptographic primitives for security, there have been vulnerabilities and weaknesses discovered in Bluetooth protocols over the years. It is important to regularly update and improve security measures in Bluetooth technology.', 'B': 'The false statement is: \\n\\n[ ] Cryptographic primitives used in Bluetooth are provably secure.'}, {'course_id': 15115, 'question_id': 7304, 'question': 'You heard about electrons and point charges in the lecture. Explain in your own words what an electron and what a point charge is and what their respective properties are. What is the difference and what are the similarities of electrons and point charges?\\n', 'question_options': None, 'A_chat_id': 92715, 'B_chat_id': 92716, 'A': 'An electron is a subatomic particle that carries a negative electric charge. It is one of the fundamental components of an atom, located outside the nucleus in the electron cloud. Electrons have properties such as mass, charge, and spin.\\n\\nA point charge, on the other hand, is a theoretical concept used in physics to describe a particle with a specific amount of charge concentrated at a single point in space. Point charges do not have physical dimensions and are used to simplify calculations in electrostatics.\\n\\nThe main similarity between electrons and point charges is that they both carry electric charge. However, the key difference is that electrons are actual subatomic particles with mass and volume, while point charges are idealized particles with no physical size. Both electrons and point charges interact through the electromagnetic force, influencing the motion of other charged particles in their vicinity.', 'B': 'An electron is a subatomic particle that carries a negative electric charge. It is one of the fundamental components of matter and is found in the outer regions of an atom. The electron is extremely small and has a mass that is almost 2000 times smaller than that of a proton or neutron.\\n\\nA point charge, on the other hand, is a theoretical concept used in physics to represent a particle or object with all its charge concentrated at a single point in space. This simplification is often used to analyze the behavior of electric fields and interactions between charged particles.\\n\\nThe similarities between electrons and point charges lie in their fundamental property of carrying electric charge. Both electrons and point charges interact with other charged particles through the electromagnetic force. They can attract or repel each other based on the principles of electrostatics.\\n\\nThe main difference between electrons and point charges is that electrons are actual physical particles with mass and other properties, whereas a point charge is a conceptual model that simplifies the analysis of electric fields and interactions. While electrons have a specific mass and are confined to the structure of an atom, a point charge is an idealized representation of a charged object with no physical size or structure.\\n\\nIn summary, electrons are specific subatomic particles with negative charge and mass, while point charges are theoretical constructs used to simplify the analysis of electric interactions. Both share the property of carrying electric charge and interact with other charged particles through the electromagnetic force.'}, {'course_id': 15002, 'question_id': 961, 'question': 'Consider the following context-free grammar \\\\(G\\\\) (where \\\\(\\\\text{S}\\\\) is the top-level symbol):\\n\\n\\\\(R_{01}: \\\\text{S} \\\\rightarrow \\\\text{NP VP}\\\\)\\n\\\\(R_{02}: \\\\text{NP} \\\\rightarrow \\\\text{NP0}\\\\)\\n\\\\(R_{03}: \\\\text{NP} \\\\rightarrow \\\\text{Det NP0}\\\\)\\n\\\\(R_{04}: \\\\text{NP0} \\\\rightarrow \\\\text{N}\\\\)\\n\\\\(R_{05}: \\\\text{NP0} \\\\rightarrow \\\\text{Adj N}\\\\)\\n\\\\(R_{06}: \\\\text{NP0} \\\\rightarrow \\\\text{NP0 PNP}\\\\)\\n\\\\(R_{07}: \\\\text{VP} \\\\rightarrow \\\\text{V}\\\\)\\n\\\\(R_{08}: \\\\text{VP} \\\\rightarrow \\\\text{V NP}\\\\)\\n\\\\(R_{09}: \\\\text{VP} \\\\rightarrow \\\\text{V NP PNP}\\\\)\\n\\\\(R_{10}: \\\\text{PNP} \\\\rightarrow \\\\text{Prep NP}\\\\)\\n\\ncomplemented by the lexicon \\\\(L\\\\):\\na        : Det\\nblue     : Adj, N\\ndrink    : N, V\\ndrinks   : N, V\\nfriends  : N\\nfrom     : Prep\\ngave     : V\\nletter   : N\\nmy       : Det\\nneighbor : N\\nnice     : Adj, N\\nof       : Prep\\npostman  : N\\nran      : V\\nthe      : Det\\nto       : PrepHow many (syntactic and lexical) rules does the extended Chomsky Normal Form grammar equivalent to \\\\(G\\\\) contain, if produced as described in the parsing lecture?', 'question_options': ['the grammar \\\\(G\\\\) cannot be converted to extended Chomsky Normal Form', 'the grammar \\\\(G\\\\) already is in extended Chomsky Normal Form', '11 rules', '31 rules', '48 rules'], 'A_chat_id': 92717, 'B_chat_id': 92718, 'A': 'To convert the given context-free grammar \\\\(G\\\\) to Extended Chomsky Normal Form (ECNF), we need to eliminate the rules with more than two symbols on the right-hand side. Here is the breakdown of the rules in the given grammar:\\n\\n- \\\\(R_{01}\\\\) has 2 symbols on the right-hand side\\n- \\\\(R_{02}\\\\) has 2 symbols on the right-hand side\\n- \\\\(R_{03}\\\\) has 3 symbols on the right-hand side\\n- \\\\(R_{04}\\\\) has 1 symbol on the right-hand side\\n- \\\\(R_{05}\\\\) has 2 symbols on the right-hand side\\n- \\\\(R_{06}\\\\) has 3 symbols on the right-hand side\\n- \\\\(R_{07}\\\\) has 1 symbol on the right-hand side\\n- \\\\(R_{08}\\\\) has 2 symbols on the right-hand side\\n- \\\\(R_{09}\\\\) has 3 symbols on the right-hand side\\n- \\\\(R_{10}\\\\) has 2 symbols on the right-hand side\\n\\nTherefore, the total number of rules in the given grammar is 10. To convert this grammar to ECNF, we need to add additional rules for unit productions and rules with more than two symbols on the right-hand side. The exact number of rules in the ECNF equivalent grammar will depend on the specific transformations applied during the conversion process. The correct answer is not provided in the options given.', 'B': \"To convert a context-free grammar to Chomsky Normal Form (CNF), we need to ensure that each rule is in one of the following forms:\\n\\n1. \\\\(A \\\\rightarrow BC\\\\) where \\\\(A, B, C\\\\) are non-terminal symbols\\n2. \\\\(A \\\\rightarrow a\\\\) where \\\\(A\\\\) is a non-terminal symbol and \\\\(a\\\\) is a terminal symbol\\n3. \\\\(S \\\\rightarrow \\\\varepsilon\\\\) where \\\\(S\\\\) is the start symbol and \\\\(\\\\varepsilon\\\\) is the empty string\\n\\nGiven the context-free grammar \\\\(G\\\\) and the lexicon \\\\(L\\\\), let's convert it to Chomsky Normal Form:\\n\\n1. Introduce new non-terminal symbols for terminals:\\n   - \\\\(Noun \\\\rightarrow \\\\text{blue} | \\\\text{friends} | \\\\text{letter} | \\\\text{neighbor} | \\\\text{postman}\\\\)\\n   - \\\\(Verb \\\\rightarrow \\\\text{drink} | \\\\text{drinks} | \\\\text{gave} | \\\\text{ran}\\\\)\\n   - \\\\(Adjective \\\\rightarrow \\\\text{blue} | \\\\text{nice}\\\\)\\n   - \\\\(Preposition \\\\rightarrow \\\\text{from} | \\\\text{of} | \\\\text{to}\\\\)\\n   - \\\\(Determiner \\\\rightarrow \\\\text{a} | \\\\text{my} | \\\\text{the}\\\\)\\n\\n2. Rewrite the grammar rules in CNF:\\n   - \\\\(R_{01}: \\\\text{S} \\\\rightarrow \\\\text{NP VP}\\\\)\\n   - \\\\(R_{02}: \\\\text{NP} \\\\rightarrow \\\\text{NP0}\\\\)\\n   - \\\\(R_{03}: \\\\text{NP} \\\\rightarrow \\\\text{Det NP0}\\\\)\\n   - \\\\(R_{04}: \\\\text{NP0} \\\\rightarrow \\\\text{Noun}\\\\)\\n   - \\\\(R_{05}: \\\\text{NP0} \\\\rightarrow \\\\text{Adjective Noun}\\\\)\\n   - \\\\(R_{06}: \\\\text{NP0} \\\\rightarrow \\\\text{NP0 PNP}\\\\)\\n   - \\\\(R_{07}: \\\\text{VP} \\\\rightarrow \\\\text{Verb}\\\\)\\n   - \\\\(R_{08}: \\\\text{VP} \\\\rightarrow \\\\text{Verb NP}\\\\)\\n   - \\\\(R_{09}: \\\\text{VP} \\\\rightarrow \\\\text{Verb NP PNP}\\\\)\\n   - \\\\(R_{10}: \\\\text{PNP} \\\\rightarrow \\\\text{Preposition NP}\\\\)\\n\\nAfter converting the grammar to CNF, we have the following rules:\\n\\n- 10 original rules\\n- 5 rules for introducing new non-terminal symbols for terminals\\n- 10 rules for rewriting the original grammar rules in CNF\\n\\nTherefore, the total number of rules in the extended Chomsky Normal Form grammar equivalent to \\\\(G\\\\) is \\\\(10 + 5 + 10 = 25\\\\). \\n\\nHence, the correct option is:\\n[ ] 31 rules\"}, {'course_id': 15116, 'question_id': 7224, 'question': 'Determine the lines of current $y = y(x)$ and the acceleration $\\\\vec{a}(x,y)$ for a stationary bidimensional flow described by the velocity field :\\n\\\\begin{equation*} \\n{\\\\bf v} = (\\\\frac{{v_0 }}{l})(x\\\\vec e_x  - y\\\\vec e_y)~.\\n\\\\end{equation*}\\n', 'question_options': None, 'A_chat_id': 92720, 'B_chat_id': 92721, 'A': 'To determine the lines of current, we need to find the streamlines of the flow. Streamlines are defined by the equation $\\\\frac{dx}{v_x} = \\\\frac{dy}{v_y}$, where $v_x$ and $v_y$ are the components of the velocity field.\\n\\nGiven the velocity field ${\\\\bf v} = (\\\\frac{{v_0 }}{l})(x\\\\vec e_x  - y\\\\vec e_y)$, we have $v_x = \\\\frac{{v_0 }}{l}x$ and $v_y = -\\\\frac{{v_0 }}{l}y$.\\n\\nTherefore, the equation for the streamlines is:\\n\\\\begin{equation*} \\n\\\\frac{dx}{\\\\frac{{v_0 }}{l}x} = \\\\frac{dy}{-\\\\frac{{v_0 }}{l}y}\\n\\\\end{equation*}\\n\\nIntegrating both sides, we get:\\n\\\\begin{equation*} \\n\\\\ln|x| = -\\\\ln|y| + C\\n\\\\end{equation*}\\n\\nSolving for y, we get the equation for the lines of current $y(x)$.\\n\\nTo determine the acceleration $\\\\vec{a}(x,y)$, we use the acceleration formula in fluid dynamics which is given by:\\n\\\\begin{equation*} \\n\\\\vec{a} = \\\\frac{D\\\\vec{v}}{Dt} = \\\\frac{\\\\partial \\\\vec{v}}{\\\\partial t} + (\\\\vec{v} \\\\cdot \\\\nabla) \\\\vec{v}\\n\\\\end{equation*}\\n\\nGiven that the flow is stationary (time-independent), the first term $\\\\frac{\\\\partial \\\\vec{v}}{\\\\partial t}$ is zero. Therefore, we only need to calculate the convective acceleration term $(\\\\vec{v} \\\\cdot \\\\nabla) \\\\vec{v$.\\n\\nCalculating the convective acceleration term, we get:\\n\\\\begin{equation*} \\n(\\\\vec{v} \\\\cdot \\\\nabla) \\\\vec{v} = (v_x \\\\frac{\\\\partial}{\\\\partial x} + v_y \\\\frac{\\\\partial}{\\\\partial y})\\\\vec{v}\\n\\\\end{equation*}\\n\\nSubstitute the expressions for $v_x$ and $v_y$ in terms of x and y, and simplify to get the acceleration $\\\\vec{a}(x,y)$.', 'B': \"To determine the streamlines (lines of current) for the stationary bidimensional flow, we need to find the equation of the streamlines by setting the velocity vector field equal to the tangent vector to the streamlines. \\n\\nThe velocity field is given as ${\\\\bf v} = \\\\left(\\\\frac{{v_0 }}{l}\\\\right)(x\\\\vec e_x  - y\\\\vec e_y)$.\\n\\nThe equation of the streamlines is given by $\\\\frac{{dx}}{{v_x}} = \\\\frac{{dy}}{{v_y}}$, where $v_x$ and $v_y$ are the components of velocity in the $x$ and $y$ directions respectively.\\n\\nIn this case, $v_x = \\\\frac{{v_0 }}{l}x$ and $v_y = -\\\\frac{{v_0 }}{l}y$.\\n\\nTherefore, the equation of the streamlines is:\\n\\\\begin{align*} \\n\\\\frac{{dx}}{{\\\\frac{{v_0 }}{l}x}} &= \\\\frac{{dy}}{{-\\\\frac{{v_0 }}{l}y}} \\\\\\\\\\n\\\\frac{{dx}}{{x}} &= -\\\\frac{{dy}}{{y}} \\\\\\\\\\n\\\\ln|x| &= -\\\\ln|y| + C \\\\\\\\\\n\\\\ln\\\\left|\\\\frac{{x}}{y}\\\\right| &= C \\\\\\\\\\n\\\\frac{{x}}{y} &= e^C\\n\\\\end{align*}\\n\\nSo, the equation of the streamlines is $\\\\frac{{x}}{y} = C$, where $C$ is a constant. This represents a family of hyperbolic curves.\\n\\nNext, let's find the acceleration vector $\\\\vec{a}(x,y)$ for this flow. The acceleration is given by the material derivative of the velocity field with respect to time, which can be expressed as:\\n\\n\\\\begin{align*} \\n\\\\vec{a}(x,y) &= \\\\frac{{D\\\\vec{v}}}{{Dt}} \\\\\\\\\\n&= \\\\frac{{\\\\partial\\\\vec{v}}}{{\\\\partial t}} + \\\\left(\\\\vec{v}\\\\cdot\\\\nabla\\\\right)\\\\vec{v} \\\\\\\\\\n&= \\\\frac{{\\\\partial\\\\vec{v}}}{{\\\\partial t}} + \\\\left(v_x\\\\frac{{\\\\partial}}{{\\\\partial x}} + v_y\\\\frac{{\\\\partial}}{{\\\\partial y}}\\\\right)\\\\vec{v}\\n\\\\end{align*}\\n\\nSince the flow is stationary (time-independent), the first term on the right-hand side is zero. We can now calculate the acceleration vector using the given velocity field. \\n\\nLet's calculate the terms in the acceleration vector $\\\\vec{a}(x,y)$ one by one.\"}, {'course_id': 15003, 'question_id': 7348, 'question': 'Implement a uniform reliable broadcast algorithm without using any failure detector, i.e., using only BestEffort-Broadcast(BEB).', 'question_options': None, 'A_chat_id': 92722, 'B_chat_id': 92723, 'A': 'One way to implement a uniform reliable broadcast algorithm without using any failure detector is to use the following approach:\\n\\n1. Let `n` be the number of processes in the system.\\n2. Each process `p_i` maintains a set `delivered_i` to keep track of messages it has delivered.\\n3. When a process `p_i` wants to broadcast a message `m`, it first sends the message using BEB to all other processes.\\n4. Upon receiving a message `m` from process `p_j`, process `p_i` delivers `m` to its application layer if `m` has not been delivered before and adds `m` to `delivered_i`.\\n5. Each process `p_i` periodically piggybacks its `delivered_i` set in its BEB messages to all other processes.\\n6. Upon receiving a message with piggybacked delivered set from process `p_i`, process `p_j` checks if all messages in `delivered_i` have been delivered. If not, process `p_j` requests missing messages from `p_i`.\\n7. Process `p_i` re-broadcasts missing messages to process `p_j` upon receiving a request.\\n\\nThis way, by piggybacking delivered sets in BEB messages and requesting missing messages, each process can ensure that all messages are reliably delivered to all processes in the system without using any failure detector.', 'B': 'To implement a uniform reliable broadcast without using any failure detector, we can leverage the BestEffort-Broadcast (BEB) primitive along with additional acknowledgments to achieve reliability. Here is a step-by-step guide to implementing a uniform reliable broadcast algorithm using BEB:\\n\\n1. **Initialization**:\\n   - Each process in the system maintains a list of delivered messages and a list of pending messages.\\n\\n2. **Broadcast**:\\n   - When a process wants to broadcast a message, it first sends the message using BEB to all other processes in the system.\\n   - Upon receiving a message from BEB, a process appends the message to its pending list.\\n\\n3. **Deliver**:\\n   - When a process receives a message through BEB, it checks if the message has already been delivered. If not, it delivers the message to the application layer.\\n   - After delivering the message, the process broadcasts an acknowledgment using BEB to all other processes.\\n\\n4. **Acknowledgment**:\\n   - Upon receiving an acknowledgment from BEB, a process marks the message as delivered in its list of pending messages.\\n   - If the acknowledgment is for a message that was already delivered, the process ignores the acknowledgment.\\n\\n5. **Reliability**:\\n   - To ensure reliability, a process waits for acknowledgments for each message it broadcasts before marking it as delivered. This way, if a process fails before sending an acknowledgment, the message will be rebroadcasted by the sender.\\n\\nBy using this algorithm, we can achieve reliable broadcast without relying on any failure detector. The acknowledgment mechanism ensures that messages are reliably delivered to all correct processes in the system.'}, {'course_id': 0, 'question_id': 6030, 'question': 'For two $\\\\ell$-bit numbers, the \\\\textbf{tightest} complexity to compute their gcd is', 'question_options': ['$\\\\mathcal{O}(2^{\\\\ell})$.', '$\\\\mathcal{O}(\\\\ell^3)$.', '$\\\\mathcal{O}(\\\\ell^2)$.', '$\\\\mathcal{O}(\\\\log{\\\\ell}^2)$.'], 'A_chat_id': 92724, 'B_chat_id': 92725, 'A': \"The tightest complexity to compute the gcd of two $\\\\ell$-bit numbers is $\\\\mathcal{O}(\\\\ell^3)$. This is because algorithms like Euclid's algorithm have a complexity of $\\\\mathcal{O}(\\\\log{ab})$ where $a$ and $b$ are the input numbers. Since the input numbers have $\\\\ell$ bits each, the complexity can be written as $\\\\mathcal{O}(\\\\log{2^{\\\\ell}\\\\cdot 2^{\\\\ell}}) = \\\\mathcal{O}(\\\\log{2^{2\\\\ell}}) = \\\\mathcal{O}(2\\\\ell) = \\\\mathcal{O}(\\\\ell)$. So, the tightest complexity is $\\\\mathcal{O}(\\\\ell^3)$.\", 'B': 'To compute the gcd of two $\\\\ell$-bit numbers, we can use the Euclidean algorithm. The Euclidean algorithm has a complexity of $\\\\mathcal{O}(\\\\log{\\\\min(a, b)})$ where $a$ and $b$ are the two input numbers.\\n\\nIn this case, the input numbers are $\\\\ell$-bit numbers. Since the numbers are $\\\\ell$-bit, the minimum of the two numbers is at most $2^{\\\\ell}$.\\n\\nTherefore, the tightest complexity to compute their gcd would be $\\\\mathcal{O}(\\\\log{2^{\\\\ell}}) = \\\\mathcal{O}(\\\\ell)$. \\n\\nSo, the correct option is:\\n[ ] $\\\\mathcal{O}(\\\\ell)$.'}, {'course_id': 15002, 'question_id': 4948, 'question': \"In an automated email router of a company, we want to make the distinction between three kind of\\nemails: technical (about computers), financial, and the rest ('irrelevant'). For this we plan to use a\\nNaive Bayes approach.\\nWhat is the main assumption made by Naive Bayes classifiers? Why is it 'Naive'?\\n\\nWe will consider the following three messages:\\n\\nThe Dow industrials tumbled 120.54 to 10924.74, hurt by GM's sales forecast\\nand two economic reports. Oil rose to $71.92.\\n\\nBitTorrent Inc. is boosting its network capacity as it prepares to become a centralized hub for legal video content. In May, BitTorrent announced a deal with\\nWarner Brothers to distribute its TV and movie content via the BT platform. It\\nhas now lined up IP transit for streaming videos at a few gigabits per second\\n\\nIntel will sell its XScale PXAxxx applications processor and 3G baseband processor businesses to Marvell for $600 million, plus existing liabilities. The deal\\ncould make Marvell the top supplier of 3G and later smartphone processors, and\\nenable Intel to focus on its core x86 and wireless LAN chipset businesses, the\\ncompanies say.\\n\\nSuppose we have collected the following statistics $3^{3}$ about the word frequencies within the corresponding classes, where '0.00...' stands for some very small value:\\n\\\\begin{center}\\n\\\\begin{tabular}{|c|c|c|c|c|c|c|c|}\\n\\\\hline\\n & technical & financial & irrelevant &  & technical & financial & irrelevan \\\\\\\\\\n\\\\hline\\n$\\\\$<$ number $>$ & 0.01 & 0.07 & 0.05 & deal & 0.01 & 0.02 & $0.00 \\\\ldots$ \\\\\\\\\\n\\\\hline\\nDow & $0.00 \\\\ldots$ & 0.08 & $0.00 \\\\ldots$ & forecast & $0.00 \\\\ldots$ & 0.03 & 0.01 \\\\\\\\\\n\\\\hline\\nGM & $0.00 \\\\ldots$ & 0.03 & $0.00 \\\\ldots$ & gigabit & 0.03 & $0.00 \\\\ldots$ & $0.00 \\\\ldots$ \\\\\\\\\\n\\\\hline\\nIP & 0.03 & $0.00 \\\\ldots$ & $0.00 \\\\ldots$ & hub & 0.06 & $0.00 \\\\ldots$ & 0.01 \\\\\\\\\\n\\\\hline\\nIntel & 0.02 & 0.02 & $0.00 \\\\ldots$ & network & 0.04 & 0.01 & $0.00 \\\\ldots$ \\\\\\\\\\n\\\\hline\\nbusiness & 0.01 & 0.07 & 0.04 & processor & 0.07 & 0.01 & $0.00 \\\\ldots$ \\\\\\\\\\n\\\\hline\\ncapacity & 0.01 & $0.00 \\\\ldots$ & $0.00 \\\\ldots$ & smartphone & 0.04 & 0.04 & 0.01 \\\\\\\\\\n\\\\hline\\nchipset & 0.04 & 0.01 & $0.00 \\\\ldots$ & wireless & 0.02 & 0.01 & $0.00 \\\\ldots$ \\\\\\\\\\n\\\\hline\\ncompany & 0.01 & 0.04 & 0.05 & sen & re & . & . \\\\\\\\\\n\\\\hline\\n\\\\end{tabular}\\n\\\\end{center}\\n\\nWe now want to specifically focus on the processing of compounds such as 'network capacity' in\\nthe second text.\\n\\nOutline how you would build a pre-processor for compound words\", 'question_options': None, 'A_chat_id': 92726, 'B_chat_id': 92728, 'A': \"A pre-processor for compound words in text data involves breaking down the compound words into their individual components to improve the accuracy of the Naive Bayes classifier. Here's an outline of how you can build a pre-processor for compound words:\\n\\n1. Tokenization: Tokenize the text data into individual words using whitespace or punctuation as delimiters.\\n\\n2. Identify Compound Words: Look for patterns in the text data that indicate compound words, such as words separated by spaces or hyphens.\\n\\n3. Extract Components: For compound words identified, extract the individual components by splitting the compound word based on the identified pattern.\\n\\n4. Update Word Frequencies: Update the word frequency statistics for the individual components of the compound words in the corresponding classes.\\n\\n5. Remove Compound Words: Replace the compound words in the text data with their individual components to create a new text dataset.\\n\\nBy following these steps, you can preprocess the text data to handle compound words effectively in a Naive Bayes classifier. This approach helps improve the accuracy of the classifier by treating compound words as separate features rather than single entities.\", 'B': \"The main assumption made by Naive Bayes classifiers is that the features are conditionally independent given the class label. This assumption is 'naive' because it simplifies the model by assuming that the presence of a particular feature in a class is independent of the presence of other features.\\n\\nTo build a pre-processor for compound words like 'network capacity' in the text, you can follow these steps:\\n\\n1. Tokenization: Break down the text into individual words or tokens. This step is important to separate compound words into their constituent parts.\\n\\n2. Identify Compound Words: Look for patterns in the tokens that indicate compound words. In the given example, the pattern 'word1 word2' can be a clue that the two words together form a compound word.\\n\\n3. Merge Compound Words: Once compound words are identified, merge them into a single token to represent the compound concept. For example, 'network capacity' can be merged into a single token 'network_capacity'.\\n\\n4. Update Word Frequencies: Update the word frequency statistics for the compound words based on the merged tokens. This will ensure that the Naive Bayes classifier can learn the association between the compound words and the corresponding class labels.\\n\\n5. Feature Extraction: Use the pre-processed tokens, including the merged compound words, as features for training the Naive Bayes classifier. This will help the classifier learn how different words and compound words are associated with the specific classes.\\n\\nBy building a pre-processor that specifically handles compound words like 'network capacity', you can improve the accuracy of the Naive Bayes classifier in distinguishing between technical, financial, and irrelevant emails based on the content of the messages.\"}, {'course_id': 0, 'question_id': 5904, 'question': 'Tick the \\\\textit{wrong} assertion.', 'question_options': ['If $\\\\Big(\\\\frac{b}{n}\\\\Big)=+$1 for $b \\\\in \\\\mathbb{Z}_n^* $, then $b$ is a quadratic residue.', 'If $\\\\Big(\\\\frac{b}{p}\\\\Big)=+$1 for $b \\\\in \\\\mathbb{Z}_p^* $, then $b$ is a quadratic residue, where $p$ is prime.', 'If $b$ is a quadratic residue for $b \\\\in \\\\mathbb{Z}_n^* $, then $\\\\Big(\\\\frac{b}{n}\\\\Big)=+1$.', 'If $b$ is a quadratic residue for $b \\\\in \\\\mathbb{Z}_p^* $, then $\\\\Big(\\\\frac{b}{p}\\\\Big)=+1$, where $p$ is prime.'], 'A_chat_id': 92729, 'B_chat_id': 92730, 'A': 'The wrong assertion is: If $b$ is a quadratic residue for $b \\\\in \\\\mathbb{Z}_n^*$, then $\\\\Big(\\\\frac{b}{n}\\\\Big)=+1$. This is incorrect because if $b$ is a quadratic residue modulo $n$, then $\\\\Big(\\\\frac{b}{n}\\\\Big)$ can be either +1 or -1, depending on the specific value of $b$ and $n$.', 'B': 'The wrong assertion is:\\n\\n[ ] If $b$ is a quadratic residue for $b \\\\in \\\\mathbb{Z}_n^* $, then $\\\\Big(\\\\frac{b}{n}\\\\Big)=+1$. \\n\\nThis is incorrect because the Legendre symbol is defined for odd primes $n$, not for all integers $n$.'}, {'course_id': 0, 'question_id': 6105, 'question': 'Let $E$ be an elliptic curve. Solving which of the following problems would help you to break Elliptic Curve Diffie-Hellman (ECDH) over $E$?', 'question_options': ['Let $P,R \\\\in E$. Given $P$ and $P+R$, compute $R$.', 'Let $P,Q \\\\in E$. Given $P$ and $Q$, compute the product between $P$ and $Q$, i.e., $P \\\\times Q$.', 'Let $P \\\\in E$ and $\\\\ell \\\\in \\\\mathbb{N}$. Given $P$ and $\\\\ell P$, compute $\\\\ell$.', 'Find a point which is not on the curve $E$.'], 'A_chat_id': 92731, 'B_chat_id': 92732, 'A': 'Finding a point which is not on the curve E would help break Elliptic Curve Diffie-Hellman (ECDH) over E. This is because if an attacker can find a point not on the curve, they can potentially create a trapdoor and break the security of the ECDH key exchange protocol. The other options do not directly relate to breaking ECDH over E.', 'B': 'The problem that would help break Elliptic Curve Diffie-Hellman (ECDH) over $E$ is:\\n[ ] Let $P \\\\in E$ and $\\\\ell \\\\in \\\\mathbb{N}$. Given $P$ and $\\\\ell P$, compute $\\\\ell$.\\n\\nThis problem would allow an attacker to calculate the discrete logarithm, which is the key operation underlying the security of ECDH. If an attacker can efficiently compute the discrete logarithm, they can break the security of the ECDH scheme.'}, {'course_id': 15116, 'question_id': 7222, 'question': 'Determine the relation between pressure and height for a gas for : $T=T(z)$ but no exchange of heat in the gas (adiabatic atmosphere).\\nEstimate the pressure at an altitude of 10 km. Consider the atmosphere as an ideal, biatomic gas of molecular mass 28.\\n\\nN.A.: R = 8.2 J/mol K ; T$_0$=293 K.\\\\\\\\\\n', 'question_options': None, 'A_chat_id': 92733, 'B_chat_id': 92734, 'A': 'For an adiabatic atmosphere, the relation between pressure and height can be expressed using the ideal gas law and the adiabatic process equation. The ideal gas law is given by:\\n\\n\\\\[ PV = nRT \\\\]\\n\\nWhere P is the pressure, V is the volume, n is the number of moles, R is the gas constant, and T is the temperature.\\n\\nFor an adiabatic process, we have the relation:\\n\\n\\\\[ PV^\\\\gamma = \\\\text{constant} \\\\]\\n\\nWhere γ is the ratio of specific heats.\\n\\nFor a biatomic gas, γ = 7/5.\\n\\nGiven that T = T(z), we can express T as a function of z by using the temperature lapse rate:\\n\\n\\\\[ \\\\frac{dT}{dz} = - \\\\frac{g}{C_p} \\\\]\\n\\nWhere g is the acceleration due to gravity and Cp is the specific heat at constant pressure.\\n\\nIntegrating the above equation, we get:\\n\\n\\\\[ T(z) = T_0 - \\\\frac{g}{C_p}z \\\\]\\n\\nSubstitute this expression for T(z) into the ideal gas law to get the relation between pressure and height.\\n\\nTo estimate the pressure at an altitude of 10 km, we can use the relation between pressure and height derived above and the given values for R, T0, and the molecular mass of the gas. Calculate the temperature at 10 km altitude using the temperature lapse rate equation and then use the ideal gas law to find the pressure at that altitude.', 'B': 'To determine the relation between pressure and height for an adiabatic atmosphere, we can use the ideal gas law and the equation of state for an adiabatic process. \\n\\nThe ideal gas law is given by: \\n\\\\[ PV = nRT \\\\]\\nwhere P is the pressure, V is the volume, n is the number of moles, R is the gas constant, and T is the temperature.\\n\\nFor an adiabatic process, we have: \\n\\\\[ PV^{\\\\gamma} = \\\\text{constant} \\\\]\\nwhere \\\\(\\\\gamma\\\\) is the adiabatic index and is given by: \\n\\\\[ \\\\gamma = \\\\frac{C_p}{C_v} \\\\]\\nwhere \\\\(C_p\\\\) and \\\\(C_v\\\\) are the specific heat capacities at constant pressure and constant volume, respectively.\\n\\nFor a diatomic gas, such as the one described in the problem, the specific heat capacities are: \\n\\\\[ C_p = \\\\frac{5}{2} R \\\\]\\n\\\\[ C_v = \\\\frac{3}{2} R \\\\]\\n\\nSubstituting the expressions for \\\\(C_p\\\\) and \\\\(C_v\\\\) into the equation for \\\\(\\\\gamma\\\\), we get: \\n\\\\[ \\\\gamma = \\\\frac{5}{3} \\\\]\\n\\nNow, we can express the pressure as a function of height using the ideal gas law and the adiabatic equation: \\n\\\\[ P(z)V(z)^{\\\\gamma} = nRT(z) \\\\]\\n\\\\[ P(z) = \\\\frac{nRT(z)}{V(z)^{\\\\gamma}} \\\\]\\n\\\\[ P(z) = \\\\frac{m}{M} \\\\frac{RT(z)}{V(z)^{\\\\gamma}} \\\\]\\n\\\\[ P(z) = \\\\frac{m}{M} \\\\frac{RT(z)}{\\\\left(\\\\frac{m}{\\\\rho}\\\\right)^{\\\\gamma}} \\\\]\\n\\\\[ P(z) = \\\\left(\\\\frac{RT(z)}{M}\\\\right) \\\\left(\\\\frac{\\\\rho}{m}\\\\right)^{\\\\gamma} \\\\]\\n\\\\[ P(z) = \\\\frac{R\\\\rho}{M} T(z) \\\\left(\\\\frac{\\\\rho}{m}\\\\right)^{\\\\gamma} \\\\]\\n\\nwhere \\\\(m\\\\) is the mass of the gas, \\\\(M\\\\) is the molar mass, \\\\(\\\\rho\\\\) is the density of the gas, and we have used the relation \\\\(V = \\\\frac{m}{\\\\rho}\\\\).\\n\\nTo estimate the pressure at an altitude of 10 km, we need to know the temperature profile \\\\(T(z)\\\\) and the density profile \\\\(\\\\rho(z)\\\\) of the atmosphere. Without these profiles, we cannot provide an exact numerical value for the pressure at 10 km. \\n\\nHowever, we can provide a general expression for the pressure at 10 km using the derived relation above and the given parameters in the problem.'}, {'course_id': 4, 'question_id': 6580, 'question': 'Which of the following apply to recent Android-based mobile systems but not\\n    to Linux-based desktop systems?', 'question_options': ['Apps should use the binder interface to communicate with other\\n            apps.', 'By default, each app runs as its own user.', 'All apps run in a strict container with only limited system\\n            calls available.', 'Arbitrary apps can exchange files through shared\\n            directories.'], 'A_chat_id': 92736, 'B_chat_id': 92737, 'A': '[ ] Apps should use the binder interface to communicate with other apps.\\n[X] By default, each app runs as its own user.\\n[X] All apps run in a strict container with only limited system calls available.\\n[ ] Arbitrary apps can exchange files through shared directories.\\n\\nThe binder interface is used for inter-process communication in Android systems, but not specific to Android only. The other three statements are specific to recent Android-based mobile systems.', 'B': 'The following applies to recent Android-based mobile systems but not to Linux-based desktop systems:\\n\\n- [ ] Apps should use the binder interface to communicate with other apps.\\n- [ ] By default, each app runs as its own user.\\n- [ ] All apps run in a strict container with only limited system calls available.'}, {'course_id': 0, 'question_id': 5748, 'question': 'Which of the following operation is not part of AES?', 'question_options': ['AddRoundKey', 'SubBytes', 'MixColumns', 'MulRoundKey'], 'A_chat_id': 92738, 'B_chat_id': 92739, 'A': 'The operation that is not part of AES is MulRoundKey. The correct operations in AES are AddRoundKey, SubBytes, and MixColumns.', 'B': 'The operation \"MulRoundKey\" is not part of the AES algorithm. The correct operations in AES are:\\n\\n- AddRoundKey\\n- SubBytes\\n- MixColumns\\n\\n\"MulRoundKey\" is not a standard operation in AES.'}, {'course_id': 0, 'question_id': 6134, 'question': 'Which of the following integers has the square roots $\\\\{2,3\\\\}$ when taken modulo $5$ \\\\textbf{and} the square roots $\\\\{3,10\\\\}$ when taken modulo $13$.', 'question_options': ['$4$.', '$9$.', '$6$.', '$5$.'], 'A_chat_id': 92740, 'B_chat_id': 92741, 'A': '$4$. \\n\\nFirst, we check for the square roots {2,3} modulo 5:\\n- For $4^2 \\\\equiv 1 \\\\pmod{5}$, $4$ is a square root of $2$ modulo $5$.\\n- For $4^2 \\\\equiv 1 \\\\pmod{5}$, $4$ is a square root of $3$ modulo $5$.\\n\\nNext, we check for the square roots {3,10} modulo 13:\\n- For $4^2 \\\\equiv 3 \\\\pmod{13}$, $4$ is not a square root of $3$ modulo $13$.\\n- For $9^2 \\\\equiv 3 \\\\pmod{13}$, $9$ is a square root of $3$ modulo $13$.\\n- For $4^2 \\\\equiv 3 \\\\pmod{13}$, $4$ is not a square root of $10$ modulo $13$.\\n- For $9^2 \\\\equiv 3 \\\\pmod{13}$, $9$ is not a square root of $10$ modulo $13$.\\n\\nTherefore, the integer $4$ satisfies the conditions given in the question.', 'B': \"Let's analyze each option one by one:\\n\\n1. If we take the square roots of $4$ modulo $5$, we get $\\\\{2,3\\\\}$ as $2^2 \\\\equiv 4 \\\\equiv 9 \\\\equiv 3^2 \\\\pmod{5}$. However, when we take the square roots of $4$ modulo $13$, we get $\\\\{2,11\\\\}$, not $\\\\{3,10\\\\}$. So, $4$ is not the correct answer.\\n\\n2. If we take the square roots of $9$ modulo $5$, we get $\\\\{2,3\\\\}$ as $2^2 \\\\equiv 4 \\\\equiv 9 \\\\equiv 1 \\\\equiv 3^2 \\\\pmod{5}$. When we take the square roots of $9$ modulo $13$, we get $\\\\{3,10\\\\}$ as $3^2 \\\\equiv 9 \\\\equiv 22 \\\\equiv 10 \\\\pmod{13}$. Thus, $9$ satisfies the given conditions.\\n\\n3. If we take the square roots of $6$ modulo $5$, we get $\\\\{1,4\\\\}$, not $\\\\{2,3\\\\}$. Additionally, the square roots of $6$ modulo $13$ are $\\\\{4,9\\\\}$, not $\\\\{3,10\\\\}$. So, $6$ is not the correct answer.\\n\\n4. If we take the square roots of $5$ modulo $5$, we get $\\\\{0,0\\\\}$, not $\\\\{2,3\\\\}$. Additionally, the square roots of $5$ modulo $13$ are $\\\\{4,9\\\\}$, not $\\\\{3,10\\\\}$. So, $5$ is not the correct answer.\\n\\nTherefore, the integer that satisfies all the given conditions is $\\\\boxed{9}$.\"}, {'course_id': 15002, 'question_id': 1036, 'question': \"You have been publishing a daily column for the Gazette over the last few years and have recently reached a milestone --- your 1000th column! Realizing you'd like to go skiing more often, you decide it might be easier to automate your job by training a story generation system on the columns you've already written. Then, whenever your editor pitches you a title for a column topic, you'll just be able to give the title to your story generation system, produce the text body of the column, and publish it to the website!\\nYour column generation system has become quite successful and you've managed to automate most of your job simply by typing your editor's title pitches into your model to produce your column every day. Two years later, during the COVID--25 pandemic, your editor proposes to use your system to generate an information sheet about the pandemic for anyone looking for information about symptoms, treatments, testing sites, medical professionals, etc. Given the similarity to a previous pandemic many years before, COVID--19, you train your model on all news articles published about COVID--19 between the years of 2019--2022. Then, you generate the information page from your trained model.\\nGive an example of a potential harm that your model could produce from the perspective of leaking private information.\", 'question_options': None, 'A_chat_id': 92744, 'B_chat_id': 92745, 'A': 'One potential harm that could arise from using a story generation system trained on personal data such as columns or news articles is the unintentional leakage of private information. If the model inadvertently generates content that includes personal details, sensitive information, or confidential data from the columns or news articles it was trained on, this could lead to privacy breaches and compromise the security of individuals involved. This could have serious consequences for both the individuals whose information is leaked and the organization responsible for using the model. It is crucial to implement strong data protection measures and ethical guidelines when training and deploying such models to mitigate the risk of leaking private information.', 'B': 'One potential harm that could arise from using a story generation system trained on personal columns and news articles is the inadvertent leakage of private information. For example, if your previous columns contained personal anecdotes, details about your life, or information about individuals you know, there is a risk that the model could generate content that inadvertently reveals sensitive or private information.\\n\\nIf the model is not properly trained to filter out private or confidential details, it could generate stories that expose personal relationships, health issues, financial matters, or other sensitive information that was originally shared in your columns. This could lead to violations of privacy, breaches of trust, and potential legal implications if the leaked information is sensitive or confidential.\\n\\nIt is essential to implement strict data privacy protocols and ethical guidelines when using AI models trained on personal or sensitive data to prevent the unintentional disclosure of private information and to safeguard the privacy and confidentiality of individuals involved.'}, {'course_id': 0, 'question_id': 5795, 'question': 'Tick the \\\\emph{false} assertion.', 'question_options': ['RSA-PSS is a signature scheme.', 'RSA-OAEP is an encryption scheme.', 'The RSA based encryption scheme of the standard PKCS \\\\#1 v1.5 is vulnerable to a side channel attack.', 'The RSA based scheme ISO/IEC 9796 is an encryption scheme.'], 'A_chat_id': 92746, 'B_chat_id': 92747, 'A': 'The false assertion is : The RSA based encryption scheme of the standard PKCS \\\\#1 v1.5 is vulnerable to a side channel attack. The RSA-PSS is a signature scheme, RSA-OAEP is an encryption scheme, and the RSA based scheme ISO/IEC 9796 is an encryption scheme. The RSA based encryption scheme of the standard PKCS \\\\#1 v1.5 is indeed vulnerable to a padding oracle attack, which is a type of side channel attack.', 'B': '- [ ] The RSA based encryption scheme of the standard PKCS \\\\#1 v1.5 is vulnerable to a side channel attack.'}, {'course_id': 15127, 'question_id': 3333, 'question': 'Consider a classification problem on linearly separable data. We train an SVM model and a logistic regression model. For logistic regression (LR) we add a small regularization term (penalty on weights) in order to make the optimum well-defined. Each model gives us a margin. Consider a datapoint $\\\\mathbf{x}_{0}$ that is correctly classified and strictly outside both margins Which one of the following statements is incorrect ?', 'question_options': ['There exists a direction in which we can slightly move $\\\\mathbf{x}_{0}$ without changing the LR decision boundary after retraining.', \"$\\\\mathbf{x}_{0}$ isn't a support vector\", 'There exists a direction in which we can arbitrarily move $\\\\mathbf{x}_{0}$ without changing the SVM decision boundary after retraining.', 'If we remove $\\\\mathbf{x}_{0}$ from the dataset and retrain, this will change the LR decision boundary.', 'If we remove $\\\\mathbf{x}_{0}$ from the dataset and retrain, this will not change the SVM decision boundary.'], 'A_chat_id': 92748, 'B_chat_id': 92749, 'A': 'The incorrect statement is: There exists a direction in which we can arbitrarily move $\\\\mathbf{x}_{0}$ without changing the SVM decision boundary after retraining. \\n\\nIn SVM, the decision boundary is determined by the support vectors, which are the data points closest to the decision boundary. By moving $\\\\mathbf{x}_{0}$ arbitrarily, we may change the support vectors and hence the decision boundary.', 'B': 'Let\\'s analyze each statement:\\n\\n1. There exists a direction in which we can slightly move $\\\\mathbf{x}_{0}$ without changing the LR decision boundary after retraining.\\n- This statement is correct. Since logistic regression with a small regularization term is continuous, small movements of $\\\\mathbf{x}_{0}$ may not change the decision boundary significantly.\\n\\n2. $\\\\mathbf{x}_{0}$ isn\\'t a support vector\\n- This statement is correct. Since $\\\\mathbf{x}_{0}$ is strictly outside both margins, it is not a support vector for either the SVM or the logistic regression model.\\n\\n3. There exists a direction in which we can arbitrarily move $\\\\mathbf{x}_{0}$ without changing the SVM decision boundary after retraining.\\n- This statement is incorrect. In SVM, the decision boundary is determined by the support vectors, and moving a point that is not a support vector arbitrarily can change the decision boundary.\\n\\n4. If we remove $\\\\mathbf{x}_{0}$ from the dataset and retrain, this will change the LR decision boundary.\\n- This statement is correct. Removing $\\\\mathbf{x}_{0}$ from the dataset can change the logistic regression decision boundary as the model will be trained on a different set of data points.\\n\\n5. If we remove $\\\\mathbf{x}_{0}$ from the dataset and retrain, this will not change the SVM decision boundary.\\n- This statement is incorrect. Since $\\\\mathbf{x}_{0}$ is not a support vector, removing it from the dataset may not change the SVM decision boundary, as the decision boundary is determined by the support vectors.\\n\\nTherefore, the incorrect statement is: \"There exists a direction in which we can arbitrarily move $\\\\mathbf{x}_{0}$ without changing the SVM decision boundary after retraining.\"'}, {'course_id': 15127, 'question_id': 1205, 'question': 'Consider the following matrix-factorization problem. For the observed ratings $r_{u m}$ for a given pair $(u, m)$ of a user $u$ and a movie $m$, one typically tries to estimate the score by $$ f_{u m}=\\\\left\\\\langle\\\\mathbf{v}_{u}, \\\\mathbf{w}_{m}\\\\right\\\\rangle+b_{u}+b_{m} $$ Here $\\\\mathbf{v}_{u}$ and $\\\\mathbf{w}_{m}$ are vectors in $\\\\mathbb{R}^{D}$ and $b_{u}$ and $b_{m}$ are scalars, indicating the bias. Assume that our objective is given by $$ \\\\frac{1}{2} \\\\sum_{u \\\\sim m}\\\\left(f_{u m}-r_{u m}\\\\right)^{2}+\\\\frac{\\\\lambda}{2}\\\\left[\\\\sum_{u \\\\in \\\\mathbf{U}}\\\\left(b_{u}^{2}+\\\\left\\\\|\\\\mathbf{v}_{u}\\\\right\\\\|^{2}\\\\right)+\\\\sum_{m \\\\in \\\\mathbf{M}}\\\\left(b_{m}^{2}+\\\\left\\\\|\\\\mathbf{w}_{m}\\\\right\\\\|^{2}\\\\right)\\\\right] $$ where $\\\\lambda>0$. Here $\\\\mathbf{U}$ denotes the set of all users, $M$ the set of all movies, and $u \\\\sim m$ represents the sum over all $(u, m)$ pairs for which a rating exists. Write the optimal values of $b_{u}$, provided that all other values are fixed.', 'question_options': None, 'A_chat_id': 92750, 'B_chat_id': 92751, 'A': 'To find the optimal value of $b_u$, we need to take the derivative of the objective function with respect to $b_u$ and set it equal to zero. The objective function is given by:\\n\\n$$\\\\frac{1}{2} \\\\sum_{u \\\\sim m}(f_{u m}-r_{u m})^{2}+\\\\frac{\\\\lambda}{2}\\\\left[\\\\sum_{u \\\\in \\\\mathbf{U}}(b_{u}^{2}+\\\\|\\\\mathbf{v}_{u}\\\\|^{2})+\\\\sum_{m \\\\in \\\\mathbf{M}}(b_{m}^{2}+\\\\|\\\\mathbf{w}_{m}\\\\|^{2})\\\\right]$$\\n\\nTaking the derivative with respect to $b_u$, we get:\\n\\n$$\\\\frac{\\\\partial}{\\\\partial b_u}\\\\left[\\\\frac{1}{2} \\\\sum_{u \\\\sim m}(f_{u m}-r_{u m})^{2}+\\\\frac{\\\\lambda}{2}\\\\sum_{u \\\\in \\\\mathbf{U}}(b_{u}^{2}+\\\\|\\\\mathbf{v}_{u}\\\\|^{2})\\\\right] = \\\\lambda b_u + \\\\sum_{m \\\\sim u}(f_{u m}-r_{u m})$$\\n\\nSetting this derivative equal to zero and solving for $b_u$, we get:\\n\\n$$\\\\lambda b_u + \\\\sum_{m \\\\sim u}(f_{u m}-r_{u m}) = 0$$\\n$$b_u = -\\\\frac{1}{\\\\lambda} \\\\sum_{m \\\\sim u}(f_{u m}-r_{u m})$$\\n\\nTherefore, the optimal value of $b_u$ is given by the above expression.', 'B': \"To find the optimal value of $b_{u}$, we differentiate the objective function with respect to $b_{u}$ and set it to zero. Let's calculate the derivative:\\n\\nGiven the objective function: \\n\\n$$ \\\\frac{1}{2} \\\\sum_{u \\\\sim m}\\\\left(f_{u m}-r_{u m}\\\\right)^{2}+\\\\frac{\\\\lambda}{2}\\\\left[\\\\sum_{u \\\\in \\\\mathbf{U}}\\\\left(b_{u}^{2}+\\\\left\\\\|\\\\mathbf{v}_{u}\\\\right\\\\|^{2}\\\\right)+\\\\sum_{m \\\\in \\\\mathbf{M}}\\\\left(b_{m}^{2}+\\\\left\\\\|\\\\mathbf{w}_{m}\\\\right\\\\|^{2}\\\\right)\\\\right] $$\\n\\nThe partial derivative of the objective function with respect to $b_{u}$ is:\\n\\n$$ \\\\frac{\\\\partial}{\\\\partial b_{u}} = \\\\sum_{u \\\\sim m} (f_{um} - r_{um}) + \\\\lambda b_{u} $$\\n\\nSetting this derivative to zero, we get:\\n\\n$$ \\\\sum_{u \\\\sim m} (f_{um} - r_{um}) + \\\\lambda b_{u} = 0 $$\\n\\nSolving for $b_{u}$, we get:\\n\\n$$ b_{u} = -\\\\frac{1}{\\\\lambda} \\\\sum_{u \\\\sim m} (f_{um} - r_{um}) $$\\n\\nTherefore, the optimal value of $b_{u}$, provided that all other values are fixed, is:\\n\\n$$ b_{u} = -\\\\frac{1}{\\\\lambda} \\\\sum_{u \\\\sim m} (f_{um} - r_{um}) $$\\n\\nThis is the expression for updating the bias term $b_{u}$ in the matrix factorization problem.\"}, {'course_id': 15002, 'question_id': 4931, 'question': \"You are responsible for a project aiming at providing on-line recommendations to the customers of\\na on-line book selling company.\\nThe general idea behind this recommendation system is to cluster books according to both customers\\nand content similarities, so as to propose books similar to the books already bought by a given\\ncustomer. The core of the recommendation system is a clustering algorithm aiming at regrouping\\nbooks likely to be appreciate by the same person. This clustering should not only be achieved\\nbased on the purchase history of customers, but should also be refined by the content of the books\\nthemselves. It's that latter aspect we want to address in this exam question.\\n\\nConsider the following six 'documents' (toy example):\\nd1: 'Because cows are not sorted as they return from the fields to their home pen, cow flows\\nare improved.'\\nd2: 'He was convinced that if he owned the fountain pen that he'd seen in the shop window for years, he could write fantastic stories with it. That was the kind of pen you cannot forget.'\\nd3: 'With this book you will learn how to draw humans, animals (cows, horses, etc.) and flowers with a charcoal pen.'\\nd4: 'The cows were kept in pens behind the farm, hidden from the road. That was the typical kind of pen made for cows.'\\nd5: 'If Dracula wrote with a fountain pen, this would be the kind of pen he would write with, filled with blood red ink. It was the pen she chose for my punishment, the pen of my torment. What a mean cow!'\\nd6: 'What pen for what cow? A red pen for a red cow, a black pen for a black cow, a brown pen for a brown cow, ... Understand?'\\n\\nand suppose (toy example) that they are indexed only by the two words: pen and cow.\\n\\nWhat are their vector representations?\", 'question_options': None, 'A_chat_id': 92752, 'B_chat_id': 92753, 'A': \"To represent the documents as vectors, we can use the Bag of Words (BoW) model. First, we need to create a vocabulary consisting of all unique words in the documents. In this case, the vocabulary would be {because, cows, are, not, sorted, as, they, return, from, the, fields, to, their, home, pen, cow, flows, improved, he, was, convinced, that, if, owned, fountain, he'd, seen, in, shop, window, for, years, could, write, fantastic, stories, with, it, kind, of, you, cannot, forget, this, book, will, learn, how, draw, humans, animals, horses, etc, flowers, charcoal, were, kept, pens, behind, farm, hidden, road, typical, made, Dracula, wrote, blood, red, ink, she, chose, my, punishment, torment, mean, what, black, brown, Understand}.\\n\\nThen, we can represent each document as a vector where each element corresponds to the frequency of the corresponding word in the document. For example:\\n- d1: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\\n- d2: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\", 'B': 'To represent the documents as vectors, we can use the Bag-of-Words model. In this model, each document is represented as a vector where each element corresponds to the frequency of a specific word in the document.\\n\\nIn this case, we have two words of interest: \"pen\" and \"cow\". We can create a vector representation for each document based on the occurrence of these two words.\\n\\nLet\\'s calculate the vector representations for the given documents:\\n\\n- d1: [1, 1] (pen appears once, cow appears once)\\n- d2: [2, 0] (pen appears twice, cow does not appear)\\n- d3: [1, 1] (pen appears once, cow appears once)\\n- d4: [1, 1] (pen appears once, cow appears once)\\n- d5: [2, 1] (pen appears twice, cow appears once)\\n- d6: [1, 1] (pen appears once, cow appears once)\\n\\nSo, the vector representations for the given documents based on the occurrences of the words \"pen\" and \"cow\" are:\\n\\n- d1: [1, 1]\\n- d2: [2, 0]\\n- d3: [1, 1]\\n- d4: [1, 1]\\n- d5: [2, 1]\\n- d6: [1, 1]\\n\\nThese vectors represent the documents in a simplified manner based on the presence of the words \"pen\" and \"cow\" in each document.'}, {'course_id': 4, 'question_id': 6627, 'question': 'Which of the following is/are true about fuzzing?', 'question_options': [\"Fuzzers may get ``stuck'' and cannot easily detect that they are\\n               no longer improving coverage\", 'The efficacy of a fuzzing campaign scales with its speed (executions per second)', 'Fuzzers generally determine the exploitability of a crash.', 'There is little to no benefit in running fuzzers in parallel.'], 'A_chat_id': 92757, 'B_chat_id': 92758, 'A': 'The true statements about fuzzing are:\\n\\n- Fuzzers may get \"stuck\" and cannot easily detect that they are no longer improving coverage\\n- The efficacy of a fuzzing campaign scales with its speed (executions per second)', 'B': \"1. [X] Fuzzers may get ``stuck'' and cannot easily detect that they are no longer improving coverage.\\n- True. Fuzzers can sometimes get stuck in a particular part of the program and may not be able to detect that they are not making progress in finding new vulnerabilities.\\n\\n2. [X] The efficacy of a fuzzing campaign scales with its speed (executions per second).\\n- True. The faster a fuzzer can execute test cases, the more likely it is to find vulnerabilities within a given timeframe.\\n\\n3. [ ] Fuzzers generally determine the exploitability of a crash.\\n- False. Fuzzers are designed to generate input to trigger crashes, but determining the exploitability of a crash typically requires further manual analysis.\\n\\n4. [ ] There is little to no benefit in running fuzzers in parallel.\\n- False. Running fuzzers in parallel can help increase coverage and find vulnerabilities more efficiently by exploring different paths simultaneously.\"}, {'course_id': 0, 'question_id': 5659, 'question': 'If we pick independent random numbers in $\\\\{1, 2, \\\\dots, N\\\\}$ with uniform distribution, $\\\\theta \\\\sqrt{N}$ times, we get at least one number twice with probability\\\\dots', 'question_options': ['$e^{\\\\theta ^2}$', '$1-e^{\\\\theta ^2}$', '$e^{-\\\\theta ^2 /2}$', '$1-e^{-\\\\theta ^2 /2}$'], 'A_chat_id': 92759, 'B_chat_id': 92760, 'A': 'The probability that we do not get any repeated numbers when picking $\\\\theta \\\\sqrt{N}$ independent random numbers from $\\\\{1, 2, \\\\dots, N\\\\}$ with uniform distribution is given by:\\n\\n$1 - \\\\frac{N}{N} \\\\cdot \\\\frac{N-1}{N} \\\\cdot \\\\frac{N-2}{N} \\\\dots \\\\frac{N-\\\\theta \\\\sqrt{N}+1}{N}$\\n\\nSimplifying this expression gives:\\n\\n$1 - \\\\frac{N!}{N^{\\\\theta \\\\sqrt{N}}(N-\\\\theta \\\\sqrt{N})!}$\\n\\nUsing the approximation $n! \\\\approx \\\\sqrt{2\\\\pi n}(\\\\frac{n}{e})^n$, we can further simplify this expression to get:\\n\\n$1 - e^{-\\\\frac{\\\\theta^2}{2}}$\\n\\nTherefore, the correct answer is: $1 - e^{-\\\\frac{\\\\theta^2}{2}}$', 'B': 'To solve this problem, we can consider the probability that no number is repeated in the $\\\\theta \\\\sqrt{N}$ draws. \\n\\nIn the first draw, we have $N$ choices. In the second draw, we have $N-1$ choices (since we cannot repeat the number we chose in the first draw). In the $\\\\theta \\\\sqrt{N}$ draws, we have $(N)(N-1)(N-2) \\\\cdots (N - \\\\theta \\\\sqrt{N} + 1)$ choices.\\n\\nTherefore, the probability that no number is repeated is given by:\\n\\n$$P(\\\\text{no number is repeated}) = \\\\frac{N(N-1)(N-2) \\\\cdots (N - \\\\theta \\\\sqrt{N} + 1)}{N^{\\\\theta \\\\sqrt{N}}}$$\\n\\nNow, we can use the fact that $e^{-x} = 1 - x + \\\\frac{x^2}{2!} - \\\\frac{x^3}{3!} + \\\\cdots$, and for small $x$, we can approximate $e^{-x} \\\\approx 1 - x$.\\n\\nTherefore, for small values of $\\\\theta$, we can approximate the above expression as:\\n\\n$$P(\\\\text{no number is repeated}) \\\\approx 1 - \\\\frac{\\\\theta \\\\sqrt{N}}{N} = 1 - \\\\frac{\\\\theta}{\\\\sqrt{N}}$$\\n\\nSince the probability of getting at least one number repeated is the complement of the probability of no number being repeated, we have:\\n\\n$$P(\\\\text{at least one number is repeated}) = 1 - P(\\\\text{no number is repeated}) \\\\approx \\\\frac{\\\\theta}{\\\\sqrt{N}}$$\\n\\nTherefore, the correct choice is:\\n[ ] $e^{\\\\theta ^2}$\\n[ ] $1-e^{\\\\theta ^2}$\\n[ ] $e^{-\\\\theta ^2 /2}$\\n[ ] $1-e^{-\\\\theta ^2 /2}$\\n\\nThe correct choice is:\\n[ ] $e^{\\\\theta ^2}$\\n[ ] $1-e^{\\\\theta ^2}$\\n[ ] $e^{-\\\\theta ^2 /2}$\\n[ ] $1-e^{-\\\\theta ^2 /2}$'}, {'course_id': 15103, 'question_id': 1768, 'question': 'Assume you are working in a company on the back-end of a mobile application. You are tasked with improving the integration of the authentication via Google in your app, but your manager tells you:\\n\"Don\\'t run any tests today, we only have a few API calls left for today\\'s rate limit, we need to preserve those for customers.\"\\nIn 1-2 sentences, propose a change to the codebase to avoid this problem.', 'question_options': None, 'A_chat_id': 92761, 'B_chat_id': 92762, 'A': 'One solution could be to implement local testing environments that mimic the behavior of the Google authentication API, allowing developers to test the integration without using up the limited API calls.', 'B': \"One approach could be to temporarily disable the Google authentication feature in the app's development environment while working on improvements, so that API calls are not being consumed unnecessarily and the team can continue developing and testing without exceeding the rate limit.\"}, {'course_id': 15103, 'question_id': 1710, 'question': \"Assume you are working on SuperQuiz, a trendy app that lets everyone design quizzes and share them with friends! Your first assignment is to add a new feature that is requested by users. You are given the following transcript of an interview with a customer of your product:\\n> Hi!\\n> So you're the developer of this quiz app?\\n> The one where you write questions and answers and get your friends to guess?\\n> It's fun, but I can't use it as much as I'd like.\\n> I'm a firefighter, I don't have time for this app during the day, but I wish I could use it at home.\\n> See, when I come back home after work, I have a bunch of stuff to do, cleaning, cooking, ...\\n> And when I'm doing these tasks, I'm rather busy. Not like when I'm watching TV.\\n> I don't always have my phone in my hands! Sometimes I even forget where I put it.\\n> Maybe if you made it so I could talk to the app? You know, many apps have that feature now.\\n> Then I could multitask! Think about quizzes while I'm cooking!\\n> Otherwise, I won't use the app much.\\n\\nWrite down a user story, as a single sentence that follows the following guidelines:\\n1) A user story that summarizes all necessary information from the feedback\\n2) the user story does not contain any unnecessary information\", 'question_options': None, 'A_chat_id': 92763, 'B_chat_id': 92764, 'A': 'As a firefighter user, I want to be able to use the quiz app hands-free by implementing voice command functionality, so that I can multitask and enjoy the app while doing chores at home.', 'B': '\"As a firefighter user, I want to be able to use the quiz app hands-free through voice commands so that I can multitask and engage with the app while doing household chores.\"'}, {'course_id': 0, 'question_id': 6322, 'question': 'Tick the \\\\emph{incorrect} statement. When $x\\\\rightarrow+\\\\infty$ \\\\ldots', 'question_options': ['$x^3 + 2x + 5 = \\\\mathcal{O}(x^3)$.', '$\\\\frac{1}{x^2} = \\\\mathcal{O}(\\\\frac{1}{x})$.', '$2^{\\\\frac{x}{\\\\log x}} = \\\\mathcal{O}(2^x)$.', '$n^x = \\\\mathcal{O}(x^n)$ for any constant $n>1$.'], 'A_chat_id': 92765, 'B_chat_id': 92766, 'A': 'The incorrect statement is: $n^x = \\\\mathcal{O}(x^n)$ for any constant $n>1$. This is not true as $n^x$ grows faster than $x^n$ for any constant $n>1$ as $x\\\\rightarrow+\\\\infty$.', 'B': 'The incorrect statement is: \\n\\n[ ] $n^x = \\\\mathcal{O}(x^n)$ for any constant $n>1$. \\n\\nThis statement is incorrect because $n^x$ grows faster than $x^n$ for any constant $n>1$ as $x\\\\rightarrow+\\\\infty$.'}, {'course_id': 0, 'question_id': 6078, 'question': 'Tick the \\\\emph{incorrect} assertion regarding the Diffie-Hellman key exchange', 'question_options': ['It is secure under a passive adversary.', 'It is secure when working in a subgroup of $\\\\mathbb{Z}_p^*$ of big prime order.', 'It is secure under an active Man-In-The-Middle attack.', 'It is not secure when working in $\\\\mathbb{Z}_n$ with $n$ having only small prime factors.'], 'A_chat_id': 92767, 'B_chat_id': 92768, 'A': 'It is secure under an active Man-In-The-Middle attack. \\n\\nThe Diffie-Hellman key exchange is vulnerable to a Man-In-The-Middle attack if an adversary intercepts the communication between the two parties and establishes separate key exchanges with each party, allowing them to decrypt and read the messages.', 'B': 'The \\\\emph{incorrect} assertion regarding the Diffie-Hellman key exchange is:\\n\\n\\\\[ \\\\text{\\\\textbf{[ ] It is secure under an active Man-In-The-Middle attack.}} \\\\]\\n\\nDiffie-Hellman key exchange is vulnerable to Man-In-The-Middle attacks if not properly authenticated.'}, {'course_id': 15003, 'question_id': 7331, 'question': 'Can we devise a Best-effort Broadcast algorithm that satisfies the causal delivery property, without being a causal broadcast algorithm, i.e., without satisfying the agreement property of a reliable broadcast?', 'question_options': None, 'A_chat_id': 92769, 'B_chat_id': 92770, 'A': 'Yes, it is possible to devise a Best-effort Broadcast algorithm that satisfies the causal delivery property without being a causal broadcast algorithm. In a Best-effort Broadcast algorithm, messages are delivered to all correct processes in the system, but there is no guarantee of agreement on the order of delivery. By implementing causal delivery, messages are delivered in a causal order, meaning that if message m1 causally precedes message m2, then m1 will be delivered before m2. However, without satisfying the agreement property of a reliable broadcast, there is no guarantee that all correct processes will deliver the same set of messages in the same order. This allows for some flexibility in the delivery order while still ensuring causal consistency.', 'B': 'Yes, we can devise a Best-effort Broadcast algorithm that satisfies the causal delivery property without being a causal broadcast algorithm. In a Best-effort Broadcast algorithm, messages are delivered to all correct processes in the system, but there is no guarantee of the order in which messages are delivered. \\n\\nTo achieve causal delivery in a Best-effort Broadcast algorithm, we can use a causal ordering of messages based on the happened-before relation. When a process broadcasts a message, it includes the causal information of the message, such as the message itself and the timestamp indicating the order in which events occurred. Upon receiving a message, a process delivers it only if all preceding messages in the causal order have been delivered.\\n\\nThis approach ensures that messages are delivered in a causally consistent order, satisfying the causal delivery property. However, since Best-effort Broadcast does not guarantee agreement, there may be cases where different processes have different sets of delivered messages due to message losses or failures.'}, {'course_id': 0, 'question_id': 6139, 'question': 'Select the \\\\emph{incorrect} statement. Pedersen Commitment is', 'question_options': ['unconditionally hiding.', 'computationally binding.', 'based on the hardness of the discrete logarithm problem.', 'based on DSA.'], 'A_chat_id': 92771, 'B_chat_id': 92772, 'A': 'The incorrect statement is: based on DSA. Pedersen Commitment is not based on the Digital Signature Algorithm (DSA), but rather on the hardness of the discrete logarithm problem.', 'B': 'The incorrect statement is:\\n[ ] based on DSA.\\n\\nPedersen Commitment is not based on DSA; it is based on the hardness of the discrete logarithm problem.'}, {'course_id': 15006, 'question_id': 4192, 'question': 'The goal of the 4 following questions is to prove that the methods map and mapTr are equivalent. The\\nformer is the version seen in class and is specified by the lemmas MapNil and MapCons. The later version\\nis a tail-recursive version and is specified by the lemmas MapTrNil and MapTrCons.\\nAll lemmas on this page hold for all x: Int, y: Int, xs: List[Int], ys: List[Int], l: List\\n[Int] and f: Int => Int.\\nGiven the following lemmas:\\n\\n(MapNil) Nil.map(f) === Nil\\n(MapCons) (x :: xs).map(f) === f(x) :: xs.map(f)\\n(MapTrNil) Nil.mapTr(f, ys) === ys\\n(MapTrCons) (x :: xs).mapTr(f, ys) === xs.mapTr(f, ys ++ (f(x) :: Nil))\\n(NilAppend) Nil ++ xs === xs\\n(ConsAppend) (x :: xs) ++ ys === x :: (xs ++ ys)\\nLet us first prove the following lemma:\\n\\n(AccOut) l.mapTr(f, y :: ys) === y :: l.mapTr(f, ys)\\n\\nWe prove it by induction on l.\\nInduction step: l is x :: xs. Therefore, we need to prove:\\n(x :: xs).mapTr(f, y :: ys) === y :: (x :: xs).mapTr(f, ys)\\n\\nWe name the induction hypothesis IH.\\nWhat exact sequence of lemmas should we apply to rewrite the left hand-side ((x :: xs).mapTr(f, y\\n:: ys)) to the right hand-side (y :: (x :: xs).mapTr(f, ys))?', 'question_options': None, 'A_chat_id': 92773, 'B_chat_id': 92774, 'A': 'To rewrite the left hand-side ((x :: xs).mapTr(f, y :: ys)) to the right hand-side (y :: (x :: xs).mapTr(f, ys)), we should apply the following sequence of lemmas:\\n\\n1. (MapTrCons) - Apply (x :: xs).mapTr(f, y :: ys) = xs.mapTr(f, y :: ys ++ (f(x) :: Nil)) by using (MapTrCons) with x = x, xs = xs, f = f, ys = y :: ys.\\n2. (ConsAppend) - Simplify ys ++ (f(x) :: Nil) to y :: (ys ++ (f(x) :: Nil)) by using (ConsAppend) with x = y, xs = ys, ys = f(x) :: Nil.\\n3. (IH) - Substitute xs.mapTr(f, y :: (ys ++ (f(x) :: Nil))) with y :: xs.mapTr(f, ys) using the induction hypothesis (IH).\\n\\nBy applying this sequence of lemmas, we can rewrite the left hand-side to the right hand-side as required.', 'B': 'To rewrite the left hand-side ((x :: xs).mapTr(f, y :: ys)) to the right hand-side (y :: (x :: xs).mapTr(f, ys)), we can follow these steps using the provided lemmas:\\n\\n1. Apply the MapTrCons lemma with x, xs, f, and (y :: ys) as arguments:\\n   - (x :: xs).mapTr(f, y :: ys) === xs.mapTr(f, y :: ys ++ (f(x) :: Nil))\\n\\n2. Apply the definition of list concatenation (ConsAppend) to the right-hand side:\\n   - xs.mapTr(f, y :: ys ++ (f(x) :: Nil)) === xs.mapTr(f, y :: (ys ++ (f(x) :: Nil)))\\n\\n3. Apply the induction hypothesis (AccOut) with xs, f, y, and ys as arguments:\\n   - xs.mapTr(f, y :: (ys ++ (f(x) :: Nil))) === y :: xs.mapTr(f, ys ++ (f(x) :: Nil))\\n\\nTherefore, the exact sequence of lemmas to apply to rewrite the left-hand side to the right-hand side is as follows:\\nMapTrCons, ConsAppend, AccOut.'}, {'course_id': 15118, 'question_id': 6918, 'question': \"When you're running and you need to stop all of a sudden, where does the force stopping you come from?\\n\\n\", 'question_options': None, 'A_chat_id': 92775, 'B_chat_id': 92776, 'A': 'When you need to stop all of a sudden while running, the force stopping you comes from the friction between your feet and the ground. As you decelerate, the force of friction between your shoes and the ground acts in the opposite direction of your motion, helping to bring you to a stop. This force of friction converts your kinetic energy into heat and work, ultimately allowing you to come to a halt.', 'B': \"When you need to stop suddenly while running, the force that stops you comes from a combination of factors:\\n\\n1. **Friction**: The primary force that stops you is friction between your feet and the ground. As you apply a braking force by pushing your feet backward against the ground, the friction between your shoes and the ground helps to slow you down.\\n\\n2. **Muscular force**: Your muscles also play a significant role in stopping your body's forward motion. When you decide to stop, your leg muscles contract to generate the force needed to slow down and eventually come to a stop.\\n\\n3. **Inertia**: Inertia is the tendency of an object to resist changes in its motion. When you stop suddenly, your body's inertia is also a factor that needs to be overcome by the force exerted by your muscles and the friction with the ground.\\n\\nOverall, the force that stops you when running comes from a combination of friction, muscular force, and overcoming your body's inertia.\"}, {'course_id': 15103, 'question_id': 1703, 'question': \"Assume that you are part of a team developing a mobile app using Scrum.\\nWhen using the app, you identified multiple bugs and features which you think should be implemented, and took some notes. You want to\\nshare these with the Product Owner. Your backlog of tasks includes the following task:\\n- [ ] [Bug] The landing page doesn't render well, if the language of my device is not English.\\nIs this item suitable to be submitted to the Product Backlog? Why?\", 'question_options': None, 'A_chat_id': 92777, 'B_chat_id': 92778, 'A': 'Yes, this item is suitable to be submitted to the Product Backlog. The Product Backlog is a list of all desired work on the project, and includes bugs, new features, improvements, and other tasks. Identifying a bug in the landing page that affects the user experience is important for the Product Owner to be aware of and prioritize for fixing. By adding it to the Product Backlog, the team can track and address this issue in future sprints.', 'B': 'Yes, the item \"The landing page doesn\\'t render well if the language of my device is not English\" is suitable to be submitted to the Product Backlog. \\n\\nIn Scrum, the Product Backlog is a prioritized list of all the work to be done on the project. It contains all features, bugs, improvements, and any other tasks that need to be addressed. The purpose of the Product Backlog is to ensure transparency and provide a clear understanding of the work that needs to be done.\\n\\nSince the item you mentioned is a bug that affects the functionality of the app, it is important to have it recorded in the Product Backlog so that it can be prioritized, estimated, and eventually worked on by the development team. This will allow the Product Owner to understand the issues that users are facing and prioritize them accordingly.'}, {'course_id': 9, 'question_id': 6839, 'question': 'Which of the following is equivalent to \\\\((10001)_2\\\\) ? (Multiple answers can be correct)', 'question_options': ['\\\\(  (17)_{10}  \\\\)', '\\\\(  (F0)_{16}  \\\\)', '\\\\(  (23)_{8}  \\\\)', '\\\\(  (101)_{4}  \\\\)'], 'A_chat_id': 92779, 'B_chat_id': 92780, 'A': '[ ] \\\\(  (17)_{10}  \\\\)\\n[ ] \\\\(  (F0)_{16}  \\\\)\\n[x] \\\\(  (23)_{8}  \\\\)\\n[ ] \\\\(  (101)_{4}  \\\\)\\n\\nTo convert \\\\( (10001)_2 \\\\) to base 10, we can use the formula \\\\( \\\\sum_{i=0}^{n} d_i \\\\times 2^i \\\\), where \\\\( d_i \\\\) is the digit at position i. This gives us \\\\( 1 \\\\times 2^4 + 0 \\\\times 2^3 + 0 \\\\times 2^2 + 0 \\\\times 2^1 + 1 \\\\times 2^0 = 16 + 1 = 17 \\\\).\\n\\nTo convert \\\\( (10001)_2 \\\\) to base 8, we can group the binary digits into groups of 3 (starting from the right) and convert each group to base 8. This gives us \\\\( (23)_8 \\\\).\\n\\nTo convert \\\\( (10001)_2 \\\\) to base 4, we can group the binary digits into groups of 2 (starting from the right) and convert each group to base 4. This gives us \\\\( (101)_4 \\\\).', 'B': 'To convert the binary number \\\\((10001)_2\\\\) to decimal, we can use the positional notation of the binary system. \\n\\n\\\\((10001)_2 = 1*2^4 + 0*2^3 + 0*2^2 + 0*2^1 + 1*2^0 = 16 + 1 = 17\\\\)\\n\\nSo, the decimal equivalent of \\\\((10001)_2\\\\) is \\\\( (17)_{10} \\\\).\\n\\nTherefore, the correct answer is:\\n[ ] \\\\(  (17)_{10}  \\\\)'}, {'course_id': 0, 'question_id': 5954, 'question': 'How many different simple substitution ciphers do exist with respect to an alphabet of 26 characters?', 'question_options': ['$26!$', '$2^{26}$', '$26^2$', '26'], 'A_chat_id': 92781, 'B_chat_id': 92782, 'A': 'There are $26!$ different simple substitution ciphers that exist with respect to an alphabet of 26 characters. This is because each letter in the alphabet can be replaced by any of the other 25 letters, and there are 26 letters in total.', 'B': 'To create a simple substitution cipher, we need to assign each letter in the alphabet a unique corresponding letter. Since there are 26 letters in the alphabet, the first letter can be assigned to any of the 26 letters, the second letter can be assigned to any of the remaining 25 letters, and so on.\\n\\nTherefore, the total number of different simple substitution ciphers that can be created with respect to an alphabet of 26 characters is $26!$, which is the total number of permutations of 26 distinct objects.\\n\\nSo, the correct answer is:\\n[ ] $26!$'}, {'course_id': 0, 'question_id': 6073, 'question': 'In a challenge/response protocol,\\\\dots', 'question_options': ['the secret is sent in clear over the channel.', 'the response is derived using a pseudo-random function.', 'the response is a hash of the secret (i.e., $h(w)$ for a secret $w$).', 'the size of the challenge space can be 1.'], 'A_chat_id': 92783, 'B_chat_id': 92784, 'A': 'In a challenge/response protocol, the response is derived using a pseudo-random function.', 'B': '- [ ] the secret is sent in clear over the channel.\\n- [x] the response is derived using a pseudo-random function.\\n- [ ] the response is a hash of the secret (i.e., $h(w)$ for a secret $w$).\\n- [ ] the size of the challenge space can be 1.\\n\\nIn a challenge/response protocol, the response is typically derived using a pseudo-random function. This ensures that the response cannot be easily predicted or forged by an attacker, even if they know the challenge and the protocol details. Sending the secret in clear over the channel is not recommended for security reasons, and having a challenge space of size 1 would not provide much variability or security in the protocol.'}, {'course_id': 15000, 'question_id': 0, 'question': 'Consider the following contains function defined on Iterable (in particular, it accepts both Vector and List).  def contains[A](l: Iterable[A], elem: A): Boolean =   val n = l.size   if n <= 5 then     for i <- l do       if i == elem then         return true     false   else     val (p0, p1) = parallel(       contains(l.take(n / 2), elem),       contains(l.drop(n / 2), elem)     )   p0 || p1 Let $n$$n$ be the size of l. Assume that drop and take run in $\\\\Theta(1)$ on Vector and $\\\\Theta(n)$ on List. What is the asymptotic depth of contains if it is called on a List?', 'question_options': None, 'A_chat_id': 92785, 'B_chat_id': 92786, 'A': 'The asymptotic depth of the contains function when called on a List is O(log n), where n is the size of the list. This is because the function recursively splits the list into halves and searches for the element in each half, effectively reducing the search space by half in each recursive call. Since each split operation takes O(n) time on a List, the depth of the recursion tree will be logarithmic in the size of the list.', 'B': \"To determine the asymptotic depth of the `contains` function when called on a List, let's analyze the recursive structure and depth of the function.\\n\\nGiven that `drop` and `take` run in $\\\\Theta(n)$ on a List, the `contains` function splits the List in half at each recursive step, leading to a binary tree structure.\\n\\nAt each depth of the recursive tree, the size of the List is halved. Therefore, the depth of the recursive tree is $\\\\log_2(n)$, where $n$ is the size of the List.\\n\\nSince the function performs a parallel recursive call at each level of the tree, the asymptotic depth of the `contains` function when called on a List is $\\\\Theta(\\\\log(n))$.\\n\\nTherefore, the asymptotic depth of the `contains` function when called on a List is logarithmic, specifically $\\\\Theta(\\\\log(n))$.\"}, {'course_id': 15118, 'question_id': 6958, 'question': \"A yoyo is made up of a disk of radius $R$ and mass $M$, around which a massless thread is wound up. The thread is attached to the ceiling and remains constantly vertical; gravity acts on the yo-yo which is free to lower down.\\n\\nFind the acceleration $\\\\vec{a}$ of the yo-yo's center of mass, as well as the thread's tension $\\\\vec{T}$.\\n\", 'question_options': None, 'A_chat_id': 92787, 'B_chat_id': 92788, 'A': \"Let's denote the tension in the string as $T$ and the acceleration of the yo-yo's center of mass as $a$. The forces acting on the yo-yo are the tension in the string $T$, the gravitational force $mg$, and the normal force $N$ from the ceiling.\\n\\nThe net force acting on the yo-yo in the vertical direction is given by $T - mg = Ma$, where $M$ is the mass of the yo-yo.\\n\\nSince the yo-yo is not accelerating horizontally, the net force in the horizontal direction is zero.\\n\\nThe tension in the string is providing the centripetal force required to keep the yo-yo in a circular motion. This force is given by $T = \\\\frac{Mv^2}{R}$, where $v$ is the linear velocity of the yo-yo.\\n\\nCombining the equations, we get $T - mg = Ma$ and $T = \\\\frac{Mv^2}{R}$.\\n\\nSolving these equations simultaneously, we can find the acceleration $a$ of the yo-yo's center of mass and the tension $T$ in the string.\", 'B': \"To solve this problem, we can consider the forces acting on the yo-yo. The forces acting on the yo-yo are the tension force $\\\\vec{T}$ of the thread and the force of gravity $\\\\vec{F}_g = -Mg\\\\hat{j}$, where $g$ is the acceleration due to gravity and $\\\\hat{j}$ is the unit vector in the vertical direction.\\n\\nThe acceleration of the yo-yo's center of mass can be found using Newton's second law:\\n\\n$$\\\\sum \\\\vec{F} = M\\\\vec{a}$$\\n\\nThe forces acting in the vertical direction are the tension force $\\\\vec{T}$ and the force of gravity $\\\\vec{F}_g$. Since the yo-yo is free to lower down, the acceleration will be in the downward direction, so we can write the equation as:\\n\\n$$\\\\vec{T} + \\\\vec{F}_g = M\\\\vec{a}$$\\n\\nBreaking this equation into its components, we get:\\n\\n$$T - Mg = Ma$$\\n\\nSolving for the acceleration $a$, we get:\\n\\n$$a = \\\\frac{T - Mg}{M}$$\\n\\nTo find the tension in the thread, we can use the rotational dynamics of the yo-yo. The torque due to the tension in the thread will cause the yo-yo to rotate. The torque $\\\\tau$ is given by:\\n\\n$$\\\\tau = I\\\\alpha$$\\n\\nwhere $I$ is the moment of inertia of the yo-yo and $\\\\alpha$ is the angular acceleration. For a disk rotating about its center, the moment of inertia is $I = \\\\frac{1}{2}MR^2$.\\n\\nThe torque causing the rotation is due to the tension in the thread and can be written as:\\n\\n$$\\\\tau = TR$$\\n\\nThe angular acceleration $\\\\alpha$ is related to the linear acceleration $a$ by $\\\\alpha = \\\\frac{a}{R}$. Substituting these into the torque equation, we get:\\n\\n$$TR = \\\\frac{1}{2}MR^2 \\\\frac{a}{R}$$\\n\\nSolving for the tension $T$, we get:\\n\\n$$T = \\\\frac{1}{2}Ma + Mg$$\\n\\nSubstitute the expression for acceleration $a$ we found earlier, we get:\\n\\n$$T = \\\\frac{3}{2}Mg$$\\n\\nTherefore, the acceleration of the yo-yo's center of mass is $a = \\\\frac{1}{2}g$ and the tension in the thread is $T = \\\\frac{3}{2}Mg$.\"}, {'course_id': 15127, 'question_id': 1192, 'question': \"Recall that we say that a kernel $K: \\\\R \\times \\\\R \\rightarrow \\\\R $ is valid if there exists $k \\\\in \\\\mathbb{N}$ and $\\\\Phi: \\\\R \\rightarrow \\\\R^k$ such that for all $(x, x') \\\\in \\\\R \\times \\\\R $, $K(x, x') =  \\\\Phi(x)^\\top \\\\Phi(x')$. The kernel $K(x, x') = \\\\cos(x + x')$ is a valid kernel.\", 'question_options': ['True', 'False'], 'A_chat_id': 92789, 'B_chat_id': 92791, 'A': \"False. The kernel $K(x, x') = \\\\cos(x + x')$ is not a valid kernel because it does not satisfy Mercer's condition for positive definiteness.\", 'B': \"To show that the kernel $K(x, x') = \\\\cos(x + x')$ is a valid kernel, we need to find an integer $k$ and a feature map $\\\\Phi: \\\\R \\\\rightarrow \\\\R^k$ such that for all $(x, x') \\\\in \\\\R \\\\times \\\\R$, we have $K(x, x') = \\\\Phi(x)^T \\\\Phi(x')$.\\n\\nLet's try to express $K(x, x') = \\\\cos(x + x')$ in terms of an inner product. We know that $\\\\cos(\\\\theta) = \\\\frac{1}{2} (e^{i\\\\theta} + e^{-i\\\\theta})$.\\n\\nTherefore, we can write:\\n$$\\nK(x, x') = \\\\cos(x + x') = \\\\frac{1}{2} (e^{i(x + x')} + e^{-i(x + x')})\\n$$\\n\\nNow, let's define the feature map $\\\\Phi: \\\\R \\\\rightarrow \\\\R^2$ as follows:\\n$$\\n\\\\Phi(x) = \\\\begin{bmatrix} \\\\cos(x) \\\\\\\\ \\\\sin(x) \\\\end{bmatrix}\\n$$\\n\\nThen, we have:\\n$$\\n\\\\Phi(x)^T \\\\Phi(x') = \\\\begin{bmatrix} \\\\cos(x) & \\\\sin(x) \\\\end{bmatrix} \\\\begin{bmatrix} \\\\cos(x') \\\\\\\\ \\\\sin(x') \\\\end{bmatrix} = \\\\cos(x)\\\\cos(x') + \\\\sin(x)\\\\sin(x') = \\\\cos(x - x')\\n$$\\n\\nTherefore, by setting $k = 2$ and using the feature map $\\\\Phi(x) = \\\\begin{bmatrix} \\\\cos(x) \\\\\\\\ \\\\sin(x) \\\\end{bmatrix}$, we can express $K(x, x') = \\\\cos(x + x')$ as an inner product of the feature map, which means that $K(x, x') = \\\\cos(x + x')$ is a valid kernel.\\n\\nSo, the statement is:\\n[ ] True\\n[✔] False\"}, {'course_id': 15003, 'question_id': 7337, 'question': 'If process i fails, then eventually all processes j≠i fail\\nIs the following true? If no process j≠i fails, then process i has not failed', 'question_options': None, 'A_chat_id': 92792, 'B_chat_id': 92793, 'A': 'No, the statement is not necessarily true. Just because all processes j≠i have not failed does not guarantee that process i has not failed. Process i could have failed for reasons unrelated to the other processes failing. The failure of process i could be due to hardware issues, software bugs, or other factors.', 'B': 'No, the statement is not necessarily true. The given statement is: \"If process i fails, then eventually all processes j≠i fail.\" This means that if process i fails, then all other processes will eventually fail as well.\\n\\nThe second part of the statement is: \"If no process j≠i fails, then process i has not failed.\" This does not necessarily follow from the first part. It is possible for process i to fail even if no other process has failed. The failure of process i could be due to reasons specific to that process, unrelated to the failures of other processes.\\n\\nTherefore, the second part of the statement does not logically follow from the first part.'}, {'course_id': 15002, 'question_id': 4935, 'question': 'Consider using a parser with the following (partial) grammar:\\nS -> NP VP \\nVP -> V\\nNP -> Det N\\nVP -> VP PP\\nNP -> N\\nVP -> VBP VBG PP\\nNP -> NP PP\\nPP -> P NP\\nand (also partial) lexicon:\\n2012 N\\nfrom P\\nSwitzerland N\\nin P\\nUSA N \\nincreasing VBG\\nare VBP \\nthe Det\\nexports N \\nto P\\nexports V\\nUsing the CYK algorithm, parse the following sentence with the above lexicon/grammar:\\nthe exports from the USA to Switzerland are increasing in 2012\\nProvide both the complete, fully filled, data structure used by the algorithm, as well as the result of\\nthe parsing in the form of a/the parse tree(s).', 'question_options': None, 'A_chat_id': 92794, 'B_chat_id': 92795, 'A': 'Here is the complete data structure used by the CYK algorithm for parsing the given sentence:\\n\\n|   | 1         | 2        | 3       | 4       | 5        | 6      | 7     | 8        |\\n|---|-----------|----------|---------|---------|----------|--------|-------|----------|\\n| 1 | NP(the)   |          |         |         |          |        |       |          |\\n| 2 |           | NP(exports) |       |         |          |        |       |          |\\n| 3 |           |          | P(from) |         |          |        |       |          |\\n| 4 |           |          |         | NP(the) |          |        |       |          |\\n| 5 |           |          |         |         | N(USA)   |        |       |          |\\n| 6 |           |          |         |         |          | P(to) |       |          |\\n| 7 |           |          |         |         |          |        | NP(Switzerland) | |\\n| 8 |           |          |         |         |          |        |       | VBP(are) |\\n\\nAnd here is the parse tree for the given sentence:\\n\\n```\\n         S\\n    |---------|\\n   NP        VP\\n    |         |\\n  Det         VBP\\n    |         |\\n  the        are\\n    |         |\\n  exports    VP\\n    |         |\\n    NP       PP\\n    |      /  |  \\\\\\n exports  to  NP  |\\n          |   |   |\\n         USA  |  PP\\n              |  |\\n         Switzerland\\n```', 'B': 'To parse the sentence \"the exports from the USA to Switzerland are increasing in 2012\" using the CYK algorithm with the given grammar and lexicon, we need to create a chart and fill it according to the algorithm.\\n\\nHere is the completed chart:\\n\\n|    | 1       | 2    | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 |\\n|----|---------|------|---|---|---|---|---|---|---|----|----|\\n| 1  | Det     | N    | P | N | P | N | V |    |    |    |    |\\n| 2  |         |      |   |   |   |   |   |    |    |    |    |\\n| 3  |         |      |   |   |   |   |   |    |    |    |    |\\n| 4  |         |      |   |   |   |   |   |    |    |    |    |\\n| 5  |         |      |   |   |   |   |   |    |    |    |    |\\n| 6  |         |      |   |   |   |   |   |    |    |    |    |\\n| 7  |         |      |   |   |   |   |   |    |    |    |    |\\n| 8  |         |      |   |   |   |   |   |    |    |    |    |\\n| 9  |         |      |   |   |   |   |   |    |    |    |    |\\n| 10 |         |      |   |   |   |   |   |    |    |    |    |\\n| 11 |         |      |   |   |   |   |   |    |    |    |    |\\n\\nNow, let\\'s fill in the chart based on the grammar rules and lexicon:\\n\\n1. Det -> the\\n2. N -> exports\\n3. P -> from\\n4. N -> USA\\n5. P -> to\\n6. N -> Switzerland\\n7. V -> are\\n8. VBG -> increasing\\n9. P -> in\\n10. N -> 2012\\n\\nNow, we can fill in the corresponding cells in the chart:\\n\\n|    | 1       | 2    | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 |\\n|----|---------|------|---|---|---|---|---|---|---|----|----|\\n| 1  | Det     | N    | P | N | P | N | V |    |    |    |    |\\n| 2  |         |      | NP |    |    |    |    |    |    |    |    |\\n| 3  |         |      |    |    |    |    |    |    |    |    |    |\\n| 4  |         |      |    | NP |    |    |    |    |'}, {'course_id': 15008, 'question_id': 2758, 'question': 'Considering the set of triangles previously calculated, estimate the fraction of triangles of configurations  {+,+,+}\\n ,  {−,−,−}\\n ,  {+,+,−}\\n , and  {+,−,−}\\n . What fraction of triangles are \"balanced\" according to structural balance theory?', 'question_options': None, 'A_chat_id': 92796, 'B_chat_id': 92797, 'A': 'To estimate the fraction of triangles of configurations {+,+,+}, {−,−,−}, {+,+,−}, and {+,−,−}, we need to calculate the number of triangles of each configuration and divide it by the total number of triangles.\\n\\nLet\\'s denote the total number of triangles as T. Then, we calculate the number of triangles for each configuration:\\n- {+,+,+}: Let\\'s denote the number of positive edges as P and the total number of edges as E. The number of triangles with all positive edges is P choose 3 (P3) since we need to choose 3 positive edges out of P total edges.\\n- {−,−,−}: Similarly, the number of triangles with all negative edges is (E-P) choose 3 ((E-P)3).\\n- {+,+,−}: The number of triangles with two positive edges and one negative edge is P choose 2 * (E-P) (P2 * (E-P)).\\n- {+,−,−}: The number of triangles with one positive edge and two negative edges is P * (E-P) choose 2 (P * (E-P)2).\\n\\nOnce we have calculated the number of triangles for each configuration, we can calculate the fractions by dividing by the total number of triangles T.\\n\\nAs for the fraction of triangles that are \"balanced\" according to structural balance theory, we need to consider the configurations where there are no cycles of odd length. In this case, the configurations {+,+,+} and {−,−,−} are balanced, while {+,+,−} and {+,−,−} are unbalanced. So the fraction of balanced triangles would be the sum of the fractions of triangles of configurations {+,+,+} and {−,−,−}.', 'B': 'To estimate the fraction of each type of triangle in the set, we can first count the total number of triangles and then count how many fall into each category. Let\\'s consider the following configurations:\\n\\n1. {+, +, +} - This configuration represents a balanced triangle where all three relationships are positive.\\n\\n2. {−, −, −} - This configuration also represents a balanced triangle where all three relationships are negative.\\n\\n3. {+, +, −} - This configuration represents an unbalanced triangle where two relationships are positive and one is negative.\\n\\n4. {+, −, −} - This configuration also represents an unbalanced triangle where one relationship is positive and two are negative.\\n\\nTo calculate the fraction of each type of triangle, we need to count the number of triangles in each category and then divide by the total number of triangles. Let\\'s say we have:\\n- Total number of triangles = N\\n- Number of {+, +, +} triangles = A\\n- Number of {−, −, −} triangles = B\\n- Number of {+, +, −} triangles = C\\n- Number of {+, −, −} triangles = D\\n\\nThe fraction of each type of triangle would be:\\n- Fraction of {+, +, +} triangles = A / N\\n- Fraction of {−, −, −} triangles = B / N\\n- Fraction of {+, +, −} triangles = C / N\\n- Fraction of {+, −, −} triangles = D / N\\n\\nTo determine the fraction of \"balanced\" triangles according to structural balance theory, we would add the fractions of {+, +, +} and {−, −, −} triangles, as these are the configurations that are considered balanced. This fraction would be (A + B) / N.'}, {'course_id': 15006, 'question_id': 4219, 'question': 'To which expression is the following for-loop translated? for x <- xs if x > 5; y <- ys yield x + y', 'question_options': ['xs.flatMap(x => ys.map(y => x + y)).withFilter(x => x > 5)', 'xs.withFilter(x => x > 5).map(x => ys.flatMap(y => x + y))', 'xs.withFilter(x => x > 5).flatMap(x => ys.map(y => x + y))', 'xs.map(x => ys.flatMap(y => x + y)).withFilter(x => x > 5)'], 'A_chat_id': 92798, 'B_chat_id': 92799, 'A': 'xs.withFilter(x => x > 5).flatMap(x => ys.map(y => x + y))', 'B': 'To translate the given for-loop expression `for x <- xs if x > 5; y <- ys yield x + y` into an equivalent expression using higher-order functions, we need to break it down step by step:\\n\\n1. Filter the elements in `xs` where `x > 5`.\\n2. For each filtered element `x`, generate a new sequence by combining it with each element in `ys` using the operation `x + y`.\\n\\nBased on this breakdown, the correct translation of the for-loop expression would be:\\n[ ] xs.withFilter(x => x > 5).flatMap(x => ys.map(y => x + y))\\n\\nThis expression first filters the elements in `xs` where `x > 5` using `withFilter`, and then for each filtered element `x`, it generates a new sequence by combining it with each element in `ys` using `flatMap`.'}, {'course_id': 15125, 'question_id': 3649, 'question': '10 itemsets out of 100 contain item A, of which 5 also contain B. The rule B -> A has:', 'question_options': ['unknown support and 50% confidence', 'unknown support and unknown confidence', '5% support and 50% confidence', '5% support and unknown confidence'], 'A_chat_id': 92800, 'B_chat_id': 92801, 'A': '5% support and 50% confidence. \\n\\nSupport is the proportion of transactions that contain both A and B, which is 5%. Confidence is the proportion of transactions containing B that also contain A, which is 50%.', 'B': 'To determine the support and confidence of the rule B -> A, we need to first calculate the support and confidence values.\\n\\nGiven:\\n- 10 itemsets out of 100 contain item A\\n- 5 out of these 10 itemsets also contain item B\\n\\nSupport is the proportion of transactions that contain both items A and B:\\nSupport(B -> A) = P(A and B) = Number of itemsets containing both A and B / Total number of itemsets\\nSupport(B -> A) = 5 / 100 = 0.05 or 5%\\n\\nConfidence is the likelihood of item A being bought when item B is bought:\\nConfidence(B -> A) = P(A|B) = P(A and B) / P(B)\\nConfidence(B -> A) = Support(B -> A) / Support(B) = 5% / (Number of itemsets containing B / Total number of itemsets)\\nConfidence(B -> A) = 5% / (10 / 100) = 5% / 10% = 50%\\n\\nTherefore, the rule B -> A has 5% support and 50% confidence. \\n\\nSo, the correct answer is: [ ] 5% support and 50% confidence.'}, {'course_id': 15113, 'question_id': 7076, 'question': 'We consider a ball of mass $m$ sliding without friction in a ring of radius $R$. The ring itself is rotating around the vertical axis passing through its centre $O$ with a constant angular speed $\\\\boldsymbol{\\\\omega}$ with respect to the frame of reference of the laboratory. We suppose that the ball can be considered as a material point.\\n\\nDetermine the equilibrium positions $0\\\\leq\\\\theta_1<\\\\theta_2\\\\leq\\\\frac{\\\\pi}{2}$ of the ball with respect to the ring and the minimal angular speed $\\\\omega_{\\\\,\\\\text{min}}$ for which the equilibrium position $\\\\theta_2$ exists.\\n\\n', 'question_options': None, 'A_chat_id': 92803, 'B_chat_id': 92804, 'A': 'Since the ball is sliding without friction, the only forces acting on it are the gravitational force and the centrifugal force due to the rotation of the ring.\\n\\nThe gravitational force acting on the ball is $m\\\\boldsymbol{g}$, where $\\\\boldsymbol{g}$ is the acceleration due to gravity directed vertically downward.\\n\\nThe centrifugal force acting on the ball is $mR\\\\omega^2$, directed radially outward.\\n\\nAt equilibrium, the net force acting on the ball must be zero. This gives us the equation:\\n\\n$$m\\\\boldsymbol{g} + mR\\\\omega^2 = m\\\\boldsymbol{a}$$\\n\\nwhere $\\\\boldsymbol{a}$ is the acceleration of the ball along the ring.\\n\\nSince the ball is at equilibrium, the acceleration $\\\\boldsymbol{a}$ is zero. Therefore, we have:\\n\\n$$m\\\\boldsymbol{g} + mR\\\\omega^2 = 0$$\\n\\nSolving for $\\\\omega$:\\n\\n$$\\\\omega^2 = \\\\frac{g}{R}$$\\n\\nTaking the square root of both sides, we get:\\n\\n$$\\\\omega = \\\\sqrt{\\\\frac{g}{R}}$$\\n\\nThis is the minimum angular speed $\\\\omega_{\\\\,\\\\text{min}}$ for which the equilibrium position $\\\\theta_2$ exists.\\n\\nThe equilibrium positions $\\\\theta_1$ and $\\\\theta_2$ of the ball with respect to the ring can be found by considering the forces along the radial direction. At positions $\\\\theta_1$ and $\\\\theta_2$, the centrifugal force and the gravitational force balance each other out, leading to:\\n\\nAt $\\\\theta_1$:\\n\\n$$m\\\\boldsymbol{g}\\\\cos(\\\\theta_1) + mR\\\\omega^2 = 0$$\\n\\nAt $\\\\theta_2$:\\n\\n$$m\\\\boldsymbol{g}\\\\cos(\\\\theta_2) + mR\\\\omega^2 = 0$$\\n\\nSolving these equations for $\\\\theta_1$ and $\\\\theta_2$ will give the equilibrium positions of the ball with respect to the ring.', 'B': \"To find the equilibrium positions $\\\\theta_1$ and $\\\\theta_2$, we can start by considering the forces acting on the ball in the rotating frame of reference. In this frame, we have two forces acting on the ball: the gravitational force and the centrifugal force due to the rotation of the ring.\\n\\n1. **Gravitational Force**: The gravitational force acting on the ball is directed downward and has a magnitude of $mg$, where $g$ is the acceleration due to gravity.\\n\\n2. **Centrifugal Force**: The centrifugal force experienced by the ball in the rotating frame is directed outward and has a magnitude of $m R \\\\omega^2$, where $\\\\omega$ is the angular speed of the ring.\\n\\nFor the ball to be in equilibrium, the net force acting on it in the rotating frame must be directed towards the center of the ring. This means that the centrifugal force must balance the gravitational force. Therefore, we have:\\n\\n\\\\[\\nm R \\\\omega^2 = mg\\n\\\\]\\n\\nFrom this equation, we can solve for the minimum angular speed $\\\\omega_{\\\\,\\\\text{min}}$ required for the equilibrium position $\\\\theta_2$ to exist.\\n\\nNext, we need to determine the equilibrium positions $\\\\theta_1$ and $\\\\theta_2$ of the ball with respect to the ring. To do this, we can consider the forces acting on the ball in the radial direction when it is at these equilibrium positions.\\n\\nAt position $\\\\theta_1$, the centrifugal force and the gravitational force act in opposite directions. At position $\\\\theta_2$, the centrifugal force and the gravitational force act in the same direction.\\n\\nBy analyzing the forces at these equilibrium positions, we can find the values of $\\\\theta_1$ and $\\\\theta_2$.\\n\\nLet's start by finding the minimum angular speed $\\\\omega_{\\\\,\\\\text{min}}$.\"}, {'course_id': 15125, 'question_id': 1429, 'question': 'TransE is known to have difficulties in representing symmetric relationships r. Which of the following statements is correct for a symmetric relationship and provides insight for this problem?', 'question_options': ['For all e1 , e2: \\\\( f(e_1, r, e_2) = f(e_2, r, e_1)  \\\\)', 'For all e1 , e2: \\\\( f(e_1, r, e_2) = -f(e_2, r, e_1) \\\\)', '\\\\( \\\\Sigma_{ e_1, e_2} f(e_1, r, e_2) + f(e_2, r, e_1) \\\\)\\xa0is minimized if the embedding vector of r is large', '\\\\( \\\\Sigma_{ e_1, e_2} f(e_1, r, e_2) + f(e_2, r, e_1) \\\\) is minimized if the embedding vectors of e1and e2 are close to each other'], 'A_chat_id': 92805, 'B_chat_id': 92806, 'A': 'The correct statement is: For all e1 , e2: \\\\( f(e_1, r, e_2) = f(e_2, r, e_1) \\\\). This statement indicates that for a symmetric relationship, the embedding of entities e1 and e2 with respect to the relationship r should be the same regardless of the order in which they are considered. This property is important for capturing symmetric relationships accurately in knowledge graph embeddings.', 'B': \"The correct statement for a symmetric relationship and its implications for TransE is:\\n\\n[ ] For all e1 , e2: \\\\( f(e_1, r, e_2) = f(e_2, r, e_1) \\\\)\\n\\nFor a symmetric relationship, the embeddings should be the same regardless of the order of the entities. In other words, the score function should return the same value for \\\\( f(e_1, r, e_2) \\\\) and \\\\( f(e_2, r, e_1) \\\\). This property is not directly captured by TransE's scoring function, leading to difficulties in representing symmetric relationships effectively.\"}, {'course_id': 15127, 'question_id': 3910, 'question': '(Nearest Neighbor) The training error of the 1-nearest neighbor classifier is zero.', 'question_options': ['True', 'False'], 'A_chat_id': 92808, 'B_chat_id': 92809, 'A': 'False. The training error of the 1-nearest neighbor classifier will not necessarily be zero, as it simply assigns the label of the nearest training data point to the query point. If there are multiple instances of the same data point with different labels in the training set, the classifier may still make errors on those instances.', 'B': 'True.\\n\\nExplanation: In a 1-nearest neighbor classifier, the training error is typically zero because the classifier simply memorizes the training data and assigns the label of the nearest neighbor in the training set to any new data point. This means that the classifier will always predict the correct label for the data points in the training set, resulting in a training error of zero.'}, {'course_id': 15118, 'question_id': 6912, 'question': \"A car drives over a very bumpy road (see diagram). We model the car as a material point of mass $m$, riding at constant horizontal speed $v_x$. The material point is attached to a spring with spring constant $k$ and rest length $l_0$. At the other end of the spring is a massless wheel, with negligible radius, that's following the curves of the bumpy road.\\n\\n\\nThe spring remains upright at all times; we'll ignore how it does so, and assume that it has no influence on the motion of the material point.\\nThe parameters of the problem are such that the wheel never lifts from the road and that the car never hits the wheel. \\nThe road's profile follows a sinusoidal shape. The bumps have height $H$ and length $L$.\\nExpress the vertical position of the wheel $h(t)$ as a function of time.\\n\", 'question_options': None, 'A_chat_id': 92810, 'B_chat_id': 92811, 'A': \"Let's consider the equilibrium position of the system when the spring is at rest, meaning that the spring force balances the gravitational force acting on the mass $m$. At this point, the spring is compressed by a distance $l_0$ due to the weight of the mass $m$.\\n\\nWhen the car drives over a bump, the spring will compress or extend depending on the height of the bump. Let's denote the vertical displacement of the wheel from the equilibrium position as $h(t)$.\\n\\nAt any given time $t$, the total force acting on the mass $m$ is the sum of the gravitational force, the spring force, and the normal force from the road. The normal force will vary as the wheel goes over the bumps, but it will always be perpendicular to the road surface.\\n\\nThe equation of motion for the mass $m$ in the vertical direction can be written as:\\n\\n$m\\\\ddot{h} = -mg + k(l_0 + h) - N$\\n\\nWhere $N$ is the normal force from the road surface. Since the wheel never lifts off the road, the normal force will always be present to counteract the gravitational force.\\n\\nTo simplify the problem, we can assume that the normal force is always equal to the gravitational force, i.e., $N = mg$.\\n\\nTherefore, the equation of motion becomes:\\n\\n$m\\\\ddot{h} = -mg + k(l_0 + h) - mg$\\n\\nSolving this differential equation will give us the vertical position of the wheel $h(t)$ as a function of time. The solution will be a sinusoidal function that oscillates around the equilibrium position $h = 0$.\", 'B': \"Let's analyze the situation step by step:\\n\\n1. The equilibrium position of the wheel is at a height $h_0 = -l_0$ (below the material point at rest position). This is because the spring has a rest length of $l_0$.\\n\\n2. As the car moves over the bumps, the spring will be compressed or extended, leading to a change in the vertical position of the wheel.\\n\\n3. Let's define the amplitude of the sinusoidal road profile as $A = H/2$, where $H$ is the height of the bumps. The equation for the road profile is then $h_{\\\\text{road}}(x) = A\\\\sin(2\\\\pi x/L)$, where $x$ is the horizontal position of the car.\\n\\n4. The vertical position of the wheel, $h(t)$, can be written as $h(t) = h_{\\\\text{road}}(x) + h_{\\\\text{spring}}(t)$, where $h_{\\\\text{spring}}(t)$ is the vertical displacement of the spring due to the motion of the car.\\n\\n5. The vertical displacement of the spring, $h_{\\\\text{spring}}(t)$, is related to the compression or extension of the spring. This can be calculated using Hooke's Law: $F = kx$, where $F$ is the force exerted by the spring, $k$ is the spring constant, and $x$ is the displacement from the equilibrium position.\\n\\n6. The total force acting on the material point is the sum of the gravitational force and the spring force: $mg = k(h_{\\\\text{spring}} - l_0)$, where $m$ is the mass of the material point, $g$ is the acceleration due to gravity, and $l_0$ is the rest length of the spring.\\n\\n7. Solving the above equation for $h_{\\\\text{spring}}$, we get $h_{\\\\text{spring}}(t) = \\\\frac{mg}{k} + l_0$.\\n\\n8. Substituting $h_{\\\\text{spring}}(t)$ into the expression for $h(t)$, we get:\\n$$\\nh(t) = A\\\\sin\\\\left(\\\\frac{2\\\\pi v_xt}{L}\\\\right) + \\\\frac{mg}{k} + l_0\\n$$\\n\\nTherefore, the vertical position of the wheel as a function of time is given by:\\n$$\\nh(t) = A\\\\sin\\\\left(\\\\frac{2\\\\pi v_xt}{L}\\\\right) + \\\\frac{mg}{k} + l_0\\n$$\"}, {'course_id': 15116, 'question_id': 7237, 'question': 'Two disks A and B of radius R, aligned, can rotate around a vertical axis $z$ inside a container filled with a fluid of viscosity $\\\\eta$. The distances between A and B and between A and the bottom of the container are equal to $d$. The disk B rotates at constant angular velocity $\\\\omega_0~\\\\vec{e}_z$.\\nAt $t=0$ the angular velocity of A is $\\\\omega=0$.\\n\\nWhat is the temporal dependency of $\\\\omega$?\\n', 'question_options': None, 'A_chat_id': 92813, 'B_chat_id': 92814, 'A': \"The torque acting on disk A is due to the viscous force exerted by the fluid. This torque can be expressed as $\\\\tau = -\\\\eta \\\\cdot A \\\\cdot \\\\omega$, where $A$ is the area of the disk and $\\\\omega$ is the angular velocity of disk A. The negative sign indicates that the torque opposes the motion.\\n\\nThe moment of inertia of disk A is $I = \\\\frac{1}{2}mR^2$, where $m$ is the mass of the disk and $R$ is the radius.\\n\\nApplying Newton's second law for rotation, $\\\\tau = I \\\\cdot \\\\frac{d\\\\omega}{dt}$, we can write $-\\\\eta \\\\cdot A \\\\cdot \\\\omega = \\\\frac{1}{2}mR^2 \\\\cdot \\\\frac{d\\\\omega}{dt}$.\\n\\nSolving this differential equation, we get $\\\\omega(t) = \\\\omega_0 \\\\cdot e^{-\\\\frac{2\\\\eta At}{mR^2}}$.\\n\\nTherefore, the temporal dependency of $\\\\omega$ is exponential decay.\", 'B': 'To determine the temporal dependency of the angular velocity $\\\\omega$ of disk A, we can analyze the torque acting on disk A. The torque on disk A is due to the fluid viscosity and the interaction with disk B.\\n\\nThe torque on disk A can be written as:\\n\\n$$\\\\tau = I \\\\frac{d\\\\omega}{dt}$$\\n\\nwhere $I$ is the moment of inertia of disk A about the axis of rotation. Since disk A is rotating around a vertical axis, the moment of inertia can be calculated as $I = \\\\frac{1}{2}mR^2$, where $m$ is the mass of disk A.\\n\\nThe torque is given by the sum of the torques due to the fluid viscosity and the interaction with disk B:\\n\\n$$\\\\tau = \\\\tau_{\\\\text{viscosity}} + \\\\tau_{\\\\text{interaction}}$$\\n\\nThe torque due to fluid viscosity can be calculated using the formula for viscous drag on a rotating disk:\\n\\n$$\\\\tau_{\\\\text{viscosity}} = -\\\\eta \\\\omega R^2$$\\n\\nThe torque due to the interaction with disk B can be calculated using the formula for torque due to a force acting at a distance $d$ from the axis of rotation:\\n\\n$$\\\\tau_{\\\\text{interaction}} = F \\\\cdot d = m \\\\cdot g \\\\cdot R \\\\cdot d$$\\n\\nwhere $F$ is the force due to the gravitational interaction with disk B, $m$ is the mass of disk A, $g$ is the acceleration due to gravity, and $R$ is the radius of disk A.\\n\\nSubstituting these expressions into the torque equation, we get:\\n\\n$$I \\\\frac{d\\\\omega}{dt} = -\\\\eta \\\\omega R^2 + m \\\\cdot g \\\\cdot R \\\\cdot d$$\\n\\nSubstitute the moment of inertia $I = \\\\frac{1}{2}mR^2$:\\n\\n$$\\\\frac{1}{2}mR^2 \\\\frac{d\\\\omega}{dt} = -\\\\eta \\\\omega R^2 + m \\\\cdot g \\\\cdot R \\\\cdot d$$\\n\\nSolve for $\\\\frac{d\\\\omega}{dt}$:\\n\\n$$\\\\frac{d\\\\omega}{dt} = -\\\\frac{2\\\\eta \\\\omega R}{m} + 2g \\\\cdot d$$\\n\\nThis is the differential equation for the temporal dependency of the angular velocity $\\\\omega$ of disk A. It describes how the angular velocity changes over time due to the interaction with the fluid viscosity and disk B. Solving this differential equation will give the temporal evolution of $\\\\omega$.'}, {'course_id': 15113, 'question_id': 7053, 'question': 'A missile is launched with an initial velocity $\\\\boldsymbol{v_0}$ from point $O$. At the same time, a material point is launched with no initial velocity from point $P$. \\n\\nShow that if the missile is initially launched along the line of fire $\\\\boldsymbol{OP}$, then the missile will inevitably hit the material point.\\n', 'question_options': None, 'A_chat_id': 92815, 'B_chat_id': 92816, 'A': 'Let $\\\\boldsymbol{r_1}(t)$ and $\\\\boldsymbol{r_2}(t)$ be the positions of the missile and the material point at time $t$, respectively. Since the missile is initially launched along the line of fire $\\\\boldsymbol{OP}$, we have $\\\\boldsymbol{r_1}(0) = \\\\boldsymbol{v_0}t$ and $\\\\boldsymbol{r_2}(0) = \\\\boldsymbol{0}$. \\n\\nThe distance between the missile and the material point at time $t$ is given by $||\\\\boldsymbol{r_1}(t) - \\\\boldsymbol{r_2}(t)||$. Since the missile is initially launched along the line of fire $\\\\boldsymbol{OP}$, the vector connecting the missile to the material point at time $t$ lies along the line $\\\\boldsymbol{OP}$. \\n\\nTherefore, the missile will inevitably hit the material point when $||\\\\boldsymbol{r_1}(t) - \\\\boldsymbol{r_2}(t)|| = 0$. This implies that the missile and the material point will collide at some time $t$ along the line of fire $\\\\boldsymbol{OP}$.', 'B': \"To show that the missile will inevitably hit the material point when it is initially launched along the line of fire $OP$, we can consider the motion of the missile and the material point separately.\\n\\nLet's denote the position of the missile at time $t$ as $\\\\boldsymbol{r}_m(t)$ and the position of the material point as $\\\\boldsymbol{r}_p(t)$.\\n\\nGiven that the missile is initially launched along the line of fire $OP$, we can express the initial position of the missile as:\\n$$\\\\boldsymbol{r}_m(0) = \\\\boldsymbol{v}_0t$$\\n\\nSince the material point is launched with no initial velocity from point $P$, we have:\\n$$\\\\boldsymbol{r}_p(0) = \\\\boldsymbol{0}$$\\n\\nNow, let's consider the motion of the missile. The acceleration of the missile is denoted as $\\\\boldsymbol{a}_m$. Since the missile is under the influence of gravity, we have $\\\\boldsymbol{a}_m = \\\\boldsymbol{g}$, where $\\\\boldsymbol{g}$ is the acceleration due to gravity.\\n\\nThe position of the missile at any time $t$ can be expressed as:\\n$$\\\\boldsymbol{r}_m(t) = \\\\boldsymbol{v}_0t + \\\\frac{1}{2}\\\\boldsymbol{g}t^2$$\\n\\nNext, let's consider the motion of the material point. Since it is launched with no initial velocity, the acceleration of the material point, $\\\\boldsymbol{a}_p$, is also equal to $\\\\boldsymbol{g}$.\\n\\nThe position of the material point at any time $t$ can be expressed as:\\n$$\\\\boldsymbol{r}_p(t) = \\\\frac{1}{2}\\\\boldsymbol{g}t^2$$\\n\\nNow, we want to show that the missile will hit the material point. This means that there exists a time $T$ such that $\\\\boldsymbol{r}_m(T) = \\\\boldsymbol{r}_p(T)$.\\n\\nSubstitute the expressions for $\\\\boldsymbol{r}_m(t)$ and $\\\\boldsymbol{r}_p(t)$ into the condition $\\\\boldsymbol{r}_m(T) = \\\\boldsymbol{r}_p(T)$:\\n$$\\\\boldsymbol{v}_0T + \\\\frac{1}{2}\\\\boldsymbol{g}T^2 = \\\\frac{1}{2}\\\\boldsymbol{g}T^2$$\\n\\nSimplify the equation:\\n$$\\\\boldsymbol{v}_0T = \\\\boldsymbol{0}$$\\n\\nSince $\\\\boldsymbol{v}_0 \\\\neq \\\\boldsymbol{0}$, this equation implies that $T = 0$, which means the missile and the material point will coincide at time $T = 0$. This confirms that the missile will hit the material point when it is initially launched along the line of fire $OP$.\"}, {'course_id': 5, 'question_id': 6731, 'question': 'Let  $$G= \\x08egin{pmatrix} 1 &1 &1 &0 &1 &0\\\\ 0 &1 &1 &1 &0 &0\\\\ 0 &1 &1 &0 &0 &0\\\\ 0 &1 &1 &1 &0 &1 \\\\end{pmatrix}$$ be the generator matrix of a $(6,4)$ linear code $\\\\mathcal C$ over $\\\\mathbb F_2$. True or false: $d_{min}=2$.', 'question_options': ['False', 'True'], 'A_chat_id': 92817, 'B_chat_id': 92818, 'A': 'False. The minimum distance $d_{min}$ of a linear code is the minimum Hamming weight of a non-zero codeword. In this case, the minimum Hamming weight of the non-zero codewords in $\\\\mathcal C$ is 3, not 2.', 'B': \"To find the minimum distance of the code, we need to consider the weight of all possible non-zero codewords in the code. Since this is a $(6,4)$ linear code, all non-zero codewords must have a weight of at least 2.\\n\\nLet's consider the possible non-zero codewords of weight 2:\\n\\n1. The first column of the generator matrix is a non-zero codeword of weight 1.\\n2. The second column of the generator matrix is a non-zero codeword of weight 1.\\n3. The third column of the generator matrix is a non-zero codeword of weight 1.\\n4. The fourth column of the generator matrix is a non-zero codeword of weight 1.\\n\\nTherefore, the minimum distance of the code $\\\\mathcal C$ is at least 2, which means $d_{min} \\\\geq 2$. So, the statement $d_{min}=2$ is true.\\n\\nTherefore, the correct answer is:\\n\\n[ ] True\"}, {'course_id': 0, 'question_id': 5769, 'question': 'Let $H:\\\\{0,1\\\\}^* \\\\rightarrow \\\\{0,1\\\\}^n$ be a hash function and $x_1,x_2\\\\in\\\\{0,1\\\\}^{2n}$ two random different messages. In cryptography, we usually assume that the probability of collision, i.e. $\\\\Pr[H(x_1)=H(x_2)]$, is close to \\\\ldots', 'question_options': ['$2^{-\\\\frac{n}{2}}$.', '$2^{-n}$.', '$2^{-2n}$.', '$0$.'], 'A_chat_id': 92819, 'B_chat_id': 92820, 'A': '$2^{-n}$. In cryptography, we aim for hash functions to have a very low collision probability, ideally close to $2^{-n}$ where n is the length of the output hash.', 'B': 'In cryptography, a good hash function is designed such that the probability of collision is very low. The probability of collision for a random hash function is close to $2^{-n}$, where $n$ is the length of the hash output in bits.\\n\\nTherefore, the correct answer is:\\n[ ] $2^{-n}$.'}, {'course_id': 15113, 'question_id': 7099, 'question': 'We consider the earth as a compact set of concentric spheres.\\n\\na) Use a geometric argument to show that the field vanishes inside a spherical shell. Thus, for a given point, only the spherical shell for which the point is in the exterior contributes to the field at that point.\\n', 'question_options': None, 'A_chat_id': 92821, 'B_chat_id': 92822, 'A': 'a) Inside a spherical shell, the gravitational field generated by the mass distribution outside the shell can be considered as the superposition of the fields generated by each infinitesimally thin spherical shell of mass. For any point inside the spherical shell, the gravitational field generated by all the individual infinitesimal mass elements cancels out due to symmetry. This is because for every infinitesimal mass element on one side of the point, there is an equal and opposite mass element on the other side, resulting in equal and opposite gravitational forces that cancel each other out. Therefore, the net gravitational field inside a spherical shell is zero. This implies that for a given point, only the spherical shell for which the point is in the exterior contributes to the gravitational field at that point.', 'B': 'To show that the electric field vanishes inside a spherical shell, we can use the principle of superposition. \\n\\nConsider a point inside the spherical shell. The electric field at this point is the vector sum of the electric fields due to each individual sphere making up the shell. Since the electric field due to a point charge or a spherical shell of charge is spherically symmetric, the electric fields due to all the spheres will cancel each other out inside the shell.\\n\\nThis cancellation occurs because for every point inside the shell, there exists another point on the opposite side of the shell that generates an electric field in the opposite direction. The superposition of these fields results in a net electric field of zero inside the shell.\\n\\nTherefore, only the spherical shell for which the point is in the exterior contributes to the field at that point, as the contribution from the interior spheres cancels out.'}, {'course_id': 15041, 'question_id': 2828, 'question': \"Your friend Charlie was training a neural net, and observed something very curious. During training, the same network, with the same exact weights, doesn't always give the same prediction for a given example. What can cause this behavior?\", 'question_options': ['Residual layers (skip-connections)', 'Convolutional layers', 'Batch normalization', 'SGD with momentum', 'Adam', 'Dropout', 'L1 regularization', 'L2 regularization', 'This is not possible, Charlie made a mistake'], 'A_chat_id': 92823, 'B_chat_id': 92824, 'A': 'Batch normalization can cause this behavior. Batch normalization introduces randomness during training due to the fact that it normalizes the activations of each mini-batch using the mean and variance of that mini-batch. This can lead to different predictions for the same example when the network is evaluated multiple times during training.', 'B': \"The behavior where the same network with the same exact weights doesn't always give the same prediction for a given example can be attributed to the following factors:\\n\\n- **Dropout**: Dropout is a regularization technique commonly used in neural networks to prevent overfitting. During training, random units are dropped out (i.e., set to zero) with a probability p. This can lead to different predictions for the same example since different units are dropped out in each forward pass.\\n\\n- **Batch normalization**: Batch normalization is a technique used to normalize the inputs of each layer to speed up training and improve generalization. During training, the mean and variance of the batch are used to normalize the inputs. Since the batch statistics differ in each iteration, the predictions can vary even with the same weights.\\n\\n- **SGD with momentum**: Stochastic Gradient Descent (SGD) with momentum is an optimization algorithm commonly used to train neural networks. The inclusion of momentum helps accelerate convergence and dampen oscillations. The momentum term introduces a moving average of past gradients, which can cause variations in predictions for the same example.\\n\\n- **Adam**: Adam is another popular optimization algorithm that combines the benefits of both Adagrad and RMSprop. It uses adaptive learning rates and momentum terms to optimize the training process. The adaptive nature of Adam can lead to different predictions for the same example due to the variations in learning rates.\\n\\nTherefore, the correct options that could cause the observed behavior are:\\n- [ ] Dropout\\n- [ ] Batch normalization\\n- [ ] SGD with momentum\\n- [ ] Adam\"}, {'course_id': 0, 'question_id': 5891, 'question': 'Which of these plaintexts can be the result of the decryption of \\\\texttt{SERGEV} using a simple subsitution cipher?', 'question_options': ['\\\\texttt{VERNAM}', '\\\\texttt{ENIGMA}', '\\\\texttt{TURING}', '\\\\texttt{CAESAR}'], 'A_chat_id': 92825, 'B_chat_id': 92826, 'A': '\\\\texttt{TURING}', 'B': \"To decrypt the ciphertext \\\\texttt{SERGEV} using a simple substitution cipher, we need to map the letters back to their original positions in the alphabet based on the key used for encryption.\\n\\nLet's analyze each option:\\n\\n1. \\\\texttt{VERNAM}: The letters do not match the pattern of the ciphertext, so it is unlikely to be the correct decryption.\\n\\n2. \\\\texttt{ENIGMA}: The letters do not match the pattern of the ciphertext, so it is unlikely to be the correct decryption.\\n\\n3. \\\\texttt{TURING}: The letters do not match the pattern of the ciphertext, so it is unlikely to be the correct decryption.\\n\\n4. \\\\texttt{CAESAR}: The letters \\\\texttt{SERGEV} could be rearranged to form the word \\\\texttt{CAESAR} if a specific Caesar shift was used for encryption. Therefore, \\\\texttt{CAESAR} is the plaintext that could be the result of decrypting \\\\texttt{SERGEV} with a simple substitution cipher.\\n\\nTherefore, the correct answer is:\\n[ ] \\\\texttt{VERNAM}\\n[ ] \\\\texttt{ENIGMA}\\n[ ] \\\\texttt{TURING}\\n[X] \\\\texttt{CAESAR}\"}, {'course_id': 15118, 'question_id': 6905, 'question': \"A spider of mass $m$ is suspended by its thread to a tree. The thread has elastic constant $k$ and rest length $L$ and the tree is assumed to stand still.  Gravity acts on the spider which oscillates vertically around its equilibrium position.\\nWrite the spider's equation of motion\", 'question_options': None, 'A_chat_id': 92827, 'B_chat_id': 92828, 'A': \"The forces acting on the spider are the gravitational force $mg$ and the elastic force from the thread. The elastic force is given by Hooke's Law: $F_{\\\\text{elastic}} = -k(y-L)$, where $y$ is the displacement of the spider from the equilibrium position.\\n\\nUsing Newton's second law, we have:\\n$$\\nm\\\\frac{d^2y}{dt^2} = -mg - k(y-L)\\n$$\\n\\nSimplifying, we get the equation of motion for the spider:\\n$$\\nm\\\\frac{d^2y}{dt^2} + ky = mg + kL\\n$$\\n\\nThis is a second-order linear differential equation, which can be solved to find the motion of the spider.\", 'B': \"To write the equation of motion for the spider, we can consider the forces acting on it. The two main forces are the gravitational force and the force due to the tension in the thread.\\n\\nLet's denote the displacement of the spider from its equilibrium position as $x$. The restoring force due to the tension in the thread is given by Hooke's Law, $F_{\\\\text{spring}} = -kx$, where $k$ is the elastic constant of the thread.\\n\\nThe gravitational force acting on the spider is $F_{\\\\text{gravity}} = mg$, where $m$ is the mass of the spider and $g$ is the acceleration due to gravity.\\n\\nThe net force acting on the spider is the sum of the gravitational force and the restoring force:\\n\\n$$\\n\\\\sum F = F_{\\\\text{gravity}} + F_{\\\\text{spring}} = mg - kx\\n$$\\n\\nAccording to Newton's second law, the net force is equal to the mass of the spider times its acceleration:\\n\\n$$\\nm \\\\ddot{x} = mg - kx\\n$$\\n\\nwhere $\\\\ddot{x}$ represents the second derivative of the displacement $x$ with respect to time, which is the acceleration of the spider.\\n\\nTherefore, the equation of motion for the spider is:\\n\\n$$\\nm \\\\ddot{x} + kx = mg\\n$$\"}, {'course_id': 15103, 'question_id': 1754, 'question': 'Assume you are working on a text editor written in Java. Your colleague is interested in optimizing a wrapper around \"String.substring()\" used to let users copy and paste parts of the text and decides to write some benchmarks to measure the current performance of the feature. How would you suggest that he proceeds?', 'question_options': None, 'A_chat_id': 92829, 'B_chat_id': 92830, 'A': 'I would suggest that your colleague follows these steps to benchmark the performance of the \"String.substring()\" wrapper:\\n\\n1. Identify the specific use cases for the \"String.substring()\" wrapper in the text editor where users copy and paste parts of the text.\\n\\n2. Create a set of test cases that represent typical scenarios where the \"String.substring()\" wrapper is used, including different input sizes and edge cases.\\n\\n3. Implement a benchmarking framework in Java, such as JMH (Java Microbenchmark Harness), to accurately measure the performance of the \"String.substring()\" wrapper in different scenarios.\\n\\n4. Run the benchmark tests multiple times to ensure consistency and accuracy of the results.\\n\\n5. Analyze the benchmark results to identify any performance bottlenecks or areas for optimization in the \"String.substring()\" wrapper code.\\n\\n6. Make improvements to the code based on the benchmark results and re-run the tests to measure the impact of the optimizations.\\n\\n7. Document the benchmarking process, results, and any optimizations made to the \"String.substring()\" wrapper for future reference and comparison.', 'B': 'Here are some steps your colleague can follow to benchmark the performance of the \"String.substring()\" wrapper in the text editor:\\n\\n1. **Identify the Scope of Benchmarking**: Define the specific use cases and scenarios where the \"String.substring()\" wrapper is used in the text editor. This could include copying and pasting small sections of text, large sections of text, text with different lengths, etc.\\n\\n2. **Select Benchmarking Tools**: Choose a benchmarking tool or library that can accurately measure the performance of the \"String.substring()\" wrapper. Popular Java benchmarking tools include JMH (Java Microbenchmarking Harness), Apache JMeter, and Caliper.\\n\\n3. **Create Benchmark Tests**: Write benchmark tests that simulate the typical use cases of the \"String.substring()\" wrapper in the text editor. Make sure to vary the input parameters such as text length, starting index, and ending index to cover different scenarios.\\n\\n4. **Run the Benchmark Tests**: Execute the benchmark tests multiple times to ensure consistent results. It\\'s important to run the tests on a stable environment with minimal interference from other processes.\\n\\n5. **Collect and Analyze Results**: Record the performance metrics such as execution time, memory usage, and CPU utilization for each benchmark test. Analyze the results to identify any performance bottlenecks or areas for optimization.\\n\\n6. **Optimize and Retest**: Based on the benchmark results, make any necessary optimizations to the \"String.substring()\" wrapper implementation. After making changes, re-run the benchmark tests to measure the impact of the optimizations on performance.\\n\\n7. **Iterate and Fine-Tune**: Continue to iterate on the benchmarking process by refining the test scenarios, adjusting parameters, and retesting the performance of the \"String.substring()\" wrapper. This iterative approach will help in identifying the most effective optimizations.\\n\\nBy following these steps, your colleague can effectively benchmark the performance of the \"String.substring()\" wrapper in the text editor and make informed decisions on how to optimize its implementation.'}, {'course_id': 15115, 'question_id': 7308, 'question': 'A charged body with $Q=-1~\\\\mu C$ is dropped from a height $h=1~m$ above the Earth surface. A plate charged with $10^{19}$ electrons is placed exactly below it on the surface.\\nBy using the concept of potential energy, evaluate the mass $M$ of the body in order to let it float at height $h$ \\\\textit{(remember that the gravitational potential energy at distance $z$ close to the Earth surface can be approximated as $U=Mgz$, with $g=9.81~m/s^2$)}.', 'question_options': None, 'A_chat_id': 92831, 'B_chat_id': 92832, 'A': 'The potential energy of the charged body can be calculated as the sum of its gravitational potential energy and its electrical potential energy. \\n\\nThe gravitational potential energy at height h above the Earth surface is given by $U_{\\\\text{grav}} = Mgh$, where M is the mass of the body and g is the acceleration due to gravity.\\n\\nThe electrical potential energy of the charged body is given by $U_{\\\\text{elec}} = \\\\frac{kQq}{r}$, where k is the Coulomb constant, Q is the charge of the body, q is the charge of the plate (10^19 electrons), and r is the distance between the body and the plate.\\n\\nSince the body is floating at height h, the total potential energy is zero. Therefore, we have:\\n\\n$U_{\\\\text{grav}} + U_{\\\\text{elec}} = 0$\\n\\n$Mgh + \\\\frac{kQq}{r} = 0$\\n\\nSubstitute the values of Q, h, q, k, and g into the equation and solve for M to find the mass of the body required for it to float at height h.', 'B': \"To find the mass $M$ of the body in order to let it float at a height $h$, we need to consider the equilibrium condition where the electric force repelling the body upwards is equal in magnitude to the gravitational force pulling it downward.\\n\\nLet's analyze the forces acting on the charged body at height $h$ above the Earth's surface:\\n- The electric force repelling the body upwards is due to the interaction between the body and the plate placed on the Earth's surface. This force can be calculated using Coulomb's law: $F_{\\\\text{elec}} = k \\\\frac{|Q_1| |Q_2|}{r^2}$, where $k$ is the electrostatic constant ($8.988 \\\\times 10^9 ~ N m^2/C^2$), $Q_1$ and $Q_2$ are the charges of the two bodies, and $r$ is the distance between them.\\n- The gravitational force pulling the body downwards is given by $F_{\\\\text{grav}} = M g$, where $M$ is the mass of the body and $g$ is the acceleration due to gravity.\\n\\nAt equilibrium, these two forces are equal in magnitude: $F_{\\\\text{elec}} = F_{\\\\text{grav}}$. Therefore, we can write:\\n\\n$k \\\\frac{|Q_1| |Q_2|}{r^2} = M g$\\n\\nSubstitute the given values: $Q_1 = -1 \\\\times 10^{-6} ~C$, $Q_2 = -10^{19} ~e$, $r = R_{\\\\text{Earth}} = 6.37 \\\\times 10^6 ~m$, and $g = 9.81 ~m/s^2$. Also, convert the charge of the plate to Coulombs ($-10^{19} ~e \\\\approx -1.602 \\\\times 10^{-14} ~C$) and solve for $M$.\\n\\n$k \\\\frac{|-1 \\\\times 10^{-6}| |-1.602 \\\\times 10^{-14}|}{(6.37 \\\\times 10^6)^2} = M \\\\times 9.81$\\n\\n$M = \\\\frac{k \\\\times |-1 \\\\times 10^{-6} \\\\times -1.602 \\\\times 10^{-14}|}{9.81 \\\\times (6.37 \\\\times 10^6)^2}$\\n\\nCalculate the value of $M$ using the given values and the constants.\"}, {'course_id': 15126, 'question_id': 2339, 'question': 'Why does Intel Itanium contain more general-purpose registers (128) than most RISC instruction sets (usually 32)?', 'question_options': None, 'A_chat_id': 92833, 'B_chat_id': 92834, 'A': 'The Intel Itanium architecture was designed to support a wide range of complex instructions and to handle very large amounts of data. Having more general-purpose registers allows for better performance and optimization of these complex instructions. RISC architectures, on the other hand, focus on simplicity and efficiency by using a smaller number of registers and simpler instructions to achieve high performance.', 'B': \"The reason Intel Itanium contains more general-purpose registers (128) compared to most RISC instruction sets (usually 32) can be attributed to the design philosophy and goals of the Itanium architecture.\\n\\n1. **EPIC Architecture**: Intel Itanium uses the Explicitly Parallel Instruction Computing (EPIC) architecture. EPIC architectures are designed to expose more parallelism at the hardware level, allowing for multiple instructions to be executed in parallel. To fully exploit this parallelism, a larger number of registers are needed to store intermediate values and reduce the need to access memory frequently.\\n\\n2. **Compiler Optimization**: EPIC architectures rely heavily on compiler optimization to schedule and execute instructions in parallel. By providing a larger number of registers, the compiler has more flexibility in assigning and managing register usage efficiently. This can lead to improved performance by reducing the need to spill registers to memory and enabling more aggressive optimization techniques.\\n\\n3. **Performance and Scalability**: The large number of registers in Itanium allows for better performance and scalability in handling complex and demanding workloads. By providing a vast register file, Itanium can support a wide range of applications and computational tasks, making it suitable for high-performance computing and enterprise-level workloads.\\n\\n4. **Legacy Compatibility**: Itanium was designed to be a versatile architecture that could support a wide range of existing software and applications. By providing a large number of general-purpose registers, Itanium can accommodate the register-intensive programming styles commonly found in legacy codebases without sacrificing performance.\\n\\nIn contrast, traditional RISC architectures typically focus on simplicity, reduced instruction set complexity, and efficient pipelining. They often rely on register-windowing techniques or register renaming to mitigate the impact of having a smaller number of registers. This design choice helps keep the hardware implementation simpler and more power-efficient, which can be advantageous for embedded systems or low-power devices.\\n\\nOverall, the decision to include a large number of general-purpose registers in Intel Itanium was driven by the architecture's emphasis on parallelism, performance optimization through compiler techniques, scalability, and legacy compatibility.\"}, {'course_id': 15125, 'question_id': 2636, 'question': 'Which of the following is TRUE for Recommender Systems (RS)?', 'question_options': ['The complexity of the Content-based RS depends on the number of users', 'Item-based RS need not only the ratings but also the item features', 'Matrix Factorization is typically robust to the cold-start problem.', 'Matrix Factorization can predict a score for any user-item combination in the dataset.'], 'A_chat_id': 92836, 'B_chat_id': 92837, 'A': 'Matrix Factorization can predict a score for any user-item combination in the dataset. Matrix Factorization is a popular technique used in Recommender Systems that is capable of predicting ratings for user-item combinations even if those combinations have not been observed in the training data. This helps address the cold-start problem where new users or items have limited historical data.', 'B': \"Let's analyze each statement:\\n\\n1. [ ] The complexity of the Content-based RS depends on the number of users.\\n   - This statement is generally not true. The complexity of a content-based RS typically depends more on the number of items in the dataset and the features associated with those items. The number of users may influence the computational complexity to some extent, but it is not a primary factor.\\n\\n2. [ ] Item-based RS need not only the ratings but also the item features.\\n   - This statement is true. In item-based recommendation systems, both ratings and item features play a crucial role in determining the similarity between items and making recommendations.\\n\\n3. [ ] Matrix Factorization is typically robust to the cold-start problem.\\n   - This statement is not true. Matrix factorization techniques are known to struggle with the cold-start problem, where there is a lack of historical data for new users or items. Cold-start problems can lead to challenges in making accurate recommendations using matrix factorization.\\n\\n4. [ ] Matrix Factorization can predict a score for any user-item combination in the dataset.\\n   - This statement is true. Matrix factorization models can predict scores for user-item combinations based on the learned latent factors from the matrix decomposition.\\n\\nTherefore, the correct statements are:\\n- [ ] Item-based RS need not only the ratings but also the item features.\\n- [ ] Matrix Factorization can predict a score for any user-item combination in the dataset.\"}, {'course_id': 15113, 'question_id': 7085, 'question': 'A ball of mass $m$ is hanging (vertically) on a spring of elastic constant $k$ and of natural length $l_0$. The suspension point of the spring is attached to the ceiling at height $H$.\\n\\nDetermine the equilibrium position of the ball.\\n', 'question_options': None, 'A_chat_id': 92840, 'B_chat_id': 92841, 'A': \"At equilibrium, the forces acting on the ball are the gravitational force and the spring force. The gravitational force is given by $F_{\\\\text{gravity}} = mg$, where $g$ is the acceleration due to gravity. The spring force is given by Hooke's Law, $F_{\\\\text{spring}} = k(y-l_0)$, where $y$ is the displacement of the ball from its natural length $l_0$.\\n\\nAt equilibrium, these forces balance each other out, so we have $mg = k(y-l_0)$. Solving for $y$, we get $y = \\\\frac{mg}{k} + l_0$.\\n\\nSince the ball is hanging vertically, at equilibrium the total length of the spring is equal to the height $H$ from the ceiling. Therefore, the equilibrium position of the ball is $H = y + l_0$, which gives us $H = \\\\frac{mg}{k} + 2l_0$.\", 'B': \"To determine the equilibrium position of the ball, we need to consider the forces acting on it at that position.\\n\\nAt equilibrium, the forces acting on the ball are its weight $mg$ acting downwards and the spring force acting upwards. The spring force is given by Hooke's Law, which states that the force exerted by a spring is proportional to the displacement from its equilibrium position. \\n\\nLet $x$ be the displacement of the ball from its equilibrium position, then the spring force can be written as $-kx$, where the negative sign indicates that the force is acting in the opposite direction of the displacement.\\n\\nAt equilibrium, these two forces balance each other:\\n\\n$mg = kx$\\n\\nSolving for $x$, we find:\\n\\n$x = \\\\frac{mg}{k}$\\n\\nTherefore, the equilibrium position of the ball is at a distance $\\\\frac{mg}{k}$ below the suspension point of the spring.\"}, {'course_id': 15006, 'question_id': 4203, 'question': 'An expression is referentially transparent if it always returns the same value, no matter\\nthe global state of the program. A referentially transparent expression can be replaced by its value without\\nchanging the result of the program.\\nSay we have a value representing a class of students and their GPAs. Given the following defintions:\\n1 case class Student(gpa: Double)\\n2\\n3 def count(c: List[Student], student: Student): Double =\\n4 c.filter(s => s == student).size\\n5\\n6 val students = List(\\n7 Student(1.0), Student(2.0), Student(3.0),\\n8 Student(4.0), Student(5.0), Student(6.0)\\n9 )\\nAnd the expression e:\\n1 count(students, Student(6.0))\\nIs the expression e referentially transparent?', 'question_options': None, 'A_chat_id': 92844, 'B_chat_id': 92845, 'A': 'No, the expression e is not referentially transparent. This is because the result of the expression depends on the global state of the program, specifically the list \"students\" that is defined outside of the function. If the list \"students\" were to change, the result of the expression e would also change.', 'B': \"Let's analyze the expression e: count(students, Student(6.0))\\n\\nIn this expression:\\n- The input parameters are the list of students and a specific student object with a GPA of 6.0.\\n- The count function filters the list of students to find the students that are equal to the student object with a GPA of 6.0 and then returns the size of the filtered list.\\n\\nNow, let's consider whether the expression e is referentially transparent:\\n- The expression e will always return the size of the filtered list of students with a GPA of 6.0, regardless of the global state of the program as long as the input list 'students' remains unchanged.\\n- The function count does not have any side effects and solely depends on its input parameters.\\n\\nTherefore, the expression e: count(students, Student(6.0)) is referentially transparent because it consistently returns the same value given the same input parameters, and it can be replaced by its resulting value without affecting the program's behavior.\"}, {'course_id': 15125, 'question_id': 3630, 'question': 'What is WRONG\\xa0regarding the Transformer model?', 'question_options': ['It uses a self-attention mechanism to compute representations of the input and output.', 'Its computation cannot be parallelized compared to LSTMs and other sequential models.', 'Its complexity is quadratic to the input size.', 'It captures the semantic context of the input.'], 'A_chat_id': 92847, 'B_chat_id': 92848, 'A': 'Its computation cannot be parallelized compared to LSTMs and other sequential models. This statement is incorrect, as the Transformer model is highly parallelizable due to its attention mechanism, allowing for more efficient training on modern hardware.', 'B': 'The incorrect statement regarding the Transformer model is:\\n\\n[ ] Its computation cannot be parallelized compared to LSTMs and other sequential models.\\n\\nIn fact, the Transformer model can be parallelized much more efficiently compared to traditional sequential models like LSTMs due to its attention mechanism and architecture, which allows for faster training and inference on parallel computing hardware.'}, {'course_id': 0, 'question_id': 6123, 'question': 'A simple substitution cipher can be broken \\\\dots', 'question_options': ['by analysing the probability occurence of the language.', 'only by using a quantum computer.', 'by using the ENIGMA machine.', 'by using public-key cryptogaphy.'], 'A_chat_id': 92851, 'B_chat_id': 92852, 'A': 'The correct answer is: by analysing the probability occurrence of the language. Substitution ciphers can be broken by analyzing the frequency of letters in the encrypted text and comparing it to the frequency of letters in the language being used. This method is known as frequency analysis.', 'B': '[ ] by analysing the probability occurence of the language.'}, {'course_id': 15011, 'question_id': 5185, 'question': ' Design and analyze a  polynomial-time algorithm for the following problem: \\\\begin{center} \\\\begin{boxedminipage}[t]{0.83\\\\textwidth} \\\\begin{description} \\\\item[Input:] a vertex set $V$. \\\\item[Output:]  vertex subsets $S_1, S_2, \\\\ldots, S_\\\\ell \\\\subseteq V$ with the following property:\\\\\\\\[2mm] For every set of edges $E\\\\subseteq {V \\\\choose 2}$, there is an $i\\\\in \\\\{1,2, \\\\ldots, \\\\ell\\\\}$ such that \\\\begin{align*} |\\\\{e\\\\in E: |e\\\\cap S_i| = 1\\\\}| \\\\geq |E|/2\\\\,, \\\\end{align*} i.e., $S_i$ cuts at least half the edges in $G = (V,E)$. \\\\end{description} \\\\end{boxedminipage} \\\\end{center} We remark that, since your algorithm should run in time polynomial in $n=|V|$, it can output at most polynomially (in $n$) many vertex sets. We also emphasize that the algorithm does \\\\textbf{not} take the edge set $E$ as input. {\\\\em (In this problem you are asked to (i) design the algorithm, (ii) show that it runs in time polynomial in $n$, and (iii) prove that the output satisfies the property given in the problem statement. Recall that you are allowed to refer to material covered in the lecture notes.)}', 'question_options': None, 'A_chat_id': 92856, 'B_chat_id': 92857, 'A': '(i) To design the algorithm, we can use a randomized approach. \\n\\n1. Randomly select a vertex subset $S_1 \\\\subseteq V$.\\n2. For each edge $e \\\\in E$, check if $|e \\\\cap S_1| = 1$. If so, add $e$ to a list $L$.\\n3. Repeat steps 1 and 2 for a certain number of iterations to obtain subsets $S_2, S_3, ..., S_\\\\ell$.\\n4. Output the subsets $S_1, S_2, ..., S_\\\\ell$.\\n\\n(ii) This algorithm runs in polynomial time since the main loop iterates a polynomial number of times, and for each iteration, we perform polynomial operations.\\n\\n(iii) To prove that the output satisfies the property given in the problem statement, consider any set of edges $E \\\\subseteq {V \\\\choose 2}$. By the Pigeonhole Principle, at least one of the subsets $S_i$ will cut at least half of the edges in $E$. This is because if we randomly select vertices for $S_i$ multiple times, eventually we will cover all possible edge configurations in $E$ with at least one of the subsets $S_i$.', 'B': 'To design an algorithm for this problem, we can proceed as follows:\\n\\n**Algorithm:**\\n1. Let $V_1 = V$ be the initial vertex set.\\n2. Initialize an empty list of subsets $S_1, S_2, \\\\ldots, S_\\\\ell$.\\n3. While $V_i$ is not empty, do the following:\\n   a. Pick a vertex $v$ uniformly at random from $V_i$.\\n   b. Let $S_i = \\\\{v\\\\}$.\\n   c. Remove $v$ and its neighbors from $V_i$.\\n   d. Increment $i$.\\n4. Output the list of subsets $S_1, S_2, \\\\ldots, S_\\\\ell$.\\n\\n**Analysis:**\\n- Step 1 takes $O(1)$ time.\\n- In each iteration of the while loop, we pick a vertex $v$ and remove $v$ and its neighbors. This can be done in $O(|V_i|)$ time.\\n- The while loop runs for at most $|V|$ iterations since we remove at least one vertex in each iteration.\\n- Thus, the algorithm runs in $O(|V|^2)$ time, which is polynomial in $n$.\\n\\n**Proof of Property:**\\nLet $E$ be any set of edges in ${V \\\\choose 2}$. Since we pick a vertex and remove its neighbors in each iteration, there exists at least one $S_i$ that contains an endpoint of each edge in $E$.\\nThus, for any set of edges $E$, there is at least one $S_i$ that cuts at least half the edges in $E$.\\nTherefore, the output of the algorithm satisfies the required property.'}, {'course_id': 15125, 'question_id': 2641, 'question': 'In classification, which of the following is true regarding class imbalance?', 'question_options': ['Classes should have the same distribution in the validation set and in the full dataset.', 'Oversampling the larger class can reduce the impact of the skewed distribution.', 'Oversampling rare classes in the testing set can reduce the impact of skewed distribution.', 'The leave-one-out methodology produces the same class distribution in the training and the testing set.'], 'A_chat_id': 92861, 'B_chat_id': 92862, 'A': \"Oversampling the larger class can reduce the impact of the skewed distribution. Class imbalance refers to when one class has significantly more instances than another class. Oversampling the larger class can help balance out the distribution and improve the model's performance. The other statements are false. Classes do not need to have the same distribution in the validation set and the full dataset. Oversampling rare classes in the testing set can introduce bias and is not recommended. The leave-one-out methodology does not guarantee the same class distribution in the training and testing set.\", 'B': 'The correct statement regarding class imbalance in classification is:\\n\\n[ ] Oversampling the larger class can reduce the impact of the skewed distribution.\\n\\nExplanation:\\n- Class imbalance occurs when one class has significantly more instances than another class in the dataset.\\n- In the case of class imbalance, oversampling the larger class can help balance out the distribution and reduce the impact of the skewed distribution.\\n- It is important to balance the class distribution to prevent the model from being biased towards the majority class.'}, {'course_id': 15125, 'question_id': 2649, 'question': 'We learnt in the lecture that terms are typically stored in an inverted list. Now, in the inverted list, instead of only storing document identifiers of the documents in which the term appears, assume we also store an *offset* of the appearance of a term in a document. An $offset$ of a term $l_k$ given a document is defined as the number of words between the start of the document and $l_k$. Thus our inverted list is now:  $l_k= \\\\langle f_k: \\\\{d_{i_1} \\\\rightarrow [o_1,\\\\ldots,o_{n_{i_1}}]\\\\},  \\\\{d_{i_2} \\\\rightarrow [o_1,\\\\ldots,o_{n_{i_2}}]\\\\}, \\\\ldots,  \\\\{d_{i_k} \\\\rightarrow [o_1,\\\\ldots,o_{n_{i_k}}]\\\\} \\\\rangle$  This means that in document $d_{i_1}$ term $l_k$ appears $n_{i_1}$ times and at offset $[o_1,\\\\ldots,o_{n_{i_1}}]$, where $[o_1,\\\\ldots,o_{n_{i_1}}]$ are sorted in ascending order, these type of indices are also known as term-offset indices. An example of a term-offset index is as follows:  **Obama** = $⟨4 : {1 → [3]},{2 → [6]},{3 → [2,17]},{4 → [1]}⟩$  **Governor** = $⟨2 : {4 → [3]}, {7 → [14]}⟩$  **Election** = $⟨4 : {1 → [1]},{2 → [1,21]},{3 → [3]},{5 → [16,22,51]}⟩$  Which is to say that the term **Governor** appear in 2 documents. In document 4 at offset 3, in document 7 at offset 14. Now let us consider the *SLOP/x* operator in text retrieval. This operator has the syntax: *QueryTerm1 SLOP/x QueryTerm2* finds occurrences of *QueryTerm1* within $x$ (but not necessarily in that order) words of *QueryTerm2*, where $x$ is a positive integer argument ($x \\\\geq 1$). Thus $x = 1$ demands that *QueryTerm1* be adjacent to *QueryTerm2*.  Consider the general procedure for \"merging\" two term-offset inverted lists for a given document, to determine where the document satisfies a *SLOP/x* clause (since in general there will be many offsets at which each term occurs in a document). Let $L$ denote the total number of occurrences of the two terms in the document. Assume we have a pointer to the list of occurrences of each term and can move the pointer along this list. As we do so we check whether we have a hit for $SLOP/x$ (i.e. the $SLOP/x$ clause is satisfied). Each move of either pointer counts as a step. Based on this assumption is there a general \"merging\" procedure to determine whether the document satisfies a $SLOP/x$ clause, for which the following is true? Justify your answer.      1. The merge can be accomplished in a number of steps linear in $L$ regardless of $x$, and we can ensure that each pointer moves only to the right (i.e. forward).     2. The merge can be accomplished in a number of steps linear in $L$, but a pointer may be forced to move to the left (i.e. backwards).     3. The merge can require $x \\\\times L$ steps in some cases.', 'question_options': None, 'A_chat_id': 92864, 'B_chat_id': 92865, 'A': 'The correct answer is 2. The merge can be accomplished in a number of steps linear in L, but a pointer may be forced to move to the left (i.e. backwards).\\n\\nIn order to determine whether a document satisfies a SLOP/x clause, we need to consider all possible combinations of offsets for the two terms within the document. This may require moving the pointers of the term-offset inverted lists in both directions to find valid combinations that satisfy the SLOP/x condition.\\n\\nSince the SLOP/x operator allows for the terms to appear within x words of each other in any order, it is possible that we need to backtrack and recheck certain offsets if a valid combination is not found initially. This means that in some cases, a pointer may be forced to move to the left (backwards) in order to find a satisfying combination.\\n\\nTherefore, the merge can be accomplished in a number of steps linear in L, but it may require moving the pointers in both directions to find all valid combinations that satisfy the SLOP/x clause.', 'B': \"To determine whether a document satisfies a SLOP/x clause for two terms with term-offset inverted lists, we need to find occurrences of QueryTerm1 within x words of QueryTerm2. Given the term-offset inverted lists, we can merge the lists of occurrences for each term in a document using a pointer-based approach.\\n\\nLet's analyze the options provided:\\n\\n1. **The merge can be accomplished in a number of steps linear in L regardless of x, and we can ensure that each pointer moves only to the right (i.e. forward).**\\n\\nThis option implies that we can merge the term-offset inverted lists in a linear number of steps in terms of the total number of occurrences (L), and each pointer moves only to the right. This approach is feasible because we are essentially comparing the positions of the terms in the document and checking if the SLOP/x clause is satisfied. By iterating through the occurrences of each term in the document and comparing positions, we can achieve this linear time complexity. So, this option is valid.\\n\\n2. **The merge can be accomplished in a number of steps linear in L, but a pointer may be forced to move to the left (i.e. backwards).**\\n\\nFor a SLOP/x operator, we are interested in finding occurrences within a specific range of x words, irrespective of the direction. However, moving the pointer backward in a term-offset inverted list may not always be necessary for checking the SLOP/x clause. Since we are interested in a fixed range x, we can achieve this by moving the pointers forward only, making this option less likely.\\n\\n3. **The merge can require x * L steps in some cases.**\\n\\nIf we consider this option, it would imply that for each occurrence of QueryTerm1, we would need to potentially iterate through x occurrences of QueryTerm2 to check the SLOP/x condition. This approach could lead to x * L steps in the worst-case scenario where we have to check all possible combinations within the specified range. However, a more efficient way would be to merge the inverted lists linearly and track the relative positions of the terms to satisfy the SLOP/x condition, making this option less likely.\\n\\nTherefore, based on the analysis, the most suitable option is:\\n\\n**1. The merge can be accomplished in a number of steps linear in L regardless of x, and we can ensure that each pointer moves only to the right (i.e. forward).**\"}, {'course_id': 9, 'question_id': 6836, 'question': 'Let \\\\(f(x) = 3 x \\\\left(\\\\log_2(x) \\right)^2 + x^2 \\\\). Select the correct statement:', 'question_options': ['\\\\(f(x)\\\\) is \\\\(O\\\\left(3 x \\\\left(\\\\log_2(x) \\right)^2  \\right)  \\\\) but not \\\\(\\\\Omega\\\\left(3 x \\\\left(\\\\log_2(x) \\right)^2  \\right)  \\\\)', 'None of the other statements are correct', '\\\\(f(x)\\\\) is \\\\(\\\\Theta \\\\left(3 x \\\\left(\\\\log_2(x) \\right)^2 \\right)  \\\\)', '\\\\(f(x)\\\\) is \\\\(\\\\Omega\\\\left(3 x \\\\left(\\\\log_2(x) \\right)^2  \\right)  \\\\) but not \\\\(O\\\\left(3 x \\\\left(\\\\log_2(x) \\right)^2  \\right)  \\\\)'], 'A_chat_id': 92871, 'B_chat_id': 92872, 'A': 'The correct statement is: \\\\(f(x)\\\\) is \\\\(\\\\Theta \\\\left(3 x \\\\left(\\\\log_2(x) \\\\right)^2 \\\\right)\\\\). This is because \\\\(f(x)\\\\) is both upper bounded by \\\\(3 x \\\\left(\\\\log_2(x) \\\\right)^2\\\\) and lower bounded by \\\\(3 x \\\\left(\\\\log_2(x) \\\\right)^2\\\\), indicating that it grows at the same rate.', 'B': \"To determine whether \\\\(f(x)\\\\) is \\\\(O\\\\), \\\\(\\\\Omega\\\\), or \\\\(\\\\Theta\\\\) of \\\\(3x(\\\\log_2(x))^2\\\\), we need to compare their growth rates.\\n\\nFirst, let's simplify \\\\(3x(\\\\log_2(x))^2\\\\) and \\\\(x^2\\\\):\\n\\\\[ 3x(\\\\log_2(x))^2 = 3x(\\\\log(x)/\\\\log(2))^2 = 3x(\\\\log(x))^2/\\\\log^2(2) = 3x(\\\\log(x))^2/\\\\log(2)^2 \\\\]\\n\\nNow, let's compare the growth rates of \\\\(f(x)\\\\) and \\\\(3x(\\\\log(x))^2/\\\\log(2)^2\\\\) as \\\\(x\\\\) approaches infinity.\\n\\n1. As \\\\(x\\\\) approaches infinity, the dominant term in \\\\(f(x)\\\\) is \\\\(3x(\\\\log(x))^2\\\\) because the logarithmic term grows slower than the quadratic term.\\n2. We can see that \\\\(f(x)\\\\) grows faster than \\\\(3x(\\\\log(x))^2\\\\), which means \\\\(f(x)\\\\) is \\\\(\\\\Omega(3x(\\\\log(x))^2)\\\\).\\n\\nTherefore, the correct statement is:\\n[ ] \\\\(f(x)\\\\) is \\\\(\\\\Omega\\\\left(3 x \\\\left(\\\\log_2(x)\\\\right)^2\\\\right)\\\\) but not \\\\(O\\\\left(3 x \\\\left(\\\\log_2(x)\\\\right)^2\\\\right)\\\\)\"}, {'course_id': 15002, 'question_id': 1021, 'question': 'Consider an IR engine, which uses an indexing mechanism implementing the following 3 consecutive filters:\\n\\na morpho-syntactic filter that restricts indexing term candidates to only nouns, and reduces them to their root forms;\\na frequencial filter parameterized with \\\\(f_\\\\text{min}=0.06\\\\) (resp. \\\\(f_\\\\text{max}=0.20\\\\)) as lower (resp. upper) cut-off value, expressed as relative frequencies;\\na stop word filter using the following stop list: {a, in, mouse, the}.\\n\\nand the following document \\\\(d\\\\):\\n\\nCats are the worst enemies of rodents. After all, a cat is a cat: as soon as it can, it rushes into the bushes with only one target in mind: mice, mice and mice! Naturally, the cats of houses are less frightening, as for them croquette loaded dressers have replaced prey hiding bushes. Cat\\'s life in the house is easy!...\\n\\nWhat is the multi-set resulting from the indexing of document \\\\(d\\\\) by the above described IR engine?\\nFormat your answer as an alphabetically ordered list of the form: \"lemma1(tf1), lemma2(tf2), ...\", where tfi is the term frequency of indexing term i.\\nFor instance: dog(2), frog(3), zebra(1)', 'question_options': None, 'A_chat_id': 92876, 'B_chat_id': 92877, 'A': 'After applying the 3 consecutive filters to the document \\\\(d\\\\), the resulting multi-set from the indexing by the IR engine is:\\n\\ncat(2), enemy(1), house(2), life(1), prey(1), target(1)', 'B': \"To find the multi-set resulting from the indexing of the document \\\\(d\\\\) by the described IR engine, we need to apply the three consecutive filters to the terms in the document. Let's go step by step:\\n\\n1. Apply the morpho-syntactic filter:\\n- Only nouns are retained and reduced to their root forms:\\n  - Cats -> cat\\n  - enemies -> enemy\\n  - rodents -> rodent\\n  - cat -> cat\\n  - target -> target\\n  - mice -> mouse\\n  - cats -> cat\\n  - houses -> house\\n  - croquette -> croquette\\n  - dressers -> dresser\\n  - prey -> prey\\n  - bushes -> bush\\n  - cat's -> cat\\n  - house -> house\\n\\n2. Apply the frequencial filter:\\n- Calculate the term frequencies for each lemma:\\n  - cat(3), enemy(1), rodent(1), target(1), mouse(1), house(2), croquette(1), dresser(1), prey(1), bush(1)\\n\\n3. Apply the stop word filter:\\n- Remove the terms in the stop list: {a, in, mouse, the}\\n- Remaining terms: cat(3), enemy(1), rodent(1), target(1), house(2), croquette(1), dresser(1), prey(1), bush(1)\\n\\nTherefore, the multi-set resulting from the indexing of document \\\\(d\\\\) by the IR engine is:\\ncat(3), croquette(1), dresser(1), enemy(1), house(2), prey(1), rodent(1), target(1)\"}, {'course_id': 15002, 'question_id': 993, 'question': 'For each column of the lattice used in the Viterbi algorithm applied to that input sequence (\"process time control\"), how many nodes (= lines) does it have?Provide your answer as a coma separated list of integers.For instance, if the lattice has 5 columns, you could for instance here write:4,3,2,4,2', 'question_options': None, 'A_chat_id': 92882, 'B_chat_id': 92883, 'A': 'The number of nodes in each column of the lattice decreases as we move towards the end of the input sequence. Therefore, the number of nodes in each column would be: 6, 5, 4, 3, 2, 1, 1, 1.', 'B': 'To determine the number of nodes in each column of the lattice for the Viterbi algorithm applied to the input sequence \"process time control,\" we need to consider the number of possible states at each time step.\\n\\nThe input sequence has 18 characters, so there are 18 time steps in the Viterbi algorithm. Each time step corresponds to a column in the lattice.\\n\\nNow, let\\'s analyze the number of nodes in each column:\\n\\n1. For the first column (corresponding to the first character \"p\"), there are 4 possible states: P, R, S, T. Hence, 4 nodes.\\n2. For the second column (corresponding to the first two characters \"pr\"), there are 3 possible states: O, T, R. Hence, 3 nodes.\\n3. For the third column (corresponding to the first three characters \"pro\"), there are 2 possible states: C, E. Hence, 2 nodes.\\n4. For the fourth column (corresponding to the first four characters \"proc\"), there are 4 possible states: E, S, T, O. Hence, 4 nodes.\\n5. For the fifth column (corresponding to the first five characters \"proce\"), there are 2 possible states: S, D. Hence, 2 nodes.\\n6. For the sixth column (corresponding to the first six characters \"proces\"), there are 4 possible states: S, S, T, O. Hence, 4 nodes.\\n7. For the seventh column (corresponding to the first seven characters \"process\"), there are 3 possible states: T, T, O. Hence, 3 nodes.\\n8. For the eighth column (corresponding to the first eight characters \"process \"), there are 4 possible states: T, I, M, E. Hence, 4 nodes.\\n9. For the ninth column (corresponding to the first nine characters \"process t\"), there are 3 possible states: I, M, E. Hence, 3 nodes.\\n10. For the tenth column (corresponding to the first ten characters \"process ti\"), there are 3 possible states: M, E, C. Hence, 3 nodes.\\n11. For the eleventh column (corresponding to the first eleven characters \"process tim\"), there are 2 possible states: E, E. Hence, 2 nodes.\\n12. For the twelfth column (corresponding to the first twelve characters \"process time\"), there are 3 possible states: A, M, E. Hence, 3 nodes.\\n13. For the thirteenth column (corresponding to the first thirteen characters \"process time \"), there are 3 possible states: M, C, O. Hence, 3 nodes.\\n14. For the fourteenth column (corresponding to the first fourteen characters \"process time c\"), there are 3 possible states: O, O, R. Hence, 3 nodes.\\n15. For the fifteenth column (corresponding to the first fifteen characters \"process time co\"), there are 3 possible states: N, N, T. Hence, 3 nodes.\\n16. For the sixteenth column (corresponding to the first sixteen characters \"process time con\"), there are 2 possible states: T, S. Hence, 2 nodes.\\n17. For the seventeenth column (corresponding to the first seventeen characters \"process time cont\"), there are 2 possible states: R, I. Hence, 2 nodes.\\n18. For the eighteenth column (corresponding to the entire sequence \"process time control\"), there are 3 possible states: R, O, L. Hence, 3 nodes.\\n\\nTherefore, the number of nodes in each column of the lattice, from left to right, is: 4, 3, 2, 4, 2, 4, 3, 4, 3, 3, 2, 3, 3, 3, 3, 2, 2, 3.'}, {'course_id': 15041, 'question_id': 2744, 'question': 'What is the mean squared error of $f$ for a sample, where $\\\\textbf{x}$ is an input, $y$ a target and $f(\\\\textbf{x},W)$ the mapping function  ? \\n(One answer)', 'question_options': [' $||y - f(\\\\textbf{x},W)||^2 $ ', ' $||y - f(\\\\textbf{x},W)|| $', ' $-\\\\log(P(y=i | \\\\textbf{x})) = -\\\\log(\\\\frac{e^{\\\\textbf{f}_i(\\\\textbf{x},W)}}{\\\\sum_j e^{\\\\textbf{f}_j(\\\\textbf{x},W)}})$ ', ' $P(y=i |\\\\textbf{x}) = \\\\frac{e^{\\\\textbf{f}_i(\\\\textbf{x},W)}}{\\\\sum_j e^{\\\\textbf{f}_j(\\\\textbf{x},W)}}$ '], 'A_chat_id': 92886, 'B_chat_id': 92887, 'A': 'The mean squared error (MSE) of $f$ for a sample is given by $||y - f(\\\\textbf{x},W)||^2 $.', 'B': '$||y - f(\\\\textbf{x},W)||^2 $'}, {'course_id': 15127, 'question_id': 3362, 'question': 'Given a joint data distribution $\\\\mathcal D$ on $\\\\mathcal X \\times \\\\{-1,1\\\\}$ and $n$ independent and identically distributed observations from $\\\\mathcal D$, the goal of the classification task is to learn a classifier $f:\\\\mathcal X \\to \\\\{-1,1\\\\}$ with minimum true risk $\\\\mathcal L(f) = \\\\mathbb E_{(X,Y)\\\\sim \\\\mathcal D} [\\x08oldsymbol{\\\\mathbb{1}}_{f(X)\\neq Y}]$ where $\\x08oldsymbol{\\\\mathbb{1}}_{C} = \\x08egin{cases}\\n            1 \\\\; \\text{ if } C  \\text{ is true} \\\\\\n            0 \\\\quad \\text{otherwise} \\n            \\\\end{cases}$. %\\n            We denote by $\\\\mathcal D_{X}$ the marginal law (probability distribution) of $X$, and $\\\\mathcal D_{Y|X}$ the conditional law of $Y$ given $X$.\\n            Give the two reasons seen in the course which explain that minimizing the true risk with the $0-1$ loss over the set of classifiers $f:\\\\mathcal X \\to \\\\{-1,1\\\\}$ is problematic.', 'question_options': None, 'A_chat_id': 92888, 'B_chat_id': 92889, 'A': 'The two reasons seen in the course which explain that minimizing the true risk with the 0-1 loss over the set of classifiers $f:\\\\mathcal X \\\\to \\\\{-1,1\\\\}$ is problematic are:\\n\\n1. The 0-1 loss function is discontinuous: The 0-1 loss function assigns a penalty of 1 for misclassifications and 0 for correct classifications. This makes the optimization problem non-convex and discontinuous, leading to computational challenges in finding the optimal classifier.\\n\\n2. The true risk is not differentiable: The true risk $\\\\mathcal L(f)$ with the 0-1 loss function is not differentiable, making it difficult to apply traditional optimization algorithms that rely on gradients for convergence. This lack of differentiability can lead to optimization difficulties and suboptimal solutions when trying to minimize the true risk.', 'B': 'The two main reasons why minimizing the true risk with the $0-1$ loss over the set of classifiers $f:\\\\mathcal X \\\\rightarrow \\\\{-1,1\\\\}$ is problematic are:\\n\\n1. **Non-Convex Optimization**: The $0-1$ loss function is non-convex and discontinuous, making it difficult to optimize directly. This leads to optimization problems that are hard to solve efficiently, and in many cases, the optimization algorithms get stuck in local minima. This makes it challenging to find the global minimum of the true risk when using the $0-1$ loss.\\n\\n2. **Non-Differentiability**: The $0-1$ loss function is non-differentiable almost everywhere, which poses challenges for gradient-based optimization methods commonly used in machine learning. This non-differentiability makes it hard to apply gradient descent algorithms to find the optimal classifier directly. This can lead to optimization issues, slow convergence, and difficulties in finding a good solution for the classification problem.\\n\\nDue to these reasons, it is often more practical to use surrogate loss functions that are differentiable and convex, such as the logistic loss or hinge loss, instead of the $0-1$ loss when training classifiers in practice. These surrogate loss functions provide smoother optimization landscapes and enable more efficient optimization algorithms to be applied, leading to better performance in practice.'}, {'course_id': 15003, 'question_id': 7325, 'question': 'Can we devise a broadcast algorithm that does not ensure the causal delivery property but only (in) its non-uniform variant:\\nNo correct process pi delivers a message m2 unless pi has already delivered every message m1 such that m1 → m2?', 'question_options': None, 'A_chat_id': 92891, 'B_chat_id': 92892, 'A': 'Yes, it is possible to devise a broadcast algorithm that only ensures non-uniform causal delivery. One way to achieve this is by implementing a total ordering on messages based on their causal dependencies. Each process would deliver messages in the order determined by this total ordering, ensuring that a process only delivers a message m2 after delivering all messages m1 such that m1 → m2. This way, the non-uniform causal delivery property is maintained without enforcing strict causal delivery.', 'B': 'Yes, we can devise a broadcast algorithm that does not ensure the causal delivery property but only its non-uniform variant. One such algorithm is the basic flooding algorithm.\\n\\nIn a basic flooding algorithm, when a process receives a message, it forwards that message to all other processes it knows about. This ensures that all processes eventually receive the message, but it does not guarantee causal delivery. In this algorithm, a process may deliver a message without having previously delivered all messages that causally precede it.\\n\\nTo implement the non-uniform variant of the causal delivery property, we can modify the basic flooding algorithm by adding a mechanism to track the causal relationships between messages. When a process receives a message, it also receives the causal history of that message (i.e., the list of messages that causally precede it). Before delivering a message, a process can check if it has already delivered all messages in the causal history of the received message. If not, the process can wait until it has delivered those messages before delivering the new message.\\n\\nThis modification ensures that no correct process delivers a message unless it has already delivered every message that causally precedes it. However, it does not guarantee that messages are delivered in the order they were sent, as in the strict causal delivery property.'}, {'course_id': 0, 'question_id': 6237, 'question': 'Tick the \\\\textbf{false} assertion. In Linear Cryptanalysis, the corresponding mask circuit of \\\\ldots', 'question_options': ['\\\\ldots a XOR gate ($X\\\\oplus Y = Z$) is $a\\\\cdot Z=(a\\\\cdot X)\\\\oplus (a\\\\cdot Y)$', '\\\\ldots a XOR to constant gate ($Y=X\\\\oplus K$) is $a\\\\cdot Y = (a\\\\cdot X)\\\\oplus (a\\\\cdot K)$', '\\\\ldots a linear circuit ($Y=M\\\\times X$) is $a\\\\cdot Y = (M\\\\times a)\\\\cdot X$', '\\\\ldots a duplicate gate ($X=Y=Z$) is $(a\\\\oplus b)\\\\cdot X=(a\\\\cdot Y)\\\\oplus (b\\\\cdot Z)$'], 'A_chat_id': 92894, 'B_chat_id': 92895, 'A': 'The false assertion is: \"... a duplicate gate ($X=Y=Z$) is $(a\\\\oplus b)\\\\cdot X=(a\\\\cdot Y)\\\\oplus (b\\\\cdot Z)$\". The correct corresponding mask circuit for a duplicate gate should be $(a\\\\oplus b)\\\\cdot X=(a\\\\cdot X)\\\\oplus (b\\\\cdot X)$.', 'B': \"Let's analyze each assertion:\\n\\n1. The corresponding mask circuit of an XOR gate is $a\\\\cdot Z=(a\\\\cdot X)\\\\oplus (a\\\\cdot Y)$. This assertion is true because in Linear Cryptanalysis, XOR gates are represented using linear equations.\\n2. The corresponding mask circuit of an XOR to constant gate is $a\\\\cdot Y = (a\\\\cdot X)\\\\oplus (a\\\\cdot K)$. This assertion is false. The correct expression for an XOR to constant gate is $a\\\\cdot Y = (a\\\\cdot X)\\\\oplus K$.\\n3. The corresponding mask circuit of a linear circuit ($Y=M\\\\times X$) is $a\\\\cdot Y = (M\\\\times a)\\\\cdot X$. This assertion is true. In Linear Cryptanalysis, linear circuits are represented by linear equations.\\n4. The corresponding mask circuit of a duplicate gate is $(a\\\\oplus b)\\\\cdot X=(a\\\\cdot Y)\\\\oplus (b\\\\cdot Z)$. This assertion is false. The correct expression for a duplicate gate is $X=Y=Z$, which means that the input is duplicated to multiple outputs.\\n\\nTherefore, the false assertion is:\\n\\n[ ] ... a XOR to constant gate ($Y=X\\\\oplus K$) is $a\\\\cdot Y = (a\\\\cdot X)\\\\oplus (a\\\\cdot K)$\"}, {'course_id': 15003, 'question_id': 7341, 'question': 'What is the communication complexity of the FloodSet algorithm in number of bits?', 'question_options': None, 'A_chat_id': 92896, 'B_chat_id': 92897, 'A': 'The communication complexity of the FloodSet algorithm in terms of bits can be calculated as follows:\\n\\nIn the FloodSet algorithm, each node communicates its current set of neighbors to its neighbors in each round of communication. Since each node can have at most n-1 neighbors in a network with n nodes (excluding itself), the maximum number of bits needed to represent the set of neighbors of a node is log2(n-1) bits.\\n\\nTherefore, in each round of communication, each node needs to communicate log2(n-1) bits to each of its neighbors. Since there are n nodes in the network, the total communication complexity of the FloodSet algorithm in terms of bits is n * log2(n-1) bits.', 'B': \"The FloodSet algorithm is a distributed algorithm used for set agreement in a network of processes. In the worst case scenario, where all processes need to communicate their set to all other processes in the network, the communication complexity of FloodSet can be quite high.\\n\\nLet's break down the communication complexity of FloodSet in terms of the number of bits exchanged between processes:\\n\\n1. Initialization phase: Each process needs to broadcast its initial set to all other processes in the network. This requires each process to send the size of its set (log2(N) bits, where N is the number of processes) and the elements in the set. If we assume each element in the set is represented using log2(M) bits (where M is the maximum number of elements in the set), then the total number of bits exchanged in the initialization phase is approximately N * (log2(N) + M * log2(M)).\\n\\n2. Flooding phase: In each round of the flooding phase, each process broadcasts its set to all other processes that have not received it yet. This requires each process to send the size of its set and the elements in the set. The number of bits exchanged in each round is approximately N * (log2(N) + M * log2(M)).\\n\\n3. Termination phase: Once all processes have received the sets of all other processes, the algorithm terminates. This phase may involve some additional communication to ensure that all processes have reached a consensus.\\n\\nOverall, the total communication complexity of the FloodSet algorithm can be quite high, especially in the worst case scenario where all processes need to exchange their sets with all other processes. The exact number of bits exchanged will depend on the number of processes, the size of the sets, and the specific implementation of the algorithm.\"}, {'course_id': 0, 'question_id': 5740, 'question': 'In order to achieve a collision resistance equivalent to a $128$ bit key search, the size of the digest must be at least $\\\\ldots$', 'question_options': ['$128$ bits.', '$2^{256}$ bits.', '$256$ bits.', '$2^{128}$ bits.'], 'A_chat_id': 92898, 'B_chat_id': 92899, 'A': 'In order to achieve a collision resistance equivalent to a $128$ bit key search, the size of the digest must be at least $256$ bits.', 'B': 'To achieve a collision resistance equivalent to a $128$ bit key search, we need a digest size of at least $2^{128}$ bits. This is because the digest size should ideally be double the desired security level to ensure a high level of collision resistance. Therefore, the correct option is:\\n\\n[ ] $2^{128}$ bits.'}, {'course_id': 15113, 'question_id': 7040, 'question': \"Make some rough estimations (in terms of powers of $10$) according to your ``feeling'' (test for a job interview as ``management consultant''...):\\n\\nHow many pencils would you need to draw a straight line along the Earth's equator ?\\n\", 'question_options': None, 'A_chat_id': 92900, 'B_chat_id': 92901, 'A': \"The Earth's equator is approximately $40,075$ kilometers long. Let's assume a typical pencil can draw a line of about $1$ meter. \\n\\nSo, to draw the Earth's equator with pencils, we would need approximately $40,075,000$ pencils.\\n\\nThis can be estimated as $10^7$ pencils. \\n\\nOf course, this is a rough estimation and the actual number may vary.\", 'B': \"Let's break down the problem step by step:\\n\\n1. The Earth's equator is approximately $40,075$ kilometers long.\\n2. Let's estimate the length of a pencil to be about $0.1$ meters (or $10$ centimeters).\\n3. To draw a straight line along the Earth's equator, you would need to continuously draw a line with the pencil.\\n4. Assuming there is no breakage or sharpening needed, you would need to align the pencils end to end along the equator.\\n5. The number of pencils needed can be estimated by dividing the length of the equator by the length of one pencil.\\n\\nSo, the rough estimation would be:\\n\\n$\\\\frac{40,075,000 \\\\text{ meters}}{0.1 \\\\text{ meters}} = 400,750,000$ pencils\\n\\nTherefore, you would need approximately $10^8$ (or $100$ million) pencils to draw a straight line along the Earth's equator.\"}, {'course_id': 0, 'question_id': 5730, 'question': 'Tick the \\\\emph{false} answer. In a group, the operation\\\\dots', 'question_options': ['is commutative', 'is associative.', 'has a neutral element.', 'associates an inverse to each value.'], 'A_chat_id': 92902, 'B_chat_id': 92903, 'A': 'The false answer is: is commutative. In a group, the operation is not necessarily commutative, meaning the order in which the operation is performed matters.', 'B': 'The false answer is: [ ] is commutative'}, {'course_id': 15113, 'question_id': 7088, 'question': \"A particle of mass $m_1$, of initial speed $\\\\boldsymbol{v}_1 = v_1\\\\,\\\\boldsymbol{e}_x$ collides with a particle of mass $m_2$, initially at rest, i.e. $\\\\boldsymbol{v}_2 = \\\\boldsymbol{0}$. We consider here the case of an elastic collision between the two particles. We denote $\\\\boldsymbol{v}'_1 = v'_1\\\\left(\\\\cos\\\\theta_1\\\\,\\\\boldsymbol{e}_x + \\\\sin\\\\theta_1\\\\,\\\\boldsymbol{e}_y\\\\right)$ and $\\\\boldsymbol{v}'_2 = v'_2\\\\left(\\\\cos\\\\theta_2\\\\,\\\\boldsymbol{e}_x -\\\\,\\\\sin\\\\theta_2\\\\,\\\\boldsymbol{e}_y\\\\right)$ the speeds after the collision.\\n\\nUsing the conservation laws, write the equations relating the physical variables $v_1$, $m_1$, $m_2$ with the physical variables $v'_1$, $v'_2$, $\\\\theta_1$, $\\\\theta_2$.\\n\", 'question_options': None, 'A_chat_id': 92904, 'B_chat_id': 92905, 'A': \"In an elastic collision, both momentum and kinetic energy are conserved. \\n\\n1. Conservation of momentum:\\nBefore the collision:\\n$$m_1 v_1 = m_1 v'_1 \\\\cos \\\\theta_1 + m_2 v'_2 \\\\cos \\\\theta_2$$\\n2. Conservation of kinetic energy:\\nBefore the collision:\\n$$\\\\frac{1}{2} m_1 v_1^2 = \\\\frac{1}{2} m_1 v'_1^2 + \\\\frac{1}{2} m_2 v'_2^2$$\\n\\nThese two equations can be used to relate the physical variables $v_1$, $m_1$, $m_2$ with the physical variables $v'_1$, $v'_2$, $\\\\theta_1$, $\\\\theta_2$ after the collision.\", 'B': \"To solve this problem, we will use the conservation of momentum and the conservation of kinetic energy.\\n\\n1. Conservation of momentum in the $x$ direction:\\n\\\\[ m_1v_1 = m_1v'_1\\\\cos\\\\theta_1 + m_2v'_2\\\\cos\\\\theta_2 \\\\]\\n\\n2. Conservation of momentum in the $y$ direction:\\n\\\\[ 0 = m_1v'_1\\\\sin\\\\theta_1 - m_2v'_2\\\\sin\\\\theta_2 \\\\]\\n\\n3. Conservation of kinetic energy:\\n\\\\[ \\\\frac{1}{2}m_1v_1^2 = \\\\frac{1}{2}m_1v'_1^2 + \\\\frac{1}{2}m_2v'_2^2 \\\\]\\n\\nThese three equations relate the physical variables $v_1$, $m_1$, $m_2$ with the physical variables $v'_1$, $v'_2$, $\\\\theta_1$, $\\\\theta_2$.\"}, {'course_id': 15113, 'question_id': 7057, 'question': 'Let us consider a hydrogen atom of mass $m = 1.67\\\\cdot10^{-27}\\\\,\\\\text{kg}$ chemically bound to a metallic surface. We model the chemical bound by a spring of constant $k$, of natural length $l_0$ and of vibration frequency $f=10^{13}\\\\,\\\\text{s}^{-1}$. \\nDetermine the value of the spring constant $k$ of the chemical bound, neglecting the action of the gravitational force.\\n', 'question_options': None, 'A_chat_id': 92906, 'B_chat_id': 92907, 'A': 'The natural frequency of vibration of a spring-mass system is given by the formula $f = \\\\frac{1}{2\\\\pi}\\\\sqrt{\\\\frac{k}{m}}$, where $k$ is the spring constant and $m$ is the mass.\\n\\nGiven that $f = 10^{13}\\\\,\\\\text{s}^{-1}$ and $m = 1.67\\\\cdot10^{-27}\\\\,\\\\text{kg}$, we can rearrange the formula to solve for $k$:\\n\\n$10^{13} = \\\\frac{1}{2\\\\pi}\\\\sqrt{\\\\frac{k}{1.67\\\\cdot10^{-27}}}$\\n\\nSquaring both sides and rearranging, we get:\\n\\n$k = (2\\\\pi)^2 \\\\times (1.67\\\\cdot10^{-27}) \\\\times (10^{13})^2$\\n\\nCalculating the value, we find:\\n\\n$k \\\\approx 1.05 \\\\times 10^{-13}\\\\,\\\\text{N/m}$\\n\\nTherefore, the value of the spring constant $k$ for the chemical bond is approximately $1.05 \\\\times 10^{-13}\\\\,\\\\text{N/m}$.', 'B': 'To determine the value of the spring constant $k$ of the chemical bond, we can use the relationship between the natural frequency of vibration $f$, the mass of the object $m$, and the spring constant $k$.\\n\\nThe natural frequency of vibration $f$ of a harmonic oscillator (such as a spring-mass system) is given by:\\n\\n$$ f = \\\\frac{1}{2\\\\pi} \\\\sqrt{\\\\frac{k}{m}} $$\\n\\nGiven that $f = 10^{13}\\\\,\\\\text{s}^{-1}$ and $m = 1.67\\\\cdot10^{-27}\\\\,\\\\text{kg}$, we can rearrange the equation to solve for the spring constant $k$:\\n\\n$$ k = (2\\\\pi f)^2 \\\\cdot m $$\\n\\nPlugging in the values, we get:\\n\\n$$ k = (2\\\\pi \\\\cdot 10^{13}\\\\,\\\\text{s}^{-1})^2 \\\\cdot 1.67\\\\cdot10^{-27}\\\\,\\\\text{kg} $$\\n\\nCalculating this expression will give us the value of the spring constant $k$ for the chemical bound.'}, {'course_id': 15008, 'question_id': 2739, 'question': 'For students born in April, how many months older are they than the average student in their grade? 5.4898 months\\nFor students born in March, how many months younger are they than the average student in their grade? 5.5102 months\\n\\nDiscuss: Considering your common sense and the results obtained from the simulation: what advantage do students born in April have over those born in March? How may this affect their odds of becoming professional athletes?', 'question_options': None, 'A_chat_id': 92908, 'B_chat_id': 92909, 'A': 'Students born in April have a slight advantage over those born in March in terms of age, as they are slightly older on average. This advantage may affect their odds of becoming professional athletes in sports where age and physical maturity play a significant role. Being slightly older may give them a physical advantage over their younger peers, especially in sports where strength and athleticism are important factors. However, it is important to note that factors such as talent, dedication, and training also play a significant role in becoming a professional athlete.', 'B': 'Based on the information provided, students born in April are 5.4898 months older than the average student in their grade, while students born in March are 5.5102 months younger than the average student. This slight age difference of around 0.02 months may not seem significant, but it can have a cumulative effect in certain competitive fields, such as sports.\\n\\nIn sports, especially at the professional level, age can play a crucial role in skill development, physical maturity, and overall performance. The advantage of being slightly older, even by a few months, could mean that students born in April may have had more time to develop their skills, physical abilities, and maturity compared to those born in March. This could potentially give them a slight edge in sports competitions and selection processes.\\n\\nIn terms of becoming professional athletes, this age difference could impact the odds of success for students born in April compared to those born in March. The additional months of development and experience could give April-born students a competitive advantage in terms of physical conditioning, skill development, and overall performance, which may increase their chances of being noticed by scouts, coaches, and teams.\\n\\nWhile individual talent, hard work, and dedication are also crucial factors in becoming a professional athlete, the age advantage that April-born students have over March-born students could potentially influence their odds of success in the highly competitive world of sports.'}]\n"
     ]
    }
   ],
   "source": [
    "print(generated_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "sciper = get_sciper()\n",
    "json_file_path = os.path.join(\"data\", f\"{sciper}_generated_answers.json\")\n",
    "\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(generated_answers, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
